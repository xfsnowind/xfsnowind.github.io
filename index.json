[{"body":"","link":"https://xfsnowind.github.io/blogs/","section":"blogs","tags":null,"title":"Blogs"},{"body":"","link":"https://xfsnowind.github.io/tags/frontend/","section":"tags","tags":null,"title":"Frontend"},{"body":"Around 2018, one of my colleague was working on creating a list component which only renders a limited amount of items in the list instead of the whole one to improve the performance if the list is in large or huge scale. I was always interested at how he did that, but I did not do any investment, just an idea. Then once I was asked how to implement such thing during an interview, it remindered me. I wrote it to my learning plan blog. After I began to work in the new company, I found all the lists in the product already used this idea with the library react-virtualized and its optimized version react-window. Finaly, I decided to learn this thing -- virtualized, figure out how it is implemented. Nowadays virtualized has become a kind of standard for all the grid/list library, it's used in most frameworks or libraries,like mui, react-table. So here I would share my research about how it is implemented. Since I am more familiar with React, so I will use React as the framework.\nGrid/List Normally, both List and Grid are virtualized. But since List is actually an one-dimension Grid, so let's take Grid as an example.\nWorkflow To implement this feature, we need to implement in two parts: javascript and html. With javascript, we need to calculate the start/end indexes of the visible elements. And for html, we need to paint them.\nJavascript - logic OK, let's clear the logic firstly. Let's imagine we have a 1000x1000 grid, only 20x20 are rendered in the table no matter how it scrolls. So to render only the visible items in the long list/grid during scrolling, it must be related to the scroll event. We need to\ncalculate the scroll offset of the whole component when scroll calculate the start and end index of vertical and horizontal elements based on offset generate the visible element based on the indexes Scroll offset Apparently, we need a callback event function to bind to the scroll event of the root element, calculating the offsets in vertical and horizontal directions. It can be obtained from node's property scrollLeft and scrollTop.\n1const [verticalScroll, setVerticalScroll] = React.useState(0); 2const [horizontalScroll, setHorizontalScroll] = React.useState(0); 3 4// set up scroll event to update the offset of top and left 5const onScroll = useCallback((event: UIEvent\u0026lt;HTMLDivElement\u0026gt;) =\u0026gt; { 6 const target = event.target as HTMLDivElement; 7 const leftOffset = Math.max(0, target.scrollLeft); 8 const topOffset = Math.max(0, target.scrollTop); 9 10 setVerticalScroll(topOffset); 11 setHorizontalScroll(leftOffset); 12}, []); Start/end index OK, the offsets are here now. Naturally, the start and end indexes are easy to calculate with the size of cell and the window from input.\n1const useIndexForDimensions = ({ 2 offset, 3 cellDimension, 4 windowDimension, 5}: DimensionsType) =\u0026gt; { 6 const startIndex = Math.floor(offset / cellDimension); 7 const endIndex = Math.ceil((offset + windowDimension) / cellDimension); 8 return [startIndex, endIndex]; 9}; 10 11... 12 13// calculate the start and end row and column based on the offset 14const [verticalStartIdx, verticalEndIdx] = useIndexForDimensions({ 15 offset: verticalScroll, 16 cellDimension: cellHeight, 17 windowDimension: inputWindowHeight, 18}); 19 20const [horizontalStartIdx, horizontalEndIdx] = useIndexForDimensions({ 21 offset: horizontalScroll, 22 cellDimension: cellWidth, 23 windowDimension: inputWindowWidth, 24}); Grid cell After getting the index, we can just render the element within the range. Just simply slice the data array and pass the width and height to the cell element.\n1const useScrollItem = ({ 2 verticalStartIdx, 3 verticalEndIdx, 4 horizontalStartIdx, 5 horizontalEndIdx, 6 cellWidth, 7 cellHeight, 8 data, 9}: ScrollItemType) =\u0026gt; 10 useMemo(() =\u0026gt; { 11 return data.slice(verticalStartIdx, verticalEndIdx).map((row, i) =\u0026gt; { 12 const rowChildren = row 13 .slice(horizontalStartIdx, horizontalEndIdx) 14 .map((_, j) =\u0026gt; { 15 const vIdx = i + verticalStartIdx; 16 const hIdx = j + horizontalStartIdx; 17 let background = (vIdx + hIdx) % 2 === 1 ? \u0026#34;grey\u0026#34; : \u0026#34;white\u0026#34;; 18 return ( 19 \u0026lt;div 20 key={\u0026#34;row-\u0026#34; + vIdx + \u0026#34;-column-\u0026#34; + hIdx} 21 style={{ 22 background, 23 color: \u0026#34;black\u0026#34;, 24 display: \u0026#34;flex\u0026#34;, 25 justifyContent: \u0026#34;center\u0026#34;, 26 alignItems: \u0026#34;center\u0026#34;, 27 width: cellWidth + \u0026#34;px\u0026#34;, 28 height: cellHeight + \u0026#34;px\u0026#34;, 29 }} 30 \u0026gt; 31 {vIdx}, {hIdx} 32 \u0026lt;/div\u0026gt; 33 ); 34 }); 35 36 return ( 37 \u0026lt;div key={\u0026#34;row-\u0026#34; + i} style={{ display: \u0026#34;flex\u0026#34; }} \u0026gt; 38 {rowChildren} 39 \u0026lt;/div\u0026gt; 40 ); 41 }); 42 }, [ 43 verticalStartIdx, 44 verticalEndIdx, 45 horizontalStartIdx, 46 horizontalEndIdx, 47 cellWidth, 48 cellHeight, 49 data, 50 ]); Html part So the logic part is finished. We also need to render it correctly in the html file. At first, to limit the component in the given size, we need a root element to set the width and height.\n1\u0026lt;div 2 onScroll={onScroll} 3 style={{ 4 width: `${inputWindowWidth}px`, 5 height: `${inputWindowHeight}px`, 6 overflow: \u0026#34;auto\u0026#34;, 7 position: \u0026#34;relative\u0026#34;, 8 }} 9\u0026gt; You can see we bind the onScroll callback function on this root element, and also set the overflow as auto to allow the children elements scrollable.\nSince we do not paint all the elements in the DOM, we must have something to meet two requirements at the same time.\nWe need a child element with big enough size to make the root element scrollable. And its size should allow the visible element display correctly. This child element has no text to display, only has size. 1\u0026lt;div style={{ 2 width: `${cellWidth * data[0].length}px`, 3 height: `${cellHeight * data.length}px`, 4 }} 5\u0026gt; So here the width would be cell width multiple the length of the row and height would be the same. When we scroll the page, actually we are scrolling this non-text element.\nFinally, we need to the parent node to display the visible elements. This is the core part, because when the previous invisible element scrolls, this child element would also have offset. To make sure it displays inside of the window, we need to do transform to it with the offset values calculated from the first step in javascript part.\n1\u0026lt;div 2 style={{ 3 position: \u0026#34;absolute\u0026#34;, 4 transform: `translate(${horizontalScroll}px, ${verticalScroll}px)`, 5 display: \u0026#34;flex\u0026#34;, 6 flexDirection: \u0026#34;column\u0026#34;, 7 }} 8\u0026gt; Deploy to Github pages You can check Here for full codes, I have deployed it to github pages as well.\nActually, I have already deployed my own blog website by Hugo in Github Pages, then how could I deploy this app to a subpage of the website without effecting Hugo. Check here to deploy and here to add command to github actions.\n","link":"https://xfsnowind.github.io/blogs/react-virtualized/","section":"blogs","tags":["Javascript","React","virtualized","Frontend"],"title":"How to implement Virtualized Grid/List in React"},{"body":"","link":"https://xfsnowind.github.io/tags/javascript/","section":"tags","tags":null,"title":"Javascript"},{"body":"","link":"https://xfsnowind.github.io/tags/react/","section":"tags","tags":null,"title":"React"},{"body":"","link":"https://xfsnowind.github.io/tags/","section":"tags","tags":null,"title":"Tags"},{"body":"","link":"https://xfsnowind.github.io/tags/virtualized/","section":"tags","tags":null,"title":"virtualized"},{"body":"","link":"https://xfsnowind.github.io/","section":"","tags":null,"title":"xfsnowind"},{"body":"","link":"https://xfsnowind.github.io/tags/git/","section":"tags","tags":null,"title":"Git"},{"body":"","link":"https://xfsnowind.github.io/tags/learning-notes/","section":"tags","tags":null,"title":"Learning Notes"},{"body":"Git merge Normally, to get the latest update from main branch during development the feature or fix branch, I would checkout to the main branch and git pull the latest commits and then checkout back and run the merge command.\n1git checkout main 2git pull 3git checkout FEATURE-BUG-BRANCH 4git merge --no-ff development 5 6or 7 8git checkout main 9git pull 10git merge FEATURE-BUG-BRANCH main It works and will create a MERGE commit in the feature branch. It's OK because it's non-destructive operation. But it will always have an extraneous merge commit in the history, which may be fine to have it at the end of development, but not good during the development. So is there a possibility to merge the main branch into our feature branch without a merge commit?\nGit rebase The answer is git rebase. We can try the following:\n1git checkout FEATURE-BUG-BRANCH 2git rebase main This will move the whole feature branch to beginning of the main branch. And instead of creating a merge commit, it will re-write the whole history by making new commits, even there is some merge commits in the feature branch before.\nThe benefit of rebasing would be, first, there is no unrequired merge commits, second, the git history is quite linear, the main branch would be behind the feature branch. However, all of these should be done when there is only one developer, no collaborator. Because rebasing would re-write the commits, so if you collaborate with other developers, the commits from main branch would be different from the public main branch. That would be a hard situation.\nSo before using git rebase, ask yourself, is there another developer working together with you on this branch. If the answer is yes, then use merge instead.\nWhat happen when rebase mixed with merge Let's do some experiment, creating a main and feature branch.\n1\u0026gt; git checkout -b main 2Switched to a new branch \u0026#39;main\u0026#39; 3(main)\u0026gt; touch test.js 4(main)\u0026gt; git add test.js 5(main)\u0026gt; git commit -m \u0026#34;init\u0026#34; 6[main (root-commit) b7c27e8] init 7 1 file changed, 0 insertions(+), 0 deletions(-) 8 create mode 100644 test.js 9 10// feature branch 11(main)\u0026gt; git checkout -b feature 12Switched to a new branch \u0026#39;feature\u0026#39; 13(feature)\u0026gt; touch feature.js 14(feature)\u0026gt; git add feature.js 15(feature)\u0026gt; git commit -m \u0026#34;feature.js\u0026#34; 16[feature 4d60997] feature.js 17 1 file changed, 0 insertions(+), 0 deletions(-) 18 create mode 100644 feature.js So we have one commit in both feature and main branch. Let's create one more commit for each branch.\n1(feature)\u0026gt; git co main 2Switched to branch \u0026#39;main\u0026#39; 3\u0026gt; touch main.js 4(main)\u0026gt; git add main.js 5(main)\u0026gt; git commit -m \u0026#34;main.js\u0026#34; 6[main c593f25] main.js 7 1 file changed, 0 insertions(+), 0 deletions(-) 8 create mode 100644 main.js 9 10(main)\u0026gt; git co feature 11Switched to branch \u0026#39;feature\u0026#39; 12(feature)\u0026gt; touch feature2.js 13(feature)\u0026gt; git add feature2.js 14(feature)\u0026gt; git commit -m \u0026#34;feature2.js\u0026#34; 15[feature 193b518] feature2.js 16 1 file changed, 0 insertions(+), 0 deletions(-) 17 create mode 100644 feature2.js Now, let's merge the main to the feature and check how the history looks like\n1(feature)\u0026gt; git merge --no-ff main 2Merge made by the \u0026#39;ort\u0026#39; strategy. 3 main.js | 0 4 1 file changed, 0 insertions(+), 0 deletions(-) 5 create mode 100644 main.js 6 7(feature)\u0026gt; git log --oneline --graph 8* e99a53e (HEAD -\u0026gt; feature) Merge branch \u0026#39;main\u0026#39; into feature 9|\\ 10| * c593f25 (main) main.js 11* | 193b518 feature2.js 12* | 4d60997 feature.js 13|/ 14* b7c27e8 init Yes, a merge commit is created with merging. Let's check how it looks like with rebasing\n1(feature)\u0026gt; git co main 2Switched to branch \u0026#39;main\u0026#39; 3(main)\u0026gt; touch main2.js 4(main)\u0026gt; git add main2.js 5(main)\u0026gt; git commit -m \u0026#34;main2.js\u0026#34; 6[main 6c43d0f] main2.js 7 1 file changed, 0 insertions(+), 0 deletions(-) 8 create mode 100644 main2.js 9 10(main)\u0026gt; git co feature 11Switched to branch \u0026#39;feature\u0026#39; 12(feature)\u0026gt; touch feature3.js 13(feature)\u0026gt; git add feature3.js 14(feature)\u0026gt; git commit -m \u0026#34;feature3.js\u0026#34; 15[feature dc5fbcb] feature3.js 16 1 file changed, 0 insertions(+), 0 deletions(-) 17 create mode 100644 feature3.js 18 19 (feature)\u0026gt; git rebase main 20Successfully rebased and updated refs/heads/feature. 21(feature)\u0026gt; git log --oneline --graph 22* 3caa16c (HEAD -\u0026gt; feature) feature3.js 23* cd53eed feature2.js 24* 595209c feature.js 25* 6c43d0f (main) main2.js 26* c593f25 main.js 27* b7c27e8 init We can see the feature branch locates on the top of main branch and the history is linear, even we actually have created a merge commit before.\nAnd all the commits in the main branch are kept, while all the commits in feature are, as we said, re-write as new commits, we can see the commit ids/hashes are different.\nLet's do one more step, merge the main to feature again.\n1(feature)\u0026gt; git co main 2Switched to branch \u0026#39;main\u0026#39; 3(main)\u0026gt; touch main-after-rebase.js 4(main)\u0026gt; git add main-after-rebase.js 5(main)\u0026gt; git commit -m \u0026#34;main after rebase\u0026#34; 6[main 92bd62e] main after rebase 7 1 file changed, 0 insertions(+), 0 deletions(-) 8 create mode 100644 main-after-rebase.js 9 10 (main)\u0026gt; git co feature 11Switched to branch \u0026#39;feature\u0026#39; 12(feature)\u0026gt; touch feature-after-main-after-rebase.js 13(feature)\u0026gt; git add feature-after-main-after-rebase.js 14(feature)\u0026gt; git commit -m \u0026#34;feature after main after rebase\u0026#34; 15[feature 2556a80] feature after main after rebase 16 1 file changed, 0 insertions(+), 0 deletions(-) 17 create mode 100644 feature-after-main-after-rebase.js 18 19(feature)\u0026gt; git merge --no-ff main 20Merge made by the \u0026#39;ort\u0026#39; strategy. 21 main-after-rebase.js | 0 22 1 file changed, 0 insertions(+), 0 deletions(-) 23 create mode 100644 main-after-rebase.js 24(feature)\u0026gt; git log --oneline --graph 25* f162af2 (HEAD -\u0026gt; feature) Merge branch \u0026#39;main\u0026#39; into feature 26|\\ 27| * 92bd62e (main) main after rebase 28* | 2556a80 feature after main after rebase 29* | 3caa16c feature3.js 30* | cd53eed feature2.js 31* | 595209c feature.js 32|/ 33* 6c43d0f main2.js 34* c593f25 main.js 35* b7c27e8 init So the merge commit is created as expected, but it's based on the main2.js commit, not from the beginning.\n","link":"https://xfsnowind.github.io/blogs/git-rebase/","section":"blogs","tags":["Learning Notes","Git"],"title":"Learning Notes - Git rebase vs Git merge"},{"body":"","link":"https://xfsnowind.github.io/tags/folderflip/","section":"tags","tags":null,"title":"FolderFlip"},{"body":"Update 2022-11-15: add the images to explain the steps\nAs we presented in the previous article, we have showed how to implement the FolderFlip with limited number (like 3) items with the position: sticky and IntersectionObserver.\nThe Problem But it only allows limited number, if it comes more items or the screen is smaller, the items would not be able to scroll. So how would we display if the items are more and the titles take most of the screen.\nClear the logic first If you want the final answer, just jump to here. Otherwises, I would explain the solutions and the procedures below, also some problems I met.\nThe idea is we only display a certain number of items in the screen, when the items' number reaches the limit with scrolling down/up, the next/previous one would float out to leave the room for the new item, which can be implemented by changing postion to relative like what we have done in the previous blog. So it's like the state transition. I call the state sticky before some item reaches the threshold, when it reaches, the whole component would transit to a state named float. And in the float state, the first item (according to the scroll direction) would be moved out of screen.\nAs we see in the graph,\nwhen the content3 hasn't reach 100% in the screen, the state should be position: sticky; If we scroll down and the content3 reaches threshold 100%, it changes to the state position: relative; If we scroll up, then it will go back the state position: sticky again If we keep scrolling down until it reaches the threshold 0% of content4, the state would be update to position: sticky scroll up would go back the state position: relative And as we know, React is a declarative library, which means you just need to give the required state, React would render it for you anyway, you do not need to know how it's implemented. So it would be good to use state machine diagram to explain the different states and easy to convert the diagram to codes.\nState machine diagram Here are the diagram:\nState machine diagram Define variables and states We define some concepts first:\nWe define a window here, which means the items shown in the screen, and we set it as 3 here; WS or windowStart is the start value of window and its value is START. The original value is 0 and betwee 0 and LENGTH - windowSize; edge element is the upper element which would be checked if it reaches threshold 100% showup element is the lower element which would be checked if it reaches threshold 0 And we can see the variables as well:\nreach100 -\u0026gt; boolean, indicates if the current observed edge element reach threshold 100% reach0 -\u0026gt; boolean, indicates if the current observed showup element reaches threshold 0 edgeIndex -\u0026gt; indicates the observed edge element index in edge element array, the original value is windowStart + windowSize - 1 showupIndex -\u0026gt; indicates the observed showup element index in showup element array, the original value is windowStart + windowSize sectionState -\u0026gt; STICKY or FLOAT, indicates the current state of component windowStart -\u0026gt; window start value, initial value is 0 and range is \u0026gt;= 0 and \u0026lt;= LENGTH - window size According to the state machine diagram, there are three types of states:\nthe normal state, it's normally stable (yellow one) the state triggered by user scroll behavior (pink one) the state should be updated internally (blue one) We will handle each scenario which triggered and started by the scroll event which is solid line in the diagram. One entire process should be end to the normal state whose color is yellow. From the diagram, we can see one process should have three states, except two edge situations.\nThe process is triggered by scrolling down, starting from the original state and transiting to the normal state directly, without scroll state (pink) and internal state (blue); 2. The process is triggered by scrolling up from the final normal state and transites to the normal state directly as well. We need to handle these two situations separately.\nWith only two IntersectionObservers Although there are 6 (for example) items in the list, actually we only need two active observers. One is for the edge element, the other for showup element, although these two elements are not fixed. So why wouldn't we just create two observers and update the observer's observed element dynamically to get the correct state.\nAs you see, it does work if we scroll showly and carefully. But if we swipe the page fast, something begins going wrong. Why? Because when we swipe too fast, the observer could not change to the correct element before observing the changing.\nIntersectionObserver observes multiple elements??? OK, the solution with only two observers does not work. But actually one IntersectionObserver can observe multiple elements, like this:\n1// Create a new observer 2let observer = new IntersectionObserver(function (entries) { 3\tentries.forEach(function (entry) { 4\tconsole.log(entry.target); 5\tconsole.log(entry.isIntersecting); 6\t}); 7}); 8 9// The elements to observe 10let div1 = document.querySelector(\u0026#39;#div-1\u0026#39;); 11let div2 = document.querySelector(\u0026#39;#div-2\u0026#39;); 12 13// Attach them to the observer 14observer.observe(div1); 15observer.observe(div2); so would using one observer on multiple elements save some resources?\nThe answer is no. Not just because there is no big difference, but also it does not work as we expect. According to this blog, only elements that have changed show up in the entries array. So if the element's state not changed, the state would not be in the parameters of observer's callback function, which means we cannot get the correct state of desired element.\nSo actually when we change the state by scrolling behavior or internal updating, we need the state of the observed element which can be saved in an array. When we change the observed element, we just read the state from that array.\nObserver Array So we need to setup an array for every type elment (edge, showup) which saves the value of if the elements reaches the threshold, 0 or 100%. Therefore, we have to create observer for each element. Would it effect the performance? Luckily the answer is also no. According to previous mentioned blog, there is no difference of using many observers with one element each.\nA few years ago, there was a discussion about the performance implications of using this approach on the w3c GitHub repository for this specification. The general conclusion was that using many observers with one element each and one observer with many elements should be about equally performant...\n1const [edgeElementIndex, setEdgeElementIndex] = useState(windowSize - 1); 2const [showupElementIndex, setShowupElementIndex] = useState(windowSize); 3 4// save the edge and showup elements, it should be stable 5const edgeElements = useMemo( 6 () =\u0026gt; [].slice.call(contentElements, windowSize - 1, stepLength), 7 [contentElements, stepLength] 8); 9 10const showupElements = useMemo( 11 () =\u0026gt; [].slice.call(contentElements, windowSize - 1, stepLength), 12 [contentElements, stepLength] 13); 14 15// save all the states of edge and showup elements in the array and 16// get their states update whenever observers are triggered, init values are false 17const [edgeStates, setEdgeStates] = useState([]); 18const [showupStates, setShowupStates] = useState([]); 19 20// initial the content elements 21useEffect(() =\u0026gt; { 22 let tags = elementRef.current.getElementsByClassName(\u0026#34;FolderFlip-Tag\u0026#34;); 23 // get the height of the tag 24 setTagHeight(tags[0].getBoundingClientRect().height); 25 setContentElements( 26 elementRef.current.getElementsByClassName(\u0026#34;FolderFlip-Content\u0026#34;) 27 ); 28}, []); 29 30// the callback function to handle when the folder reaches edge with scrolling down 31// keep updating the state according to observers no matter if the element\u0026#39;s state is used 32const reachEdgeFunc = ([entry], index) =\u0026gt; { 33 setEdgeStates((v) =\u0026gt; { 34 let value = [...v]; 35 value[index] = entry.isIntersecting || entry.boundingClientRect.top \u0026lt; 0; 36 return value; 37 }); 38}; 39 40const folderShowUpFunc = ([entry], index) =\u0026gt; { 41 setShowupStates((v) =\u0026gt; { 42 let value = [...v]; 43 value[index] = entry.isIntersecting; 44 return value; 45 }); 46}; 47 48// set up the observer for edge element with threshold 100% 49useIntersection(edgeElements, reachEdgeFunc, { 50 threshold: 1.0 51}); 52 53// set up the observer for showup element with threshold 0% 54useIntersection(showupElements, folderShowUpFunc, { 55 threshold: 0 56}); We use useMemo to save the edgeElements and showupElements to avoid re-rendering. And create arrays edgeStates and showupStates to save the states of all the elements. To get the correct observed element's state, we also need edgeIndex and showupIndex. When certain element reaches the threshold and triggers the callback function, it passes entry and the index in state array.\nuseIntersection needs to update as well:\n1function useIntersection(nodeElements, callbackFunc, options) { 2 let observers = useMemo(() =\u0026gt; { 3 if (typeof IntersectionObserver === \u0026#34;undefined\u0026#34;) return; 4 5 return nodeElements.map( 6 (_, i) =\u0026gt; 7 new IntersectionObserver( 8 (entries) =\u0026gt; { 9 callbackFunc(entries, i); 10 }, 11 { 12 threshold: options.threshold 13 } 14 ) 15 ); 16 }, [nodeElements, callbackFunc, options.threshold]); 17 18 useEffect(() =\u0026gt; { 19 observers.forEach((observer, i) =\u0026gt; { 20 if (nodeElements[i]) { 21 if (observer) observer.observe(nodeElements[i]); 22 } 23 }); 24 25 return () =\u0026gt; { 26 observers.forEach((observer) =\u0026gt; { 27 if (observer) observer.disconnect(); 28 }); 29 }; 30 }, [nodeElements, observers]); 31} But here comes another problem, it seems too many useState, and each of them hangs out with others, to handle the logic, it's better to put them in one function. The state transition could be processed there. How to implement this?\nuseReducer makes my day The answer is useReducer in React.\nreducer and dispatcher are the concepts from Redux, even though we do not use it here, but useReducer was introduced to React as well.\n1const [state, dispatch] = useReducer(reducer, initialArg, init); So we can handle all the variables in the reducer and update the UI according to the returned state. Also use dispatch to send the state from observer's callback function.\n1// the callback function to handle when the folder reaches edge with scrolling down 2// keep updating the state according to observers no matter if the element\u0026#39;s state is used 3const reachEdgeFunc = useCallback( 4 ([entry], index) =\u0026gt; 5 dispatchFunc({ 6 type: REDUCER_TYPE.edge, 7 payload: { 8 index, 9 value: entry.isIntersecting || entry.boundingClientRect.top \u0026lt; 0 10 } 11 }), 12 [dispatchFunc] 13); 14 15const folderShowUpFunc = useCallback( 16 ([entry], index) =\u0026gt; 17 dispatchFunc({ 18 type: REDUCER_TYPE.showup, 19 payload: { index, value: entry.isIntersecting } 20 }), 21 [dispatchFunc] 22); Here we use useCallback to avoid re-rendering in hooks useIntersection. And the payload contains the element index and the state of element.\nThe reducer takes state and action as parameters and should be pure, which means with the same input, the output should also not change. Note: Within StrictMode of React, the reducer would be called twice with same value.\n1function FolderFlipReducer(state, action) { 2 if (!action) return state; 3 4 // set the value of edge state with given index 5 if (action.type === REDUCER_TYPE.edge) { 6 state.edgeStates[action.payload.index] = action.payload.value; 7 } else if (action.type === REDUCER_TYPE.showup) { 8 state.showupStates[action.payload.index] = action.payload.value; 9 } 10 11 let edgeIndex = state.edgeIndex, 12 showupIndex = state.showupIndex, 13 sectionState = state.sectionState, 14 windowStart = state.windowStart; 15 16 const reach0 = state.showupStates[state.showupIndex - windowSize + 1], 17 reach100 = state.edgeStates[state.edgeIndex - windowSize + 1]; 18 19 // if the prev state is initial stable state, just update the section state 20 if (!reach0 \u0026amp;\u0026amp; reach100 \u0026amp;\u0026amp; edgeIndex + 1 === showupIndex) { 21 sectionState = SECTION_STATE.float; 22 return { 23 ...state, 24 sectionState 25 }; 26 } 27 28 // if the prev state is final stable state 29 if (reach0 \u0026amp;\u0026amp; !reach100 \u0026amp;\u0026amp; edgeIndex === showupIndex) { 30 sectionState = SECTION_STATE.sticky; 31 return { 32 ...state, 33 sectionState 34 }; 35 } 36 37 // all the other four situations would need to be handled under state type scroll 38 // handle the pink ones in state machine diagram 39 40 // if edge and showup observed elements are the same, set the state as float 41 if (edgeIndex === showupIndex) sectionState = SECTION_STATE.float; 42 43 // otherwises, sticky 44 if (edgeIndex + 1 === showupIndex) sectionState = SECTION_STATE.sticky; 45 46 // need to update the edge and showup index in the internal state type 47 48 if (sectionState === SECTION_STATE.float) { 49 if (reach0 \u0026amp;\u0026amp; reach100) { 50 if (windowStart + windowSize \u0026lt; state.stepLength) 51 showupIndex = windowStart + windowSize; 52 } else if (!reach0 \u0026amp;\u0026amp; !reach100) { 53 windowStart = state.windowStart \u0026gt; 0 ? state.windowStart - 1 : 0; 54 edgeIndex = state.windowStart + windowSize - 2; 55 } 56 } 57 58 if (sectionState === SECTION_STATE.sticky) { 59 if (!reach0 \u0026amp;\u0026amp; !reach100) { 60 if (windowStart \u0026gt; 0) showupIndex = windowStart + windowSize - 1; 61 } else if (reach0 \u0026amp;\u0026amp; reach100) { 62 edgeIndex = windowStart + windowSize; 63 windowStart = 64 state.windowStart + windowSize \u0026lt; state.stepLength 65 ? state.windowStart + 1 66 : state.stepLength - windowSize; 67 } 68 } 69 70 return { 71 ...state, 72 windowStart, 73 edgeIndex, 74 showupIndex, 75 sectionState 76 }; 77} So til now, we have explained and presented the solution, the page works quite stable. Below is the full codes and welcome any comments.\n","link":"https://xfsnowind.github.io/blogs/folderflip-version2/","section":"blogs","tags":["Javascript","React","FolderFlip","Frontend"],"title":"How to implement a FolderFlip 2"},{"body":"Haven't updated the blogs for a long time. Just had been struggling on the house work during the whole summer time, painting external and internal wall, new bathroom and etc. But there is still the good news, implemented an interesting frontend component with React, which would inspired by lifeatspotify - borrow the name FolderFlip.\nThe original idea was come up with by the UX designer in our team, she would like to develop a fancy component which can be used to present the company culture. Here is how it looks like:\nAfter investing, I found it can be done with the css feature position: sticky and javascript's IntersectionObserver.\nTip: position: sticky This is not a new feature, but I rarely used it before because of not fully supported by all the browsers before. But now definitely it's supported by all the main stream browsers. Check CanIUse.\nLet's start with creating a list with three items which consists of a title and some simple texts as the content. And before the list, it also has some texts.\nWe can see when we scroll down and the list enters the screen, all the three titles would always be inside of screen with setting the value of top, bottom and margin-top. And display the titles in order according to the item's index in the list.\n1marginTop: `${tagHeight * idx}px`, 2top: `${idx * tagHeight}px`, 3bottom: `${(stepLength - idx - 1) * tagHeight}px` Here there is one thing I would like to mention. When we use position: sticky, the stickied item would be attached to its parent node, to make all the titles have the same parent node, we use React's fragment to compose each item.\n1\u0026lt;React.Fragment key={\u0026#34;FolderFlipStep\u0026#34; + Title.value + idx}\u0026gt; 2 \u0026lt;div id={id}\u0026gt;\u0026lt;/div\u0026gt; 3 \u0026lt;a 4 href={\u0026#34;#\u0026#34; + id} 5 className=\u0026#34;FolderFlip-Tag\u0026#34;\u0026gt; 6 \u0026lt;span className=\u0026#34;FolderFlip-Tag-Number\u0026#34; /\u0026gt; 7 \u0026lt;h2\u0026gt;{Title.value ?? \u0026#34;\u0026#34;}\u0026lt;/h2\u0026gt; 8 \u0026lt;/a\u0026gt; 9 \u0026lt;div className=\u0026#34;FolderFlip-Content\u0026#34;\u0026gt; 10 \u0026lt;span className=\u0026#34;FolderFlip-Content-Title\u0026#34;\u0026gt;{Title ?? \u0026#34;\u0026#34;}\u0026lt;/span\u0026gt; 11 \u0026lt;div className=\u0026#34;FolderFlip-Content-Container\u0026#34;\u0026gt; 12 \u0026lt;div\u0026gt;{Ingress}\u0026lt;/div\u0026gt; 13 \u0026lt;button\u0026gt;{Button}\u0026lt;/button\u0026gt; 14 \u0026lt;/div\u0026gt; 15 \u0026lt;/div\u0026gt; 16\u0026lt;/React.Fragment\u0026gt; OK, now it seems we have fixed the most important feature of the component. Nja, kind of. Actually, maybe you have found it when we keep scrolling down (there are some texts under the list as well) and beyond the list, the titles are still sticky and only contents move up. Definitely the title should move together with contents fluently. How do we solve this?\nFloating with IntersectionObserver It comes the js API IntersectionObserver, which observes how the node intersects with the specified master node (defaultly and normally it's the screen) in the non-main process. For detail and description, you can check Mozilla's doc.\n1let observer = new IntersectionObserver( 2 ([entry]) =\u0026gt; { 3 console.log(\u0026#34;reach 100%\u0026#34;); 4 }, 5 { 6 threshold: 1.0 7 } 8); 9 10observer.observe(element); In this example, when the node reaches 100% in the screen, it would print out the log.\nTherefore, the logic would be simple, when the content of the last item reaches the threshold 100% (taking the screen as master), we would change the items inside the screen from position: sticky to position: relative to allow the items float.\n1let observer = new IntersectionObserver( 2 ([entry]) =\u0026gt; { 3 setIntersection( 4 entry.isIntersecting || entry.boundingClientRect.top \u0026lt; 0 5 ); 6 }, 7 { 8 threshold: 1.0 9 } 10); 11 12useEffect(() =\u0026gt; { 13 observer.observe(textRef.current); 14 15 return () =\u0026gt; { 16 observer.disconnect(); 17 }; 18}, [observer]); In the code, the variable observer would be created every time when the page renders which would disconnect the observer and observe the same element again in useEffect. To avoid this, we can use useMemo to reserve the observer from rendering and we can pass a memorized callback function to deal with the entries. And we can create a new hooks to handle this:\n1function useIntersection (textRef, callbackFunc) { 2 let observer = useMemo(() =\u0026gt; { 3 return new IntersectionObserver(callbackFunc, 4 { 5 threshold: 1.0 6 } 7 ); 8 }, [callbackFunc]); 9 10 useEffect(() =\u0026gt; { 11 if (textRef?.current) observer.observe(textRef.current); 12 13 return () =\u0026gt; { 14 observer.disconnect(); 15 }; 16 }, [textRef, observer]); 17} And we can use this hooks to observe the last item of the list.\n1 const textRef = useRef(null); 2 3 const callbackFunc = useCallback( 4 ([entry]) =\u0026gt; 5 setIntersection(entry.isIntersecting || entry.boundingClientRect.top \u0026lt; 0), 6 [] 7 ); 8 9 useIntersection(textRef, intersectCallbackFunc); 10 11 ... 12 13 return (\u0026lt;React.Fragment\u0026gt; 14 \u0026lt;div 15 className=\u0026#34;FolderFlip-Content\u0026#34; 16 ref={stepLength - 1 == idx ? textRef : undefined} 17 \u0026gt;\u0026lt;/div\u0026gt; 18 \u0026lt;/React.Fragment\u0026gt;) Notice that the textRef is a React ref which would not trigger the execution of useEffect when it changes.\nNow we can see when we keep scrolling down, the whole items move out of the screen fluently.\nWhat if more items? Till now, we have implemented the component. And maybe someone has noticed that we have only three items in the example, what if there are more items, like 6 or more? And actually the title of items would take over the whole screen, the content of the item would only have a very small part of the screen or even cannot show, especially in mobile. How could we fix that?\nThe solution to this in simple would be that we set maximum value of displayed items in the screen, like 3, no matter how many items we have. And definitely it is more complicated and will be explained in the next article.\n","link":"https://xfsnowind.github.io/blogs/folderflip/","section":"blogs","tags":["Javascript","React","FolderFlip","Frontend"],"title":"How to implement a FolderFlip with React"},{"body":"","link":"https://xfsnowind.github.io/tags/azure/","section":"tags","tags":null,"title":"Azure"},{"body":"This blog is about the Azure developer challenge from Sparebanken Vest. I would like to write the learning notes here.\nExplore Azure App Service Target: Learn about the key components of Azure App Service and how App Service can help you create, maintain, and deploy web apps more efficiently.\nAzure App Service So what is Azure App Service? It's a Http-based service, which would server for web application, REST APIs and mobile backends. It can:\nauto scale support CI/CD support Deployment slots -- support different deployment environment, like stage, prod Linux support. But have some limitaions: Not support on Shared pricing tier; Cannot mix Windows and Linux in same App service plan; Cannot mix Windows and Linux apps in the same resource group after Jan 21, 2021; Azure Portal shows only working features Azure App Service plans An app runs in an App Service plan and each plan defines:\nRegion (West US, North Euro, etc) Number of VM instances Size of VM instances Pricing tier (Free, Shared, Basic, Premium and etc) And pricing tier decides what feature you can use:\nShared compute: Both Free and Shared share the resource pools and can't scale out. Dedicated compute: The Basic, Standard, Premium, PremiumV2, and PremiumV3 tiers run apps on dedicated Azure VMs. Isolated: This tier runs dedicated Azure VMs on dedicated Azure Virtual Networks and provides the maximum scale-out capabilities. Consumption: This tier is only available to function apps. It scales the functions dynamically depending on workload. In the Free and Shared tiers, app cannot scale out. And apps in the same App Service plan would share the same VM instances.\nWhen we add a new app, we need to understand the expected load for the new app. If it\nis resource intensive; needs resource in other geographical region; is scaled out independently from other apps; , we can isolate it into a new App Service plan. Deploy We can deploy App Service automatically from\nAzure DevOps Github Bitbucket Or manually through:\nGit CLI - az webapp up would create a new App Service web app and deploy it; Zip deploy - Use curl or similar Http utility to send a ZIP to App Service; FTP/S Deployment slots can be used when deploying a new production build.\nAuthentication and Authorization in App Service Built-in authentication can save time and effort with OpenID identity providers:\nMicrosoft Identity Platform Facebook Google Twitter Any OpenID connect provider The authentication and authorization will run in the same sandbox as application code and every incoming Http request would be handled with:\nauthenticating with the specified provider validating, storing and refreshing tokens managing the authenticated session injecting identity information to request headers Authentication flow:\nSign user in Post authentication Establish authenticated session Serve authenticated content In Azure portal, we can also configure App Service when the request is not authenticated:\nAllow unauthenticated requests Require authentication with Http 401/403 Networking features Sometimes we need to control the inbound and outbound network traffic. And features of inbound and outbound cannot be used to each other.\nInbound features Outbound features App-assigned address Hybrid Connections Access restrictions Gateway-required virtual network integration Service endpoints Virtual network integration Private endpoints But we can mix some features to solve the problems with a few exceptions.\nInbound use case Feature Support IP-based SSL needs for your app App-assigned address Support unshared dedicated inbound address for your app App-assigned address Restrict access to your app from a set of well-defined addresses Access restrictions Scale apps in Azure App Service Target Learn how autoscale operates in App Service and how to identify autoscale factors, enable autoscale, and how to create sound autoscale conditions.\nAutoscale factors Autoscaling can be triggered by defined rules and also deallocate resources when workload has diminished.\nAzure provides two options for autoscaling:\nScale based on a metric, like: CPU Percentage. Memory Percentage. Disk Queue Length. Http Queue Length. Data In. Data Out. Scale to a specific instance count according to a schedule. For example, you can arrange to scale out at a particular time of day, or on a specific date or day of the week. You also specify an end date, and the system will scale back in at this time. Azure App Service deployment slots Target In this module you will learn how slot swapping operates and how to perform a swap. You will also learn how to route traffic to different slots manually and automatically.\nExplore staging environments Deployment slot is supported in the Standard, Premium, or Isolated App Service plan tier.\nThe benefits to have the non-production deployment slot is\nvalidate the app changes in the staging environment Deploy an app and swap with production deployment can eliminate the downtime Easy to swap back to the last good site if the swapped one is not as we expected Develop for Azure Cache for Redis Target Learn how to configure Azure Cache for Redis, interact with the cache, and connect an application to Azure Cache for Redis by using .NET.\nScenarios Pattern Description Data cache Databases are often too large to load directly into a cache. It's common to use the cache-aside pattern to load data into the cache only as needed. When the system makes changes to the data, the system can also update the cache, which is then distributed to other clients. Content cache For static content for template. We can use in-memory cache to provide quick access Session store Commonly used in shopping carts or user history data that might associate with cookie. But the data is too large for cookie. We can use Cookie as a key to query the data in in-memory cache, to associate information with a user quickly. Job and message queuing Applications often add tasks to a queue when the operations associated with the request take time to execute. Longer running operations are queued to be processed in sequence, often by another server. This method of deferring work is called task queuing. Distributed transactions Azure Cache for Redis supports executing a batch of commands as a single transaction. Configuration Recommend always use Standard or Premium Tier for production system.\nWith Premium tier, you get supports:\nVirtual Network Clustering The access key is like the password to cache. There are a primary and a secondary key, we can use either, but we should update the key periodically.\nImplement Azure Key Vault Target Learn how Azure Key Vault can help you keep your apps more secure, and how to set and retrieve secrets by using the Azure CLI.\nExplore Azure Key Vault The Azure Key Vault service supports two types of containers: vaults and managed hardware security module(HSM) pools.\nAzure Key vault would manage:\nSecrets - tokens, passwords, certificates, API keys, and other secrets Key - encryption keys used to encrypt your data. Certificate - public and private Secure Sockets Layer/Transport Layer Security (SSL/TLS) certificates A Premium tier would include hardware security module(HSM)-protected keys.\nBenefites:\nCentralized application secrets Securely store secrets and keys Monitor access and use Simplified administration of application secrets Best Practices:\nUse separate key vaults: Recommended to use a vault per application per environment (Development, Pre-Production and Production).\nControl access to your vault: Key Vault data is sensitive and business critical, you need to secure access to your key vaults by allowing only authorized applications and users.\nBackup: Create regular back ups of your vault on update/delete/create of objects within a Vault.\nLogging: Be sure to turn on logging and alerts.\nRecovery options: Turn on soft-delete and purge protection if you want to guard against force deletion of the secret.\nAuthenticate to Azure Key Vault Authentication with Key Vault works in conjunction with Azure Active Directory, which is responsible for authenticating the identity of any given security principal.\nAccess tokens must be sent to the service using the HTTP Authorization header:\n1PUT /keys/MYKEY?api-version=\u0026lt;api_version\u0026gt; HTTP/1.1 2Authorization: Bearer \u0026lt;access_token\u0026gt; Explore Azure Cosmos DB Target Learn the core features and functionality of Azure Cosmos DB.\nBenefits Unlimited elastic write and read scalability. 99.999% read and write availability all around the world. Guaranteed reads and writes served in less than 10 milliseconds at the 99th percentile. Explore the resource hierarchy hierarchy of different entities in an Azure Cosmos DB account\nCosmos entities An Azure Cosmos database is mapped to various API-specific entities:\nAzure Cosmos entity SQL API Cassandra API Azure Cosmos DB API for MongoDB Gremlin API Table API Azure Cosmos database Database Keyspace Database Database N/A The mapping of API-specific entities to an Azure Cosmos item:\nCosmos entity SQL API Cassandra API Azure Cosmos DB API for MongoDB Gremlin API Table API Azure Cosmos item Item Row Document Node or edge Item Consistency With Azure Cosmos DB, developers can choose from five well-defined consistency models on the consistency spectrum. From strongest to more relaxed, the models include:\nstrong bounded staleness session consistent prefix eventual Five Consistency Levels TBC Explore the Microsoft identity platform Target Learn the core features and functionality of the Microsoft identity platform which includes authentication service, open-source libraries, and application management tools to enable and control access to resources.\nComponents Microsoft identity platform consist of several components:\nOAuth 2.0 and OpenID Connect standard-compliant authentication service enabling developers to authenticate several identity types, including:\nWork or school accounts, provisioned through Azure Active Directory Personal Microsoft account, like Skype, Xbox, and Outlook.com Social or local accounts, by using Azure Active Directory B2C Open-source libraries: Microsoft Authentication Libraries (MSAL) and support for other standards-compliant libraries\nApplication management portal\nApplication configuration API and PowerShell\nService principals An application must be registered with an Azure Active Directory tenant.\nCreate and deploy Azure Resource Manager templates Target Learn how Azure Resource Manager (ARM) can help streamline deployments, choose the correct deployment mode for your solution, and create and deploy an ARM template.\nAzure Resource Manager role Microsoft Graph Target Learn how Microsoft Graph facilitates the access and flow of data and how to form queries through REST and code\nMicrosoft Graph is the gateway to data and intelligence in Microsoft 365. It provides a unified programmability model that you can use to access the tremendous amount of data in Microsoft 365, Windows 10, and Enterprise Mobility + Security.\nThree main components to access and facilitate data:\nThe Microsoft Graph API offers a single endpoint, https://graph.microsoft.com Microsoft Graph connectors Microsoft Graph Data Connect Best practices Consent and authorization:\nUse least privilege Use the correct permission type based on scenarios. Consider the end user and admin experience. Consider multi-tenant applications. Handle responses effectively\nPagination Evolvable enumerations Provision virtual machines in Azure Target Learn the availability and sizing options of Azure Virtual Machines, and how to create a virtual machine by using the Azure CLI.\nExplore Azure virtual machines Design considerations for virtual machine creation:\nAvailability VM size VM limits - The current limit on a per subscription basis is 20 VMs per region VM image VM disks Standard disks - HDDs, deal for a cost effective dev and test workload Premium disks - SSD, Perfect for VMs running production workload. ","link":"https://xfsnowind.github.io/blogs/azure-challenge/","section":"blogs","tags":["Learning Notes","Azure"],"title":"Learning Notes - Azure Challenge"},{"body":"This article is a summary when I learned the React Hooks course in GeekTime. Even though we all use React Hooks in the frontend development, I cannot say I understand the internal core and logic of it. So this is a good time to re-learn it through this course. According to my experience, it's definitely better to write down the idea and thoughts down -- The palest ink is better than the best memory. Therefore have this article. And I would follow the course's original structure to organize the article.\nBasic chapter Reason to Hooks The nature of React is mapping the Model to View and the Model is the Component's props and state. So when Model's data change, React does not care how they change, it only focuses on the difference. And this is what we called declarative and this is implemented by React's diff function.\nSo UI presentation is more like execution of function. Model is parameter, View is function and the result would be the Dom's change. React just confirms to execute the process of changing in an optimized way.\nBefore we use class to create React Component, but actually it's not suit for React Component:\nWe rarely use inheritance in React Component; React is state driven and does not need generated instance's methods; But function also has its own limitation:\nFunction cannot provide internal state, it must be a pure function; Function cannot provide the entire lifecycle; The comes React Hooks.\nReact Hooks \u0026quot;binds\u0026quot; or \u0026quot;hooks\u0026quot; the target to some may changed data or event source. And when the hooked data or event change, the target would be executed again to generate the new result.\nThe hooked source can be not only data, also the result of another Hooks execution.\nHooks is created with the background of using High order Component, and it solves the problems of wrapper hell and code hard to understanding.\nHooks basic usage useState -- The principle of using useState is unnecessary to save the value which can be gotton from calculating. useEffect -- Should only be used to execute the code which would not effect the current result, not effect the rendered UI. And also be careful for the deps, it use reference to check if values have been changed, so take care of object and array. NB: useEffect is called after rendering useCallback -- The purpose is when need to pass function as parameter to UI, avoid triggering React render component. useMemo -- can be treated as combination of useEffect and useState. When deps change, execute useEffect to calculate the value and set the value through useState useRef Share data between multiple rendering Save the ref of a Dom node useContext -- define the global state useEffect can be equivalent to componentDidMount, componentDidUpdate and componentWillUnmount, but not exactly. The difference is\nuseEffect's callback functions are triggered only when deps change. While componentDidUpdate would be called every rendering useEffect's callback function return a function, which is used to clean, would be triggered before deps change or component unmount. If we need a constructor feature, we can use the code below:\n1function useSingleton(callback) { 2 //  called ref  callback  3 const called = useRef(false); 4 //  5 if (called.current) return; 6 //  7 callBack(); 8 //  9 called.current = true; 10} NB: Hooks can implement most functionalities of lifecycle, but not for getSnapshotBeforeUpdate, componentDidCatch, getDerivedStateFromError. These can only be implemented by class.\nPractice Data consistence The principle of using useState is keep state minimum.\nIf the data can be calculated or generated by the existing ones, then we should not store them in state.\nWhen we define the new state, ask yourself: is this state necessary? Can it be obtained by calculation? Is it just a middleware state?\nHandle rendering scenario Since Hooks cannot be handled in conditions and loops, we should move the condition into useEffect og create a wrapper for the component and return null in some conditions.\nAlthough we have Hooks now, it can only be used for logical reuse. If it comes to the UI behaviour, Hooks cannot play a role then. Therefore, we can use Render props mode.\nRender props Mode is just another presentation of High-ordering Component, which means Component takes functions as paramter or return functions. And then we can use the passed function to render, kind of like dependency injection. For example:\n1function CounterRenderProps({ children }) { 2 const [count, setCount] = useState(0); 3 const increment = useCallback(() =\u0026gt; { 4 setCount(count + 1); 5 }, [count]); 6 const decrement = useCallback(() =\u0026gt; { 7 setCount(count - 1); 8 }, [count]); 9 10 return children({ count, increment, decrement }); 11} 12 13function CounterRenderPropsExample() { 14 return ( 15 \u0026lt;CounterRenderProps\u0026gt; 16 {({ count, increment, decrement }) =\u0026gt; { 17 ... 18 }} 19 \u0026lt;/CounterRenderProps\u0026gt; 20 ); 21} So we leave children to render to make code reusable. Here, it does not have to be children, it can be any functions.\nSelf defined event When we bind an event to a node, because of Virtual Dom, React would bind the event to the app's root node. Before version 17, it's on document, after version 17, it's the react's root node. The reason to do this:\nWhen Virtual Dom renders, the node may have not been mounted to the page, so it cannot bind; It can block all the details from low level and avoid browser's compatible problem So React's event actually is the callback function.\nOrganize project structure via business To reduce the complexibility, we can organize the project based on service characteristic, so each feature can be independent and easy to manage and maintain.\nTo meet the requirement of low coupling, we can define some high level, abstract components to be reused among components.\nForm React is state driven, while Form is event driven The difference of React's onChange and html's onchange is onChange would be called whenever user inputs, while onchange is only triggered when the input loses focus.\nControlled vs uncontrolled For uncontrolled component, it would not pass the value to component, can only get the value actively, like useRef. The advantage is it would not toggle the rendering, although we cannot see the change of value as well.\nWhile for controlled component, it accepts value as props and add a callback function to update it.\nForm elements If we use Controlled component to build form, it would have three core parts:\nthe type of form element bind the value handle the onChange event So Hooks' contribution to form is, we can save the form's values to Hooks and provide the function to handle them through useState. For example:\n1import { useState, useCallback } from \u0026#34;react\u0026#34;; 2 3const useForm = (initialValues = {}) =\u0026gt; { 4 // define the state for the whole formvalues 5 const [values, setValues] = useState(initialValues); 6 7 // provide a method to set the value of some field 8 const setFieldValue = useCallback((name, value) =\u0026gt; { 9 setValues((values) =\u0026gt; ({ 10 ...values, 11 [name]: value, 12 })); 13 }, []); 14 15 // return the values and the method 16 return { values, setFieldValue }; 17}; ","link":"https://xfsnowind.github.io/blogs/geektime/react-hooks/","section":"blogs","tags":["Javascript","React Hooks","Learning Notes"],"title":"Learning Notes - React Hooks"},{"body":"","link":"https://xfsnowind.github.io/tags/react-hooks/","section":"tags","tags":null,"title":"React Hooks"},{"body":"","link":"https://xfsnowind.github.io/tags/promise/","section":"tags","tags":null,"title":"Promise"},{"body":"Promise is a general concept to handle the asynchronize development in javascript. It's not hard to use, but when it comes with some other concepts, like react's hook, its internal chain etc. It always takes me some time to think through it. Especially when check the code of some open-source libraries, find the way they use Promise is quite fancy and also hard to understand, which reminders me that I am still stay on the level of using, far away from deep understanding.\nInspired by this blog, I think it's a good idea to write promise by myself. It's not only because it's not that hard and complex, it can also help me in the future work when I meet it again. Thesedays, function programing is quite popular in js development, but object-orient coding is still used in lots of scenarioes. So I would like to try to implement it with both function and class, even though javascript's prototype is almost equal to class concept, which was introduced in ES2015. It can also train these basic skills again. I would deploy them in my github and write blogs to record it.\nThanks to promise/A+, we get the requirement analysis, clear logic and library to test the solution.\nSteps According to the Promise/A+'s requirements, I think it would be four steps:\nBasic then function -- 1.1, 1.2 Fulfill Promise and then parameters -- from 2.1 to 2.2.5 Return a Promise in then -- 2.2.6, 2.2.7 resolve function -- 2.3 Basic thenable According to the Terminology, the first two are promise and thenable. The former should take a function (an executor) as parameter which would take two functions (resolve and reject) as parameters as well. Check Higher-order functions. These resolve and reject would be used in the executor and defined in the then's parameters. Let's simply implement this thenable first.\n1function Promise(executor) { 2 let self = this; 3 self.executor = executor; 4} 5 6Promise.prototype.then = function (onFulfilled, onRejected) { 7 let self = this; 8 self.executor(onFulfilled, onRejected); 9}; As we see, we just delay the execution of executor from Promise to then and the fulfill and reject functions are used in executor while defined or passed in then.\nWe can use below code to test it. NB: do not use arrow function in definition, because arrow function does not own this. If we use this inside of it, it would refer to the outer function. Check here.\n1const a = new Promise((resolve) =\u0026gt; setTimeout(() =\u0026gt; resolve(\u0026#34;result\u0026#34;), 100)); 2 3a.then((data) =\u0026gt; console.log(\u0026#34;Data\u0026#34;, data)); 4// console.log -\u0026gt; Data: result But obviously here, we only have one executor and the parameters are not validated. Besides executor runs in the then, not in the Promise. Currently, the code is simple, but it would cause problems. We will mention this below, let's go further.\nFulfill Promise and then parameters Validate then parameters 2.2.1 Both onFulfilled and onRejected are optional arguments:\n2.2.1.1 If onFulfilled is not a function, it must be ignored.\n2.2.1.2 If onRejected is not a function, it must be ignored.\nonFulfilled and onRejected should be validated:\n1let fulfillFunc = isFunction(onFulfilled) ? onFulfilled : (value) =\u0026gt; value; 2let rejectFunc = isFunction(onRejected) 3 ? onRejected 4 : (e) =\u0026gt; { 5 throw e; 6 }; Update state After validating the parameters, we can implement the point 2.2.2 and 2.2.3. Translate here:\nIf onFulfilled/onRejected is a function,\nit must be called after promise is fulfilled/rejected, with promise's value/reason as its first argument;\nit must not be called before promise is fulfilled/rejected;\nit must not be called more than once;\nSo we need to set the state and pass the value or reason to related functions. To do this, I wrap the validated functions and update internal states inside of them:\n1// 2.2.2.1 onFulfilled must be called after promise is fulfilled, with promises value as its first argument. 2function resolve(value) { 3 if (self.state === STATE.PENDING) { 4 // 2.2.2.2 it must not be called before promise is fulfilled. 5 self.state = STATE.FULFILLED; 6 self.value = value; 7 fulfillFunc(value); 8 } 9} 10 11// 2.2.3.1 onRejected must be called after promise is rejected, with promises reason as its first argument. 12function reject(err) { 13 if (self.state === STATE.PENDING) { 14 // 2.2.3.2 it must not be called before promise is rejected. 15 self.state = STATE.REJECTED; 16 self.value = err; 17 rejectFunc(err); 18 } 19} Asynchronized execution According to the first point 2.2.4 refering NOTE 3.1, we should execute the fulfill and reject functions asynchronously, which is the main reason for people using it. In javascript, we can utilize setTimeout.\n1setTimeout(() =\u0026gt; fulfillFunc(value), 0); Return Promise in then Before we continue implementing the rest requirement, we need to reorganize the codes first. We need to move the executor from then to the constructor of Promise.\nWhy? One main reason is we will execute the executor multiple times if it's in then, since one promise can have multiple thens. This is definitely unacceptable because we only need to execute executor once.\nSo til now, the Promise function looks like this:\n1function Promise(executor) { 2 let self = this; 3 4 // set the state as pending, 2.1.1 5 self.state = STATE.PENDING; 6 7 // 2.2.2.1 onFulfilled must be called after promise is fulfilled, with promises value as its first argument. 8 function resolve(value) { 9 if (self.state === STATE.PENDING) { 10 // 2.2.2.2 it must not be called before promise is fulfilled. 11 self.state = STATE.FULFILLED; 12 self.value = value; 13 setTimeout(() =\u0026gt; resolveFunc(value), 0); 14 } 15 } 16 17 // 2.2.3.1 onRejected must be called after promise is rejected, with promises reason as its first argument. 18 function reject(err) { 19 if (self.state === STATE.PENDING) { 20 // 2.2.3.2 it must not be called before promise is rejected. 21 self.state = STATE.REJECTED; 22 self.value = err; 23 setTimeout(() =\u0026gt; rejectFunc(err), 0); 24 } 25 } 26 27 try { 28 // executor is function whose parameters is resolve and reject functions, 29 // which would be called inside of executor. 30 if (isFunction(executor)) executor(resolve, reject); 31 } catch (err) { 32 reject(err); 33 } 34} And you may notice we use the function resolveFunc and rejectFunc, but we haven't define them. They would work together with the requirement of multiple calling of then.\nCall then mutiple times 2.2.6 2.2.6 then may be called multiple times on the same promise.\nSo all the respective fulfill/reject functions should be called in the order of original calls. Obviously, we can apply a queue here. Create a callback queue, add then's onFulfilled and onRejected parameters to it and handle it when fulfilled/rejected. And this is how we handle the above resolveFunc and rejectFunc.\n1function resolve(value) { 2 ... 3 // 2.2.6.1 4 setTimeout( 5 () =\u0026gt; self.callback.forEach(({ resolveFunc }) =\u0026gt; resolveFunc(value)), 6 0 7 ); 8} 9 10function reject(err) { 11 ... 12 // 2.2.6.2 13 setTimeout( 14 () =\u0026gt; self.callback.forEach(({ rejectFunc }) =\u0026gt; rejectFunc(err)), 15 0 16 ); 17} When Promise is fulfilled/rejected, we would execute all the related functions in the queue. And obviously, we have to push the callback functions to the queue in then when the state is still pending.\n1Promise.prototype.then = function (onFulfilled, onRejected) { 2 let self = this; 3 4 // 2.2.1 Both onFulfilled and onRejected are optional arguments, if any is not function, must ignore it 5 let fulfillFunc = isFunction(onFulfilled) ? onFulfilled : (value) =\u0026gt; value; 6 let rejectFunc = isFunction(onRejected) 7 ? onRejected 8 : (e) =\u0026gt; { 9 throw e; 10 }; 11 12 switch (self.state) { 13 // if the state is fulfilled or rejected, just execute the related function and pass the result to the resolvePromise 14 case STATE.FULFILLED: 15 case STATE.REJECTED: 16 return setTimeout(() =\u0026gt; { 17 try { 18 let func = self.state == STATE.FULFILLED ? fulfillFunc : rejectFunc; 19 func(self.value); 20 } catch (e) { 21 rejectFunc(e); 22 } 23 }, 0); 24 case STATE.PENDING: 25 // if it\u0026#39;s still pending, push the resolve/reject to callback queue. All the callback functions would be executed once state are changed 26 return self.callback.push({ 27 resolveFunc: () =\u0026gt; { 28 try { 29 fulfillFunc(self.value); 30 } catch (e) { 31 rejectFunc(e); 32 } 33 }, 34 rejectFunc: () =\u0026gt; { 35 try { 36 rejectFunc(self.value); 37 } catch (e) { 38 rejectFunc(e); 39 } 40 }, 41 }); 42 } 43}; Return Promise 2.2.7 Here comes the difficult part, then should return a Promise which would support the chaining feature.\nthen must return a promise [3.3].\npromise2 = promise1.then(onFulfilled, onRejected);\nAfter reading other implementations, here comes a question. Would this promise2 have its own executor? Yes or no would have different implementations.\nLet's first implement the simple one - Yes. It would have its own resolve/reject functions in executor. I would implement the optimized one -- No, with an empty promise, in another blog.\nAnother thing we need to think of is what if the value returned by promise2 is a promise. This is what the 2.3 Promise Resolution Procedure would do. Let's preserve this to later chapter and assume the value returned by promise2 is NOT another promise Then the logic of this promise2's executor should be:\nIf the state is fulfilled, the value returned by the onFulfilled function should be passed to resolve2 function in promise2's executor If the state is rejected, the value returned by the onRejected function should be passed to reject2 function in promise2's executor If the state is still pending, pass the resolveFunc and rejectFunc which would call resolve2 and reject2, to callback queue Any exception throwed by onFulfilled or onRejected should be handled by reject2 And we can extract the process of handling self.value as a function to reuse code.\n1function handleResult(resolve2, reject2) { 2 return () =\u0026gt; { 3 try { 4 // 2.2.7.1, 2.2.7.2 5 let func = self.state == STATE.FULFILLED ? fulfillFunc : rejectFunc; 6 let func2 = self.state == STATE.FULFILLED ? resolve2 : reject2; 7 func2(func(self.value)); 8 } catch (e) { 9 reject2(e); 10 } 11 }; 12} Til now, we have implement the features\nReturn Promise in then to support chaining Multiple then of one Promise The codes should be like this:\n1const STATE = { 2 PENDING: Symbol.for(\u0026#34;pending\u0026#34;), 3 FULFILLED: Symbol.for(\u0026#34;fulfilled\u0026#34;), 4 REJECTED: Symbol.for(\u0026#34;rejected\u0026#34;), 5}; 6 7const isFunction = (func) =\u0026gt; func \u0026amp;\u0026amp; typeof func === \u0026#34;function\u0026#34;; 8const isObject = (arg) =\u0026gt; arg \u0026amp;\u0026amp; typeof arg === \u0026#34;object\u0026#34;; 9 10function Promise(executor) { 11 let self = this; 12 13 // set the state as pending, 2.1.1 14 self.state = STATE.PENDING; 15 16 self.callback = []; 17 18 // 2.2.2.1 onFulfilled must be called after promise is fulfilled, with promises value as its first argument. 19 function resolve(value) { 20 if (self.state === STATE.PENDING) { 21 // 2.2.2.2 it must not be called before promise is fulfilled. 22 self.state = STATE.FULFILLED; 23 self.value = value; 24 // 2.2.6.1 25 setTimeout( 26 () =\u0026gt; self.callback.forEach(({ resolveFunc }) =\u0026gt; resolveFunc(value)), 27 0 28 ); 29 } 30 } 31 32 // 2.2.3.1 onRejected must be called after promise is rejected, with promises reason as its first argument. 33 function reject(err) { 34 if (self.state === STATE.PENDING) { 35 // 2.2.3.2 it must not be called before promise is rejected. 36 self.state = STATE.REJECTED; 37 self.value = err; 38 // 2.2.6.2 39 setTimeout( 40 () =\u0026gt; self.callback.forEach(({ rejectFunc }) =\u0026gt; rejectFunc(err)), 41 0 42 ); 43 } 44 } 45 46 try { 47 // executor is function whose parameters is resolve and reject functions, 48 // which would be called inside of executor. 49 if (isFunction(executor)) executor(resolve, reject); 50 } catch (err) { 51 reject(err); 52 } 53} 54 55Promise.prototype.then = function (onFulfilled, onRejected) { 56 let self = this; 57 58 // 2.2.1 Both onFulfilled and onRejected are optional arguments, if any is not function, must ignore it 59 let fulfillFunc = isFunction(onFulfilled) ? onFulfilled : (value) =\u0026gt; value; 60 let rejectFunc = isFunction(onRejected) 61 ? onRejected 62 : (e) =\u0026gt; { 63 throw e; 64 }; 65 66 function handleResult(resolve2, reject2) { 67 return () =\u0026gt; { 68 try { 69 // 2.2.7.1, 2.2.7.2 70 let func = self.state == STATE.FULFILLED ? fulfillFunc : rejectFunc; 71 let func2 = self.state == STATE.FULFILLED ? resolve2 : reject2; 72 func2(func(self.value)); 73 } catch (e) { 74 reject2(e); 75 } 76 }; 77 } 78 79 return new Promise((resolve2, reject2) =\u0026gt; { 80 switch (self.state) { 81 // if the state is fulfilled or rejected, just execute the related function and pass the result to the resolvePromise 82 case STATE.FULFILLED: 83 return setTimeout(handleResult(resolve2, reject2), 0); 84 case STATE.REJECTED: 85 return setTimeout(handleResult(resolve2, reject2), 0); 86 case STATE.PENDING: 87 // if it\u0026#39;s still pending, push the resolve/reject to callback queue. All the callback functions would be executed once state are changed 88 return self.callback.push({ 89 resolveFunc: handleResult(resolve2, reject2), 90 rejectFunc: handleResult(resolve2, reject2), 91 }); 92 } 93 }); 94}; Let's simply test it:\n1const p1 = new Promise((resolve, reject) =\u0026gt; { 2 setTimeout(() =\u0026gt; resolve(\u0026#34;resolved first one\u0026#34;), 3000); 3}); 4 5p1.then((res) =\u0026gt; { 6 console.log(\u0026#34;then1: \u0026#34;, res); 7 return res; 8}).then((res) =\u0026gt; { 9 setTimeout(() =\u0026gt; console.log(\u0026#34;then2: \u0026#34;, res), 1000); 10}); 11 12p1.then((res) =\u0026gt; { 13 console.log(\u0026#34;another then: \u0026#34;, res); 14}); 15 16// then1: resolved first one 17// another then: resolved first one 18// then2: resolved first one Promise Resolution Procedure 2.3 Here comes the last step, implement the Promise Resolution Procedure. According to the description of requirement:\nThis treatment of thenables allows promise implementations to interoperate, as long as they expose a Promises/A+-compliant then method. It also allows Promises/A+ implementations to assimilate nonconformant implementations with reasonable then methods.\nAnd before we begin to implement, let's think of why we have to have this resolvePromise, since it calls itself inside recursively. Comparing the text explanation, let me present one test case from Promise/A+. The case is generated by two loops, I just pick one here.\nAdapter In the test case, an adapter is utilized and explained in the Promise/A+ as well, check adapter;\n1Promise.defer = Promise.deferred = function () { 2 let dfd = {}; 3 dfd.promise = new Promise((resolve, reject) =\u0026gt; { 4 dfd.resolve = resolve; 5 dfd.reject = reject; 6 }); 7 return dfd; 8}; 9 10adapter.resolved = function (value) { 11 var d = adapter.deferred(); 12 d.resolve(value); 13 return d.promise; 14}; Definitely, we have seen this resolved many times, but what it does exactly? Through its code, we can understand it\nCreate a promise with a very simple executor which normally executes the logic of asynchronous codes Resolve the promise with the value immediately by updating state and saving the value before we have this resolve method Return this created promise So for the code resolved(value), actually it just preserves the value and waiting the resolve method from its then. When its then is called, the value would be passed to resolve method immediately.\nTest case The test case's description is\ny is an already-fulfilled promise for a synchronously-fulfilled custom thenable, then calls resolvePromise synchronously\nAnd I can simplify the test code, removing all the wrapped test functions:\n1const result = { result }; 2 3var promise = resolved({ dummy }).then(function onBasePromiseFulfilled() { 4 return { 5 then: function (resolvePromise) { 6 resolvePromise( 7 resolved({ 8 then: function (onFulfilled) { 9 onFulfilled(result); 10 }, 11 }) 12 ); 13 }, 14 }; 15}); 16 17promise.then(function onPromiseFulfilled(value) { 18 assert.strictEqual(value, result); 19 done(); 20}); Yes, HHHHHHHHeadache!!!!\nDefinitely there are a lot of promises wrapped like matryoshka doll, and so hard to dig into it. Yes, I know, but we can analysis the codes step by step, at leas we can simply count how many promises are here:\nresolved({ dummy }) uses resolved. As explained above, it returns a resolved promise and waits for the resolve method from its then. Let's call this promise as promise-TEMP; promise-TEMP called then which passes the function onBasePromiseFulfilled as resolve. AND it returns our first promise -- promise onBasePromiseFulfilled return a thenable object as value of promise. Let's call it x; x, which we can simply treat it as a Promise as well -- promise2, has the then function which would call its parameter resolvePromise further. The called value would be the value of promise2. Let's call it y; The value passed to resolvePromise is another resolved promise -- promise3, which is fulfilled and has no resolve method. But its value is another thenable object -- or promise4; Finally we reach the bottom level, the resolve method onFulfilled of promise4's then calls the result; So let's count how many promises and values we have here (ignore the promise-TEMP):\npromise -- the only one having name in our test codes its value x -\u0026gt; promise2 promise2 -- first thenable object its value y -\u0026gt; promise3 promise3 -- a resolved promise its value -\u0026gt; promise4 promise4 -- second thenable object its value -\u0026gt; result, an object So we can see the value of promise is a promise -- promise2 which wraps another two promises -- promise3 and promise4. And the assert sits inside of the resolve onPromiseFulfilled method of the first promise, it would expect the value returned by onPromiseFulfilled to be the same with result, which is the value of promise4.\nWe can conclude some points here:\nThe thenable object can be treated as a promise, which means they can be handled as the same codes. (This is not a principle, we can discuss this in another blog) If the value of a promise is a thenable object, the promise's resolve/reject methods would be passed to the value until the final value is not a promise and handled by the original resolve/reject methods. Implementation OK, it's enough to learn from the test case, even though it's what I learned after I passed all the test cases. Let's go back to the requirements and implement it.\nSince thenable object can be treated as promise, we would ignore the requirement of 2.3.2:\n2.3.2 If x is a promise, adopt its state [3.4]:\n2.3.2.1 If x is pending, promise must remain pending until x is fulfilled or rejected.\n2.3.2.2 If/when x is fulfilled, fulfill promise with the same value.\n2.3.2.3 If/when x is rejected, reject promise with the same reason.\nThis point can be merged with 2.3.3. Others would not be hard, just follow the steps:\n1function resolvePromise(promise, x, resolve2, reject2) { 2 if (promise == x) { 3 return reject2( 4 new TypeError(\u0026#34;Resolved result should not be the same promise!\u0026#34;) 5 ); 6 } else if (x \u0026amp;\u0026amp; (isFunction(x) || isObject(x))) { 7 let called = false; // 2.3.3.3.3 8 9 try { 10 let then = x.then; 11 12 if (isFunction(then)) { 13 then.call( 14 // 2.3.3.3 15 x, 16 function (y) { 17 if (called) return; // 2.3.3.3.3 18 called = true; 19 return resolvePromise(promise, y, resolve2, reject2); // 2.3.3.3.1 20 }, 21 function (r) { 22 if (called) return; 23 called = true; 24 return reject2(r); // 2.3.3.3.2 25 } 26 ); 27 } else { 28 resolve2(x); // 2.3.3.4 29 } 30 } catch (err) { 31 if (called) return; // 2.3.3.3.4.1 32 called = true; 33 reject2(err); // 2.3.3.3.4.2 34 } 35 } else { 36 resolve2(x); // 2.3.4 37 } 38} Test Now we have implemented all the mandatory codes, we can run the test the codes with npm lib promises-aplus-tests.\n1npm i -g promises-aplus-tests 2promises-aplus-tests promise1.js // promise1.js is the file name The full code can be checked here. There are different versions with different techniques, you can choose anyone.\nSummary This solution is not perfect and it just simply follows the rules of Promise/A+ without any better architecture and design. There are a lot of good solutions which restructures the codes with their own idea and logic. I would rewrite the promise with other techniques later.\nBesides, this version just completes the basic part. Promise also has resolve, catch, finally, etc. I will implement them as well and write another article about them.\nThanks to this article, which inspires me to make decision to implement the Promise and Zhi Sun's article, which reminders me of taking steps to implement the hard part.\n---------------------- UPDATE ----------------------\nInstead prototype, I have implemented the Promise with javascript class, which is not the feature of ES5, therefore, we need to compile it with babel and test with nodejs. And the code logic is almost the same with the version 1. Here is the code.\nThere are two things we need to take care when using class:\nWhen we pass the #internalResolve/#internalReject functions which are defined as class private methods, to executor, we need to use bind to bind the function with class's instance or this, since we use this inside of #internalResolve/#internalReject. Codes are: 1constructor(executor) { 2 try { 3 executor( 4 this.#internalResolve.bind(this), 5 this.#internalReject.bind(this) 6 ); 7 } catch (err) { 8 this.#internalReject(err); 9 } 10} 11 12#internalResolve(value) { 13 if (this.#state == STATE.PENDING) { 14 // ... 15 } 16} 17 18#internalReject(reason) { 19 if (this.#state == STATE.PENDING) { 20 //... 21 } 22} Be careful for this especially when we create functions inside of class methods. It's best to define a variable and assign this to it, like self. ","link":"https://xfsnowind.github.io/blogs/promise/","section":"blogs","tags":["Javascript","Promise"],"title":"Promise implementation"},{"body":"The techniques and some project I plan to learn or finish:\ngRPC vs REST -- get some knowledge of gRPC Esbuild, vite, svelte -- understand the difference of vite and esbuild, apply esbuild for develop and webpack for production webpack hotload ES6 ES7 -- get overview of ES6 and ES7 Command kitty -- get familiar with kitty material design -- get to know how to use material design Flutter vs React Native -- get some overview of mobile development React-hook form website with react, redux -- use react-hook-form to generate a full form again and deploy Hugo personal github page -- xfsnowind React long lists -- react-window, react-virtual-window Go through test framework of js, jest, react-testing-library -- review the test library of js Blog for learning geektime -- learning some topics throught geektime http headers -- go through the http headers to get an overview Regular express forward -- deep learn the regex forward again Terraform -- get knowledge of it Promise -- write promise self with different js tech until not forget it any more Kubernetes Folderflip and version 2 Google map knowledge Monorepo vs polyrepo Micro Frontend - module federation, single-spa ","link":"https://xfsnowind.github.io/blogs/learning-plan/","section":"blogs","tags":null,"title":"Learning Plan"},{"body":"I am a full stack developer and I would record some technical ideas and articles here. And it may also post some flash time in life.\n","link":"https://xfsnowind.github.io/about/","section":"","tags":null,"title":"About"},{"body":"","link":"https://xfsnowind.github.io/categories/","section":"categories","tags":null,"title":"Categories"},{"body":"","link":"https://xfsnowind.github.io/series/","section":"series","tags":null,"title":"Series"}]