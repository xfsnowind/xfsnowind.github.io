[{"body":"","link":"https://xfsnowind.github.io/blogs/","section":"blogs","tags":null,"title":"Blogs"},{"body":"","link":"https://xfsnowind.github.io/tags/javascript/","section":"tags","tags":null,"title":"Javascript"},{"body":"","link":"https://xfsnowind.github.io/tags/learning-notes/","section":"tags","tags":null,"title":"Learning Notes"},{"body":"It has been a while after React published its new webiste, I would write down what I learnt from the new webiste.\nDescribe the UI List Key I know this is an old issue, but I used to use index as the key of list. To summarize it, I will note the correct way to use the key:\nWhy do we have to use key for the list item? Because the item in the list could be modified, such as insert, deleted or re-sorted, so the React need to know which item the component is responible to. Why do we cannot use index as the key? If the list is not changed, it would be fine to use index as the key. But if we have the modificaiton operation to the list, like add, insert, delete or resort, React would be confused. Why do we cannot use a random (non-duplicated) number as the key? Because with random new generated key, it would violate the reason React uses key. React would not know the item components it used to render and has to recreate all the related components and DOMs, which is not only slow, but also lose all the user inputs. So the principles to use key are:\nIt should be unique within the list locally, unnecessary to be globally Use the data which is unique naturally Do not change the key value accross rendering, it should be persistant. Think in React with lifecycle Actually, I used to have a question: why the local variable inside of a component would not be updated when I changed it, like this:\n1export default function Gallery() { 2 let index = 0; 3 4 function handleClick() { 5 index = index + 1; 6 } 7 8 let sculpture = sculptureList[index]; 9 return ( 10 \u0026lt;\u0026gt; 11 \u0026lt;button onClick={handleClick}\u0026gt; 12 Next 13 \u0026lt;/button\u0026gt; 14 \u0026lt;h3\u0026gt; 15 ({index + 1} of {sculptureList.length}) 16 \u0026lt;/h3\u0026gt; 17 \u0026lt;p\u0026gt; 18 {sculpture.description} 19 \u0026lt;/p\u0026gt; 20 \u0026lt;/\u0026gt; 21 ); 22} When we click on the button, the variable sculpture is not updated based on the index. So why? The reason for this is I only consider the native javascript, not taking one point knowledge of the frontend development into account. This knowledge is the rendering. React will render the component to the DOM and it uses the hooks to save the internal variables or states among the renderings. So either this local variable index will be recreated during each rendering which causes the click action useless, or updating the index value would not trigger the rendering which may reflect the updated value to the DOM.\nSo although we understand this, where does React save the internal states? Actually, React just save all the hooks in an internal array, and all the hooks would be identified by its index value. So this is also why the hooks can only be defined in the top level of component and cannot be used conditionally. Because if we do that, React would not be able to find the previous correct hooks.\nThen we would rethink the useState hook. The second setter method returned by this hook will theoritically trigger the re-rendering. Everytime it's called, it will inform React to re-render the page and read the state value.\nBatching Batching means the UI will not be updated until the event handler, with codes inside of it, finishes. So if there are multiple setter methods, before the next re-render, all of them will be executed. This is a kind of 'old' new feature, it used to happen that the following setter methods are not executed in React's old version.\nUpdating the state in Object or Array Since Object and array are the reference, not plain variable type, so React would not recognise the changing of the state if you just mutate the member values of them. The correct solution is to create a new one instead of passing the old one to setter method.\nPosition matters Check this official example first\nWe might expect the state to be resetted when we check/uncheck the Use fancy styling checkbox. But it isn't. This is because both of these \u0026lt;Counter /\u0026gt; tags are rendered at the same position. Since this two Counter has the same structure, so React treat them as the same Counter.\nDo remember React's explanation:\nReact will keep the state around for as long as you render the same component at the same position.\nReact preserves a component’s state for as long as it’s being rendered at its position in the UI tree.\nDifferent components in the same position But if there are different components in the same position, React will reset the state of the whole subtree.\nReset state in the same position So how to distinguish the component if we have the same components with different props in the same position? For example, we have a video, and want to change its source url when click one button:\nThe expect behaviour is when we click on the button, video player auto plays the different videos. But it does not happen because the above reason, React applies the same props to the component in the same position. So even though the value isPlayingOne changes, the player does not reload.\nOne imperative solution would be adding a reference to the video element and a useEffect function to the Video component, when the src url changes, we reload the player. Check the code of file ImperativeVideo.tsx.\nAccording to the solutions from React official website, we also have two declarative solutions:\nOne is to render the component in the different positions:\n1\u0026lt;h2\u0026gt;Video with different position\u0026lt;/h2\u0026gt; 2{isPlayingOne \u0026amp;\u0026amp; ( 3 \u0026lt;OriginalVideo 4 src={ 5 \u0026#34;http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4\u0026#34; 6 } 7 /\u0026gt; 8)} 9{!isPlayingOne \u0026amp;\u0026amp; ( 10 \u0026lt;OriginalVideo 11 src={ 12 \u0026#34;http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ElephantsDream.mp4\u0026#34; 13 } 14 /\u0026gt; 15)} The other would be assigning the key to the component, React would recognise the component with the key, check the file VideoWithKey.tsx. The key is only required to be unique within the parent, not globally.\n1\u0026lt;Video 2 key={isPlayingOne ? \u0026#34;one\u0026#34; : \u0026#34;two\u0026#34;} // NOTE: Add this line 3 src={ 4 isPlayingOne 5 ? \u0026#34;http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4\u0026#34; 6 : \u0026#34;http://commondatastorage.googleapis.com/gtv-videos-bucket/sample/ElephantsDream.mp4\u0026#34; 7 } 8/\u0026gt; Context -- sharing state with deep children Normally, we do not use Context that often, only on the top level to pass the theme and Redux's store. One of the reason is it would not be testable for the component and using Context would make the props unpredictable. Actually it's very good to make it clear that the props passed to the component, especially for the person who maintain this explicit data flow component.\nAnd according to the official doc, Context can also be avoided by passing the components as children. Like instead of using \u0026lt;Layout posts={posts} /\u0026gt;, we can make Layout to accept the component as children, \u0026lt;Layout\u0026gt;\u0026lt;Posts posts={posts} /\u0026gt;\u0026lt;/Layout\u0026gt;.\nAbout Effect The main principle of useEffect is it should mainly be used to specify the side effect caused by the rendering or external system, like fetching. There are several things we should not use Effect to do:\nDo not use Effect to calculate data from props and state and call the setter method. The reason for this is it introduces the unnecessary procedure to re-render the page. When the page gets rendered, after it finishes, it will trigger the useEffect method, as we called the setter method in the Effect. With setter method, the page will be re-rendered again.\nCache the expensive data. use useMemo to cache the expensive data instead of calculating every render.\nMostly do not update state according to props change. When you need to do this, re-think of your component in these ways:\ncompute the entire state based on the current state or props, use useMemo when too complicated reset the entire component with using key update the state in the related event handler However, in the rare case, it may still need to update the state from the rendering. Then be careful and remember to update it without in the Effect. Like this official example: 1function CountLabel({ count }) { 2 const [prevCount, setPrevCount] = useState(count); 3 const [trend, setTrend] = useState(null); 4 if (prevCount !== count) { 5 setPrevCount(count); 6 setTrend(count \u0026gt; prevCount ? \u0026#39;increasing\u0026#39; : \u0026#39;decreasing\u0026#39;); 7 } 8 return ( 9 \u0026lt;\u0026gt; 10 \u0026lt;h1\u0026gt;{count}\u0026lt;/h1\u0026gt; 11 {trend \u0026amp;\u0026amp; \u0026lt;p\u0026gt;The count is {trend}\u0026lt;/p\u0026gt;} 12 \u0026lt;/\u0026gt; 13 ); 14} Use Effects only for code that should run because the component was displayed to the user, not user's behaviour. If a logic is shared, instead of creating Effect, think of creating a function for it.\nuse useSyncExternalStore for subscribing to an external store.\nOnly use the reactive variables as dependency list. All the variables inside of the component, including props, states and generated from props and states are reactive, because they are calculated during the rendering and participate in the React data flow. React requires to add these reactive variables in the Effects' dependency list. But the global and mutable values like, location.pathname, ref.current could not be dependencies. Because changing these mutable variables could happen outside of the component and it would not trigger a re-render\nDifference between event handlers and Effects Event handler reacts to user's specific actions, while Effects runs because synchronization is required; Logic inside Event handlers is not reactive, which is mostly triggered by user, while logic inside Effects is reactive since something side effects should happen according to certain reactive values such as props, state changed; Start question to use Effects Should this code be moved to event handler or be an Effect? Is the Effect doing several unrelated things? Several things should splitted to different Effects. Does some reactive value change unintentionally? Are you reading some state to calculate the next state? Move static objects and functions outside your component Move dynamic objects and functions inside your Effect Read primitive values from objects Calculate primitive values from functions useEvent -- an event handler allowing side effects React proposed a RFC hook useEvent to improve the way of using event handler, even though it's not official published yet, we have already use it generally in our codes.\nTo understand the motivation of useEvent, you can check the official explanation or this blog. But here I want to explain the usage of useEvent as event dispatcher and handler.\n1import { useMutation } from \u0026#39;react-query\u0026#39; 2 3const addMutation = useMutation() 4const [internalState, setInternalState] = useState({ contact: \u0026#39;name\u0026#39; }) 5 6const dispatch = useEvent((event) =\u0026gt; eventHandler({event, state: internalState, setState: setInternalState, sideEffects: { addMutation }})) 7 8const eventHandler = ({ event, state, setState, sideEffects: { addMutation }}) =\u0026gt; { 9 10 switch(event) { 11 case \u0026#39;add\u0026#39;: 12 addMutation.mutate(state.contact, { 13 onSuccess: (succcess) =\u0026gt; { 14 setState((prevState) =\u0026gt; ({ 15 ...prevState, 16 success, 17 })) 18 } 19 }) 20 break; 21 default: 22 history.push(\u0026#39;/test\u0026#39;) 23 } 24} 25 26return ( 27 \u0026lt;button onClick={() =\u0026gt; dispatch(\u0026#39;add\u0026#39;)}\u0026gt; 28) So from the above code, I defined a event handler called eventHandler which takes the parameter event from the function passed to the useEvent, the defined variables from useState and the last one sideEffects which I will explain it later. So I named the value returned by the useEvent dispatch, it can be called anywhere except in the rendering. In the codes, I called it when we click on the button.\nIn the defined eventHandler, I check the event type, when it's 'add', I will call the addMutation passed from the parameter sideEffects, and set the state once it succeeds. In the default branch, I want to change the route to the '/test'.\nSo the good thing of using this event handler with useEvent is it moves all the updating logic and side effects operations to the independent method eventHandler, so it's more clear to understand the modification operations since they are moved together and easier to understand. Besides it makes both the component and handler pure and testable. We can of course move this eventHandler to a single file.\nWhy not useReducer? Yes, it comes a question automatically: why don't we use another state dispatcher and handler hook useState, since that seems simpler, at least it's not required to explicitly define the state, pass both state and setter method to the event handler.\n1const [state, dispatch] = useReducer(reducer, initialArg, init) The quick answer is useReducer cannot handle the side effect, since its reducer has to be pure, and return the updated state every time, while eventHandler has more choices, not just setting the state, but also can do the side effects with returning void. So as a event handler, useEvent provides more flexibility to handle the side effects.\n","link":"https://xfsnowind.github.io/blogs/learning-notes-from-new-react-website/","section":"blogs","tags":["Javascript","Learning Notes","React"],"title":"Learning Notes From New React Website"},{"body":"","link":"https://xfsnowind.github.io/tags/react/","section":"tags","tags":null,"title":"React"},{"body":"","link":"https://xfsnowind.github.io/tags/","section":"tags","tags":null,"title":"Tags"},{"body":"","link":"https://xfsnowind.github.io/","section":"","tags":null,"title":"xfsnowind"},{"body":"","link":"https://xfsnowind.github.io/tags/pr-review/","section":"tags","tags":null,"title":"PR review"},{"body":"I do not have a good memory and cannot remember all the mistakes I made in the previous PR reviewing. Since The palest ink is better than the best memory, so let me summarize the mistakes I have made here to reminder myself, hope it may help.\nReact Necessary of useEffect? When we use the useEffect, we need to think about if it's necessary, especially for the initial mount effect. Instead of updating some values based on the dependency of useEffect, we should check if it's possible to set the value initially directly.\nReact-query Use the query data as source of data, instead of triggering/update from UI One example would be undoing the editing to a table item with Material UI's DataGrid. The procedure of undo is\nEdit the table cell text with Material UI's editable function (Imperative) Trigger the undo by clicking somewhere undo button/link (Declarative) Here we have two ways to trigger the undo:\nuse Material UI's method to recover the data in the table and then the data would be updated sequentially 1undoCallback: async () =\u0026gt; { 2 // Undo the process should be fast with update only one field value 3 setUndoStateMap((value) =\u0026gt; ({ ...value, [newRow.id]: key })) 4 // during the undo, use data grid\u0026#39;s way to update the cell value manually 5 await tableApiRef.current.startCellEditMode({ id: newRow.id, field: key }) 6 await tableApiRef.current.setEditCellValue({ 7 id: newRow.id, 8 field: key, 9 value: oldValue, 10 }) 11 // If the cell is in edit mode, stop it 12- if (tableApiRef.current.getCellMode(newRow.id, key) === \u0026#39;edit\u0026#39;) 13- await tableApiRef.current.stopCellEditMode({ id: newRow.id, field: key }) 14} update the table cell data directly and it would be reflected by React automatically 1undoCallback: async () =\u0026gt; { 2 updateKnowTheDriverMutation.mutate({ 3 vehicleId: newRow.vehicleId, 4 category: key, 5 score: oldValue, 6 }) 7}, From the code we can see the second one is better since it's simpler and meets the react's principle declarative way. The imperative way needs to know each step of whole undo processing and it may contribute the mistake.\nThink of the rollback situation when using mutation When we mutate the data, we need to think in this way: if the action fails, do we need to rollback the previous value? Here are the example codes about mutation:\n1onMutate: async (variables) =\u0026gt; { 2 const knowTheDriverQuery = knowTheDriverListQuery() 3 4 // Cancel any outgoing refetches (so they don\u0026#39;t overwrite our optimistic update) 5 await queryClient.cancelQueries(knowTheDriverQuery) 6 7 const previousQueryData = knowTheDriverQuery.getData(queryClient) 8 9 if (previousQueryData) { 10 knowTheDriverQuery.setData(queryClient, { 11 updater: updateFirstWhere( 12 previousQueryData, 13 (c) =\u0026gt; c.vehicleId === variables.vehicleId, 14 // Explicit return type so that we don\u0026#39;t add properties by mistake 15 (c): (typeof previousQueryData)[number] =\u0026gt; ({ 16 ...c, 17 [variables.category]: Number(variables.score), 18 }), 19 ), 20 }) 21 } 22 23 return { previousQueryData } 24}, 25onError: (err, _variables, context) =\u0026gt; { 26 if (context?.previousQueryData) { 27 knowTheDriverListQuery().setData(queryClient, { 28 updater: context.previousQueryData, 29 }) 30 } 31 makeMutationErrorHandlerWithToast().onError(err) 32} Date Send Js native Date to server, it would be serialized automatically and use this as the format in API When we need to send the date to server, no matter what library we use to handle it, Luxon, Moment, etc, we should save the native Date to sever since it's native supported and could be used in all the browsers without supporting from third-part libraries.\nTypescript Parse data from external sources When we get some data which may be arbitrary from external source, we can use zod to parse the value, because Typescript cannot check the values in the runtime.\nFor example, we have a field about filters' initial values in the response of api, and it should have static options:\nvehicle_group_init, department_init, sub_department_init, drivers_init, event_type_init, 1export const apiCoachingDashboardFilterType = z.enum([ 2 \u0026#39;vehicle_group_init\u0026#39;, 3 \u0026#39;department_init\u0026#39;, 4 \u0026#39;sub_department_init\u0026#39;, 5 \u0026#39;drivers_init\u0026#39;, 6 \u0026#39;event_type_init\u0026#39;, 7]) In frontend, we cannot confirm the values sent from backend are correct. So before converting the values, we need to check if they meet our requirements\n1export declare namespace CoachingDashboardFilterType { 2 type ApiInput = { 3 id: z.infer\u0026lt;typeof apiCoachingDashboardFilterType\u0026gt; 4 default: string 5 } 6 type ParsedEvent = { 7 id: \u0026#39;vehicleGroup\u0026#39; | \u0026#39;department\u0026#39; | \u0026#39;section\u0026#39; | \u0026#39;driver\u0026#39; | \u0026#39;eventType\u0026#39; 8 value: string 9 } 10} 11 12export function parseUserSettings() { 13 // ... 14 15 const coachingDashboardFiltersRaw: Array\u0026lt;CoachingDashboardFilterType.ApiInput\u0026gt; = 16 settings.coaching_dashboard_filters 17 18 const coachingDashboardFilters = coachingDashboardFiltersRaw 19 .map((filter) =\u0026gt; { 20 const parsedResult = apiCoachingDashboardFilterType.safeParse(filter.id) 21 if (!parsedResult.success) { 22 return null 23 } 24 const parsed: CoachingDashboardFilterType.ParsedEvent = { 25 id: parsedResult.data, 26 value: `${filter.default}`, 27 } 28 return parsed 29 }) 30 .filter(Re.isNot(Re.isNil)) 31 // ... 32} And when we return the parsed values, instead of returning it directly, we can define a variable as parsed value type. With this, if the input data have some different values in the future, typescript would report it.\n1const parsed: CoachingDashboardFilterType.ParsedEvent = { 2 id: parsedResult.data, 3 value: `${filter.default}`, 4} 5return parsed Form Not recommend to use onChange to update the form field value in react-hook-form When we use the react-hook-form's Controller to\nreact-hook-form's onChange not support Typescript well ","link":"https://xfsnowind.github.io/blogs/pr-review-feedback/","section":"blogs","tags":["PR review","Summary"],"title":"PR Review Feedback"},{"body":"","link":"https://xfsnowind.github.io/tags/summary/","section":"tags","tags":null,"title":"Summary"},{"body":"","link":"https://xfsnowind.github.io/tags/frontend/","section":"tags","tags":null,"title":"Frontend"},{"body":"","link":"https://xfsnowind.github.io/tags/image/","section":"tags","tags":null,"title":"Image"},{"body":"These days when I handle the image in the frontend, there are some concepts make me confusing. How can we handle the image when saving, uploading and transfering the files? So I want to write some notes about the learning processing here.\nWhat is Blob, Buffer, ArrayBuffer and Base64 format? How to convert them among one another? How can they be used with Image? Concept ArrayBuffer ArrayBuffer is an build-in object in Javascript that represents a generic, fixed-length binary data buffer. It can be used to hold raw binary data that can be accessed with types like Int8Array, Unit8Arrray, Float32Array and etc. ArrayBuffer is normally used to work with binary data, such as binary files and sending files over network.\nBut you cannot manipulate the ArrayBuffer data directly, instead, you need a typed array object or DataView object to read or write the content of the buffer.\n1const buffer = new ArrayBuffer(8); 2const view = new DataView(buffer); 3view.setInt16(0, 42); 4view.setFloat32(2, Math.PI); 5console.log(new Uint8Array(buffer)); You can check the detail here\nBlob Blob is the abbreviation of Binary Large OBject. From its name, we can see it's used to save the raw data in the format of binary. And it can also be converted ReadableStream and represent some unusual data like File. It's similar to ArrayBuffer. However, Blob can represent the text and image files. A Blob object can contain the content of data and a MIME type which indicates the type of file.\n1const text = \u0026#39;Hello, world!\u0026#39;; 2const blob = new Blob([text], { type: \u0026#39;text/plain\u0026#39; }); 3console.log(blob); // output: Blob { size: 13, type: \u0026#34;text/plain\u0026#34; } Buffer Buffer is another object in Node.js that represents binary data. It's similar to ArrayBuffer, but it's designed for Node.js and has some additional features.\nBuffer is an object in Node.js that represents a binary data buffer. It is similar to ArrayBuffer, but it is designed for use in Node.js and has some additional functionality. For example, Buffer has methods for encoding and decoding strings, and for copying and slicing buffers.\nBase64 Base64 is a binary-to-text encoding scheme to represent binary data in an ASCII string format with a fixed set of 64 characters, consisting of uppercase and lowercase letters, digits and two additional symbols, '+' and '/'. It's commonly used to encode binary data, like image, audio and video files so that they can be transmitted over network. However, the problem of base64 is it takes an extra 33% data as each block of 3 bytes is represented as 4 characters in Javascript.\nConversion So let's look at how to convert these format with one another.\nBlob \u0026lt;-\u0026gt; ArrayBuffer Blob can be converted to ArrayBuffer with its static method .arrayBuffer:\n1const af = await blob.arrayBuffer() Another way to read Blob is to use a Response. You can read the Blob through the following code:\n1const af = await new Response(blob).arrayBuffer() Blob \u0026lt;-\u0026gt; base64 To convert the Blob to Base64 string, we need to use the FileReader's method readAsDataURL:\n1const convertBase64 = (file: Blob) =\u0026gt; 2 new Promise((resolve, reject) =\u0026gt; { 3 const fileReader = new FileReader(); 4 fileReader.readAsDataURL(file); 5 fileReader.onload = () =\u0026gt; { 6 resolve(fileReader.result); 7 }; 8 fileReader.onerror = (error) =\u0026gt; { 9 reject(error); 10 }; 11 }); 12 13const base64 = await convertBase64(blob) To convert the base64 string to Blob, we need to check the format of the base64 string if it's a file, especially an image file. If it is, we need prepend the content type data.\n1const base64: Response = await fetch(base64Data); 2// or 3const base64Response: Response = await fetch(`data:image/jpeg;base64,${base64Data}`); And then obtain the Blob by Response's method blob:\n1const blob = await base64Response.blob(); Blob \u0026lt;-\u0026gt; Buffer Buffer is Nodejs platform based object, it's mostly used to transfer data. But sometimes we use Blob in the frontend and send to the backend, so we need to convert Blob to Buffer. We have two options to do this:\n1const arrayBuffer = await blob.arrayBuffer(); 2const buffer = Buffer.from(arrayBuffer); Or\n1const buffer = Buffer.from(blob, \u0026#39;binary\u0026#39;); And sometimes, the data sent from frontend is not just a Blob file, it's a File object, a special kind of Blob.\n1const data: Buffer = fs.readFileSync(imageFile.filepath); Base64 \u0026lt;-\u0026gt; Buffer Nodejs Buffer provides a very convenient method to convert from/to these two types:\n1const base64 = Buffer.from(data).toString(\u0026#39;base64\u0026#39;); 2 3const buffer = Buffer.from(b64string, \u0026#39;base64\u0026#39;); Image How are these formats applied when we transfer, display and save the image?\nFrom Url With given url, we can display it directly in the html page by assign it to the src of a img element.\nBlob Url But what about the file uploaded?\nThen we need to use Blob url. Blob URLs can only be generated internally by the browser. URL.createObjectURL() will create a special reference to the Blob or File object which later can be released using URL.revokeObjectURL(). These URLs can only be used locally in the single instance of the browser and in the same session.\n1const imageBlob = fetch(\u0026#39;https://example.com/image.png\u0026#39;).then(response =\u0026gt; response.blob()); 2const imageUrl = URL.createObjectURL(imageBlob); 3const img = document.createElement(\u0026#39;img\u0026#39;); 4img.src = imageUrl; // blob:XXX... If you need to pass the file object through different routes, like jump with link in the same page, besides save the file on the global place, like windonw or localStorage, sessionStorage, we can also pass the file through url's query parameter\nCommunication with server Send From Frontend There are several ways to send and receive file from server:\nHTML Form: One common way to upload files to a server is using an HTML form with an input field of type file. When the form is submitted, the browser sends a multipart/form-data request to the server, which can then process the uploaded file(s) as part of the request payload. 1\u0026lt;form id=\u0026#34;uploadbanner\u0026#34; enctype=\u0026#34;multipart/form-data\u0026#34; method=\u0026#34;post\u0026#34; action=\u0026#34;#\u0026#34;\u0026gt; 2 \u0026lt;input id=\u0026#34;fileupload\u0026#34; name=\u0026#34;myfile\u0026#34; type=\u0026#34;file\u0026#34; /\u0026gt; 3 \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;submit\u0026#34; id=\u0026#34;submit\u0026#34; /\u0026gt; 4\u0026lt;/form\u0026gt; FormData: You can also use the Fetch API or XMLHttpRequest to send files to a server using FormData. The FormData object lets you build a set of key-value pairs that represent form fields and their values, including file inputs. 1const formData = new FormData(); 2formData.append(\u0026#39;imageFile\u0026#39;, file, file.name); 3 4const response = await fetch(url, { method: \u0026#39;POST\u0026#39;, body: formData }); 5const json = await response.json(); WebSocket: If you need real-time file transfer, you can use WebSockets to establish a persistent connection between the client and server. You can then send file data through the WebSocket connection as a binary stream. Receive By Backend With browser supported FormData object, we can use formidable to handle it:\n1import formidable from \u0026#39;formidable\u0026#39;; 2 3const post = async (req: NextApiRequest, res: NextApiResponse\u0026lt;Data\u0026gt;) =\u0026gt; { 4 const fData = await new Promise\u0026lt;{ fields: any; files: any }\u0026gt;((resolve) =\u0026gt; { 5 // extract the file with formidable 6 const form = new formidable.IncomingForm(); 7 form.parse(req, (err, fields, files) =\u0026gt; { 8 if (err) { 9 res.status(500).send({ result: \u0026#39;Upload failed\u0026#39; }); 10 return; 11 } 12 resolve({ fields, files }); 13 }); 14 }); 15 16 const imageFile = fData.files.imageFile; 17} To read the file as Nodejs's Buffer, we can use the above method\n","link":"https://xfsnowind.github.io/blogs/blob-buffer-arraybuffer-image/","section":"blogs","tags":["Frontend","Learning Notes","Image"],"title":"Learning Notes about Image in Frontend"},{"body":"These days I am interested at the Frontend video technologies, so did some investigation and want to write learning notes here.\nThis article would only focus on the frontend technologies, maybe I will write something about the backend in the future maybe, but let's focus frontend here. So to play a frontend html5 video/audio, we need to get familiar with some concepts first.\nOK, let's begin from the start point, video. What technologies or concept are involved when a video is played\nVideo codecs The video codecs is a software algorithm that compress and decompress the digital media, like audio and video. It can be used to reduce the size of files for efficient storage and transmission. The common video codecs include H.264, H.265, AV1 and VP9.\nA simple example about the necessary of video codecs is a 30 minute video with high definition (1920 x 1080) in full code (4 bytes per pixel) would need about 447.9 GB of storage. With encoding or compression, not only the storage, but also network band-width which is more expensive are largely saved.\nBut different codecs have different strategies to encode the videos, like lossless and lossy.\nLossless compression would encode the data without discard any information. Lossy compression would discard some unnecessary data and reduce quality when possible, while easier to store and transfer. And this is the name of the game for web compression. Here are the most common codecs being used on the web.\nAV1 - AOMedia Video 1 AVC (H.264) - Advanced Video Coding H.263 - H.263 Video HEVC (H.265) - High Efficiency Video Coding MP4V-ES - MPEG-4 Video Elemental Stream MPEG-1 - MPEG-1 Part 2 Visual MPEG-2 - MPEG-2 Part 2 Visual Theora - Theora VP8 - Video Processor 8 VP9 - Video Processor 9 Normally, H.264 for video and AAC for audio are mostly used.\nMozilla also has a very good doc to explain the codecs here and wowza gives more detail about codecs on web as well\nVideo format Once compressed, the result of audio and video would need to be packed into a file or container, which is the video format. And the video format is a type of file to contain the digital media, like audio, video and other information, subtitles and metadata. It would determine how the data is stored and organized in the file. Differences between different formats includes:\nCodecs: different formats support different codecs; Compression efficiency: different strategies are applied to compress the video files; Quality: Some format are better suited for high-quality video, while some other are designed for low-bandwidth applications; Streaming support: some video formats are only designed specifically for streaming, while others support adaptive bitrate streaming and low-latency playback The relationship between of video format and codecs is closely related. Codecs suppported by formats are different, currently, mp4 is widely used for video.\nSo format is kind of independent from codecs, it doesn't care what kind of codecs it is when the video is produced. As long as format supports, you can use any kind of codec. But considering the reality, most suitable codecs would be chosen with factors such as file size, video quality, compatibility with different devices and platforms, and support for features such as subtitles, closed captions, and streaming protocols.\nHere is the list of popular formats supported codecs:\nMP4(MPEG-4) MKV WEBM MPEG AVI H.264(AVC)H.265(HEVC)AV1MP4V-ESMPEG-2VP9 H.264(AVC)H.265(HEVC)XvidDivXMPEG-2MPEG-4VP8VP9 AV1VP8VP9 MPEG-1MPEG-2 XvidDivXMPEG-4 SPMPEG-4 AVCVC-1 The most common formats for video includes MP4, AVI, MPEG and WebM. The most famous format for audio is mp3.\nVideo player So the codecs and format of video file are explained, then we need a player to play it now.\nA video player will read the format and codecs of the video from its metadata (also other information, like audio, subtitles). It will decide if the format and codecs are supported. To play the video, the related codecs are required to decode the video or audio. That's why we have to choose the correct video player, because it needs to support the format and codecs that your audience likely use.\nWeb Video player For frontend, we have several options to play video:\nHTML5 native video player: It is built into most modern web browsers, also supporting live streaming. It offers basic playback functionalities and can be customized with HTML, css and js. video.js: It is an open source HTML5 video player, which is highly customizable and supports a wide range of video formats. It also offers a plugin system that helps developers to add additional functioanlity to the player, such as advertising and analystics. hls.js: It works directly on the H5 video element by implementing an HLS client and supports HLS (discuss in the below paragraph). dash.js: It provides DASH playback in any browser that support Media Source Extension (MSE) and is one of the best adaptive streaming algorithms. Here is the difference between H5 player and video.js:\nDifference between H5 player and video.js There are also some other commercial players, like Flowplayer, JW player, etc. We will not discuss them here.\nSome other crucial features are also need to look out for H5 video player:\nDRM - Digital Rights management. It's used to encrypt and protect your video content from unauthorized users. Ad Insertion - From commercial aspect, player needs to support to insert the ad before (preroll), in the middle (midroll) and after (postroll) the video. Subtitles - It should allow to display the different language subtitles Analystics - It's valuable to measure the viewership, engagement levels and other aspect of the viewer to help author get the statistic. Video streaming (Video on Demand - VOD) So we have explained the basic concept of the video and player. And it can be played locally now, but nowadays it's so common to play the video online. So we need a streaming protocol to delivery data over the internet. They can sit on the Application, Presentation and Session layers.\nThere are multiple protocols or solutions used:\nProgressive download RTMP (Real-Time Messaging Protocol) RTSP (Real-Time Streaming Protocol) HLS (HTTP Live Streaming) DASH (Dynamic Adaptive Streaming over HTTP) WebRTC (Web Real-Time Communication) WebSocket Traditional Stateful Streaming Protocols RTSP (Real-Time Streaming Protocol) and RTMP (Real-Time Messaging Protocol) were created by Adobe and played by the Adobe Flash player. Even though Flash was announced of death by Adobe, RTMP and RTSP are still used for video and audio transmission for fast video delivery. Many broadcasters choose to transport live streams to their media server using RTMP. RTMP and RTSP keep latency at around 5 seconds or less.\nHTTP-Based Adaptive Streaming Protocols HLS (supported by iOS and Android devices) and MPEG-DASH (supported by Android devices) are the most common protocols used nowadays. And these streaming over HTTP are technically not \u0026quot;Streams\u0026quot;, rather are progressive downloads sent from web servers. HTTP-based protocols are stateless and can cause 10-45 seconds in latency. To reduce the latency, there are also low-latency version to HLS and DASH.\nDifference between HLS and DASH Nowadays, different environments would provide different bandwidths for video delivery and could effected by different reasons. So to satisfy the user experience of a variety of devices and connection speeds, instead of creating one stream with one bitrate, HTTP-based protocols allows you create multiple streams at different bitrates and resolutions. So for ourstanding bandwidth and processing power, user can watch the high-quality streams, while user can also enjoy the lower quality video with limited speed and power instead of interruptions. And the resolution would be updated when the network speed changes.\nLive streaming The difference of video streaming from live streaming is live streaming sending the live content generated by user's camera instead of the static audio/video files. And normally live streaming has higher requirement for casting the live video to multiple users simultaneously.\nBackPressure The backpressure of live streaming problem in frontend can occur when the amount of data sent from the server exceeds the capacity of the client to receive and process those data. This can lead to buffering and delays in the live stream, which can negatively impact the user experience.\nHttp-based streaming protocols are designed to handle the backpressure due to their use of Adaptive Bitrate Streaming, which allows the server to adjust the quality of the video according to the current available bandwidth and the capability of the client device. In addition, Http-based streaming protocols works with http caching, allow the client to cache the video segments and reducing the amount of data. However, it's still possible for backpressure to occur with http-based streaming protocols if the server is under heavy load.\nContent Delivery Network When deliverying the video content to the remote users, it may cause the latency and buffering if user is far away from the server, so a Content Delivery Network is required. To provide CDN, here are the general steps to implement:\nCreate the source stream: This can be done by a live encoder or a streaming software to send the content to the streaming server; Configure the CDN - to replicate and distribute the content to multiple destinations; Set up the streaming server: The streaming server is needed to receive and distribute the content; Connect the streaming server to the CDN: Applying the pull or pushing mechanism to obtain the content from streaming server to CDN; Apple platform Live streaming for iOS devices with HLS or DASH needs an index file with format M3U8. It is the format that is supported by the native video player in iOS, which is the AVPlayer.\nIn theory, DASH streaming cannot be played in the Apple's devices, but we have some other alternatives.\nUse a third-party player app There are a number of third-party player apps available in the App Store that support DASH streaming. Some popular options include: VLC for iOS, MX Player, Infuse Pro, etc Use the built-in iOS player with a third-party DRM plugin It can be enabled by installing the third-party DRM plugins, which are normally provided by the content provider, such as Netflix or Amazon Prime Video. Once plugins are installed, the build-in iOS player could be used to play the DASH streams that are protected by the corresponding DRM scheme. WebSocket Websocket is a realtime protocol that enables client-server bi-directional communication over a persisitent, single-socket connection. This is largely used in the applications that require real time communication and cooperations, such as Google doc. And comparing the Http-based protocol's long polling, websocket is based on event-driven, this can help to reduce latency and improve the performance of the live stream.\nBut using WebSocket for live streaming have the problem of backpressure, the client cannot consume the data sent from server.\nOne solution would be pushing the data to the buffer when available. But what if the buffer is full? So another solution would be speed up the live streaming. If the current time is behind the duration, we can increase the speed based on the lag time. And of course, effecting user experience would be the trade-off.\nWebRTC WebRTC is a open-sourced framework to enable the real-time communication between to web and mobile application in a peer-to-peer fashion.\nThe difference between WebRTC and WebSocket is\nWebSocket is a client-server protocol while WebRTC is a peer-to-peer protocol and offers capabilities for browsers and mobiles. WebSocket works only over TCP, WebRTC is primarily used over UDP (although it can work over TCP as well). WebRTC is primarily designed for streaming audio and video content. But Websocket is better suitable for text data, although it can also be used for video transmission. Other aspects Some additional considerations are needed when simulcasting:\nBandwidth and storage requirement: the network and storage infrastructure should be able to handle the huge network load Latency: configuration should be optimized to minimize the delay and latency Content protection: make sure that you have the proper licenses and content protection mechanisms to prevent unauthorized access and distribution ","link":"https://xfsnowind.github.io/blogs/frontend-video-learning-notes/","section":"blogs","tags":["Frontend","Video","Learning Notes","Live Streaming"],"title":"Frontend Video Learning Notes"},{"body":"","link":"https://xfsnowind.github.io/tags/live-streaming/","section":"tags","tags":null,"title":"Live Streaming"},{"body":"","link":"https://xfsnowind.github.io/tags/video/","section":"tags","tags":null,"title":"Video"},{"body":"These days I need to implement a component to draw a line on the given image and this line should be scalable, draggable and limited within the image. So here are the steps to implement it.\nKonva Definitely we need canvas to complete it, but instead of using canvas directly, it's better to use some mature library, like Konva\nan HTML5 Canvas JavaScript framework that extends the 2d context by enabling canvas interactivity for desktop and mobile applications.\nThis library definitely can do more things, but here we would only use the drawing part of it. It also provides good documentation and examples\nSetup the canvas Let's set up the canvas with Konva's Stage. The node would fit its parent node.\n1const stageRef = useRef\u0026lt;HTMLDivElement | null\u0026gt;(); 2// calculate the width of parent\u0026#39;s node as canvas\u0026#39;s width 3const stageWidth = stageRef?.current?.offsetWidth || 400; 4return ( 5 \u0026lt;div 6 ref={stageRef} 7 style={{ 8 width: \u0026#39;100%\u0026#39;, 9 height: \u0026#39;100%\u0026#39;, 10 }} 11 \u0026gt; 12 \u0026lt;Stage 13 width={stageWidth} 14 height={imgHeight} // we need to get the related image height 15 \u0026gt; 16 \u0026lt;Layer\u0026gt; 17 //... 18 \u0026lt;/Layer\u0026gt; 19 \u0026lt;/Stage\u0026gt; 20 \u0026lt;/div\u0026gt; 21) We assign the node's width as canvas's width. But we would like to keep the origianl ratio of image, instead of scaling it, so we need to calculate the related height with given image's width.\nDisplay the image First we need to display the image as the background. Since Konva's Image do not accept string as input, we need to generate an image html element. Give the image source string, set the image instance's src when it's loaded.\n1const useLineCrossingImage = ({ imgSrc }: { imgSrc: string }) =\u0026gt; { 2 const [image, setImage] = useState\u0026lt;HTMLImageElement | undefined\u0026gt;() 3 4 // load image with given base64 string src 5 useEffect(() =\u0026gt; { 6 const imageInstance: HTMLImageElement = new window.Image() 7 const updateImage = () =\u0026gt; { 8 setImage(imageInstance) 9 } 10 imageInstance.src = imgSrc 11 imageInstance.addEventListener(\u0026#39;load\u0026#39;, updateImage) 12 return () =\u0026gt; { 13 imageInstance.removeEventListener(\u0026#39;load\u0026#39;, updateImage) 14 } 15 }, [imgSrc]) 16 17 return \u0026lt;Group\u0026gt; 18 \u0026lt;Image 19 image={image} 20 onMouseEnter={(e) =\u0026gt; updateMouseCursor(e, \u0026#39;crosshair\u0026#39;)} 21 /\u0026gt; 22 \u0026lt;/Group\u0026gt; 23} The image should fit the parent's width with original ratio, so we need the image width and calculate the height based on it and the ratio.\n1const [imgHeight, setImgHeight] = useState\u0026lt;number\u0026gt;(DEFAULT_WIDTH_HEIGHT) 2 3// load image with given base64 string src 4useEffect(() =\u0026gt; { 5 //... 6 const updateImage = () =\u0026gt; { 7 // calculate the related height with width and not changing ratio 8 const height = (width / imageInstance.width) * imageInstance.height 9 imageInstance.width = width 10 imageInstance.height = height 11 setImgHeight(height) 12 setImage(imageInstance) 13 } 14 //... 15}, [imgSrc, width]) 16 17return { 18 imgHeight, 19 instance: ( 20 \u0026lt;Group\u0026gt; 21 \u0026lt;Image 22 image={image} 23 onMouseEnter={(e) =\u0026gt; updateMouseCursor(e, \u0026#39;crosshair\u0026#39;)} 24 /\u0026gt; 25 \u0026lt;/Group\u0026gt; 26 ), 27} Finally we return the image's instance and height which would be used in the Stage.\nDraw line So the background image is done now, let's draw the line on it.\nFirst we need to define the start and end point with Konva's type Vector2d.\n1export interface Vector2d { 2 x: number; 3 y: number; 4} 5 6//... 7 8const [startPoint, setStartPoint] = useState\u0026lt;Vector2d | null\u0026gt;(null); 9const [endPoint, setEndPoint] = useState\u0026lt;Vector2d | null\u0026gt;(null); When we click on the image, the start point should be set and its coordinates are saved, and the end point would be set when we release the mouse after dragging. So a mouse down and mouse up event are required.\n1const [value , setValue] = useState\u0026lt;ImageLineCrossingFormType\u0026gt;() 2 3const [isDuringNewLine, setIsDuringNewLine] = useState\u0026lt;boolean\u0026gt;(false); 4 5const handleMouseDown = (e: Konva.KonvaEventObject\u0026lt;MouseEvent\u0026gt;) =\u0026gt; { 6 const target = e?.target; 7 8 // Draw a new line again if click on the image not the Group 9 if (target.getClassName() === \u0026#34;Image\u0026#34;) { 10 const stage = target?.getStage(); 11 if (stage \u0026amp;\u0026amp; stage.getPointerPosition()) { 12 setIsDuringNewLine(true); 13 setStartPoint(stage.getPointerPosition()); 14 // remove previous end point when start a new line 15 setEndPoint(null); 16 } 17 } 18}; 19 20const handleMouseUp = (e: Konva.KonvaEventObject\u0026lt;MouseEvent\u0026gt;) =\u0026gt; { 21 const target = e?.target; 22 // NOTE: finish the line only when the target is image 23 if (target.getClassName() === \u0026#34;Image\u0026#34; \u0026amp;\u0026amp; isDuringNewLine) { 24 const stage = target?.getStage(); 25 if (stage \u0026amp;\u0026amp; stage.getPointerPosition()) { 26 const endValue = stage.getPointerPosition(); 27 setIsDuringNewLine(false); 28 setEndPoint(endValue); 29 // save the value 30 SET_VALUE_WITH_NAME({ 31 x1: startPoint?.x ?? 0, 32 y1: startPoint?.y ?? 0, 33 x2: endValue?.x ?? DEFAULT_WIDTH_HEIGHT, 34 y2: endValue?.y ?? DEFAULT_WIDTH_HEIGHT, 35 }); 36 } 37 } 38}; 39 40// calculate the width of parent\u0026#39;s node as canvas\u0026#39;s width 41const stageWidth = stageRef?.current?.offsetWidth || DEFAULT_WIDTH_HEIGHT; 42 43// with given width, calculate the related height without changing ratio of image 44// and get the image canvas instance 45const { imgHeight, instance: ImgInstance } = useLineCrossingImage({ 46 imgSrc, 47 width: stageWidth, 48}); 49 50 51return ( 52 \u0026lt;Stage 53 width={stageWidth} 54 height={imgHeight} 55 onMouseDown={handleMouseDown} 56 onMouseUp={handleMouseUp} 57 \u0026gt; 58 //... 59 \u0026lt;/Stage\u0026gt; 60) To make sure we can draw a new line, we need to make sure the item clicked is the image. And during the drawing, we should lock this process and set the end point only after the start point being set. To achieve that, isDuringNewLine is used to lock this process.\n1const target = e?.target; 2// NOTE: finish the line only when the target is image 3if (target.getClassName() === \u0026#34;Image\u0026#34; \u0026amp;\u0026amp; isDuringNewLine) To display the line, we are gonna use the konva's class Line with only two points (it can use infinity points in theory). To distinguish the line from other objects, let's set the mouse cursor as grab.\n1\u0026lt;Line 2 points={[ startPoint.x, startPoint.y, endPoint.x, endPoint.y ]} 3 stroke=\u0026#34;green\u0026#34; 4 strokeWidth={6} 5 onMouseEnter={(e) =\u0026gt; updateMouseCursor(e, \u0026#39;grab\u0026#39;)} // use grab cursor for line 6/\u0026gt; Scale points The line's start and end points should also be draggable to reset their values. We can draw two circle objects around the points with Konva's class Circle.\n1\u0026lt;Circle 2 x={startPoint.x} 3 y={startPoint.y} 4 draggable // circle can be dragged to extend the line 5 onMouseEnter={(e) =\u0026gt; updateMouseCursor(e, \u0026#39;pointer\u0026#39;)} // the cursor is pointer 6 fill=\u0026#34;white\u0026#34; 7 stroke=\u0026#34;green\u0026#34; 8 strokeWidth={3} 9 radius={6} 10/\u0026gt; The circles can be dragged now, but they are not attached to the line, when we move the circle points, the line's points are not updated. So we need to bind them as a Group.\nGroup When we want to transform multiple shapes together with the same operation, Group can be applied. And one thing needs to be careful, the position of the whole Group is absolute to the Stage, while all the positions of shapes within the Group would be related to the Group.\nLet's give the name of the start point of Group as groupAbsoluteStart. The relative position of end point should also be applied within the Group.\n1\u0026lt;Group 2 draggable 3 // NOTE: The Group x/y should use the absolute position, we use it as start point 4 x={groupAbsoluteStart.x} 5 y={groupAbsoluteStart.y} 6\u0026gt; 7 \u0026lt;Line 8 points={[ // NOTE: the node inside of group should use relative position 9 0, 10 0, 11 groupAbsoluteEnd.x - groupAbsoluteStart.x, 12 groupAbsoluteEnd.y - groupAbsoluteStart.y, 13 ]} 14 stroke=\u0026#34;green\u0026#34; 15 strokeWidth={6} 16 onMouseEnter={(e) =\u0026gt; updateMouseCursor(e, \u0026#39;grab\u0026#39;)} // use grab cursor for line 17 /\u0026gt; 18 {groupAbsoluteStart \u0026amp;\u0026amp; ( 19 \u0026lt;Circle // NOTE: the start point of start circle should always have the static relative position to the Group 20 x={0} 21 y={0} 22 draggable // circle can be dragged to extend the line 23 onMouseEnter={(e) =\u0026gt; updateMouseCursor(e, \u0026#39;pointer\u0026#39;)} // the cursor is pointer 24 fill=\u0026#34;white\u0026#34; 25 stroke=\u0026#34;green\u0026#34; 26 strokeWidth={3} 27 radius={6} 28 /\u0026gt; 29 )} 30 {groupAbsoluteEnd \u0026amp;\u0026amp; ( 31 \u0026lt;Circle 32 // NOTE: use the relative position inside of the Group 33 x={groupAbsoluteEnd.x - groupAbsoluteStart.x} 34 y={groupAbsoluteEnd.y - groupAbsoluteStart.y} 35 draggable 36 onMouseEnter={(e) =\u0026gt; updateMouseCursor(e, \u0026#39;pointer\u0026#39;)} 37 fill=\u0026#34;white\u0026#34; 38 stroke=\u0026#34;green\u0026#34; 39 strokeWidth={3} 40 radius={6} 41 /\u0026gt; 42 )} 43\u0026lt;/Group\u0026gt; When we finish setting the line, we need the absolute positions of start/end points. To obtain them, we can get the absolute positions of the Group in the end of dragging with event onDragEnd.\nsave the start position when dragging begins - onDragStart; in the end of dragging, start point's position can be obtained through target's method getAbsolutePosition; calculate the length of the line according to the previous start/end points calculate the new end points' positions save the new start and end positions 1const [savedStartPoint, setSavedStartPoint] = useState\u0026lt;Vector2d | null\u0026gt;(null) 2 3\u0026lt;Group 4 draggable 5 // NOTE: The Group x/y should use the absolute position, we use it as start point 6 x={groupAbsoluteStart.x} 7 y={groupAbsoluteStart.y} 8 onDragStart={(e) =\u0026gt; { 9 const target = e?.currentTarget 10 // 1. Save the start point to calculate moved distance when drag ends 11 setSavedStartPoint({ x: target.x(), y: target.y() }) 12 }} 13 onDragEnd={(e) =\u0026gt; { 14 const target = e?.currentTarget 15 // 2. get the absolute of the group and save it as start point 16 const { x, y } = target.getAbsolutePosition() 17 // 3, 4. get the new end point based on the moved distance and previous end point 18 const newEndPointX = x - (savedStartPoint?.x ?? 0) + groupAbsoluteEnd.x 19 const newEndPointY = y - (savedStartPoint?.y ?? 0) + groupAbsoluteEnd.y 20 // 5. after we finish the drag, need to update the start and end points for the future actions 21 setGroupAbsoluteStart({ x, y }) 22 setGroupAbsoluteEnd({ x: newEndPointX, y: newEndPointY }) 23 24 // calculate the values with form\u0026#39;s format 25 SET_VALUE_WITH_NAME({ x1: x, y1: y, x2: newEndPointX, y2: newEndPointY }) 26 }} 27/\u0026gt; For the start/end circle points, when we drag them, the line is already attached to the circle, but the related points' values should also be updated.\nTo avoid triggering the drag event of Group, instead of calling html event's stopPropagation, we should set cancelBubble of event as true on the onDragEnd event. Check the official doc here. And note that this cancelBubble must be done on the onDragEnd event.\nNOTE: the relative position of the circle point would be changed, to keep the position consistent, we manually set its relative position as 0 (e.g for the start point)\n1// Start circle point 2onDragEnd={(e: Konva.KonvaEventObject\u0026lt;MouseEvent\u0026gt;) =\u0026gt; { 3 // NOTE: MUST set the cancelBubble on the drag end event 4 e.cancelBubble = true 5 6 const target = e.target 7 // get the absolute position of the start circle and save it to the form 8 const { x, y } = target.getAbsolutePosition() 9 // Save the value to form when ends instead of during dragging 10 SET_VALUE_WITH_NAME({ 11 x1: x / stageWidth, 12 y1: y / stageHeight, 13 x2: groupAbsoluteEnd.x / stageWidth, 14 y2: groupAbsoluteEnd.y / stageHeight, 15 }) 16}} 17onDragMove={(e: Konva.KonvaEventObject\u0026lt;MouseEvent\u0026gt;) =\u0026gt; { 18 const target = e.target 19 // NOTE: keep the circle relative position always being 0 20 target.x(0) 21 target.y(0) 22}} Limitation Til now, the basic feature has been implemented, drag line, circle to new position, draw a new line. But there is no border to the line, the line and its points can be dragged out of the image. To implement this, we need to check points' position during dragging. And the situation is different when the start point is left/right or higher/lower to the end.\n1const limitValue = (xValue: number, maxValue: number, minValue = 0) =\u0026gt; 2 Math.max(minValue, Math.min(maxValue, xValue)) 3 4\u0026lt;Group 5 ... 6 onDragMove={(e) =\u0026gt; { 7 const target = e?.currentTarget 8 const { x, y } = target.getAbsolutePosition() 9 // limit the move area 10 const xMovedDistance = groupAbsoluteEnd.x - groupAbsoluteStart.x 11 const yMovedDistance = groupAbsoluteEnd.y - groupAbsoluteStart.y 12 13 // the range changes when the start is behind or before end 14 if (xMovedDistance \u0026gt; 0) { 15 target.x(limitValue(x, stageWidth - xMovedDistance)) 16 } else { 17 target.x(limitValue(x, stageWidth, 0 - xMovedDistance)) 18 } 19 20 if (yMovedDistance \u0026gt; 0) { 21 target.y(limitValue(y, stageHeight - yMovedDistance)) 22 } else { 23 target.y(limitValue(y, stageHeight, 0 - yMovedDistance)) 24 } 25 }} 26/\u0026gt; For the circle point, we need to calculate its absolute position and limit it within the border as well.\nSummary So this is what we want now, you can check the result on the under example and the Codes here.\n","link":"https://xfsnowind.github.io/blogs/react-konva-draw-line/","section":"blogs","tags":["Typescript","Frontend","React","React konva","konva"],"title":"Draw a scalable line with React Konva"},{"body":"","link":"https://xfsnowind.github.io/tags/konva/","section":"tags","tags":null,"title":"konva"},{"body":"","link":"https://xfsnowind.github.io/tags/react-konva/","section":"tags","tags":null,"title":"React konva"},{"body":"","link":"https://xfsnowind.github.io/tags/typescript/","section":"tags","tags":null,"title":"Typescript"},{"body":"The first time I touched the React-hook-form was in 2020 and it also was the first time I learned React's new concept Hooks. During that time we compared all the popular form libraries, Formik, react-form, final form and etc, but we finally chose the React-hook-form even though it was still under the development during that time. It is because it uses React latest concept Hooks. And React was our fundamental framework in my previous company, so we didn't need to think about the compatibility.\nNow it comes to the version 7 and there are more hooks. And these days I began to use it in our project to create multiple forms. After discussing with my colleague Rodrigo, I had a better deeper understanding to React-hook-form's built-in schema validation when develop with typescript. Before we go deep, let me clear some basic concepts.\nControlled vs Uncontrolled component This is the concept introduced by the React and the difference of them is where you will keep the source of truth. For the controlled components, we will pass a React controlled value to the form element,, React will take care of the state and render the component whenever you change the value. But for uncontrolled components, the state is saved in the DOM, which means when you update the value of form element, React will not notify it. We have to manually extract the value when need (through React's ref). But the benefit of that is it will not render the component either.\nLet me clear it with the simple codes:\nControlled Component 1const ControlledComponent = () =\u0026gt; { 2 const [someValue, setSomeValue] = useState() 3 const handleChange= (event) =\u0026gt; setSomeValue(event.target.value) 4 5 return \u0026lt;input value={someValue} onChange={handleChange} /\u0026gt; 6} So this Controlled Component will monitor the input value and keep pushing the value to the element.\nA form element becomes \u0026quot;controlled\u0026quot; if you set its value via a prop. That's all.\nNOTE: checked for Radio and Checkbox.\nNOTE: it's fine to pass onChange to form element, only setting its value will make it controlled. (I used to think the property onChange or onClick decides if the component is controlled or uncontrolled as well)\nUncontrolled Component 1const UncontrolledComponent = () =\u0026gt; { 2 const testRef = useRef() 3 4 const handleButtonClick = () =\u0026gt; { 5 const value = testRef.current?.value; 6 // do something to the value 7 } 8 9 return ( 10 \u0026lt;div\u0026gt; 11 \u0026lt;input type=\u0026#34;text\u0026#34; ref={testRef} /\u0026gt; 12 \u0026lt;button onClick={handleButtonClick} /\u0026gt; 13 \u0026lt;/div\u0026gt; 14 ) 15} Since the value is not assigned to the element input, React would not know its value you typed. To get the value, we can use the ref.\nRegister So for uncontrolled component, React-hook-form will use register method to generate the related methods for the form element without the property value.\n1const { onChange, onBlur, name, ref } = register(\u0026#39;firstName\u0026#39;); 2 3\u0026lt;input 4 onChange={onChange} // assign onChange event 5 onBlur={onBlur} // assign onBlur event 6 name={name} // assign name prop 7 ref={ref} // assign ref prop 8/\u0026gt; 9// same as above 10\u0026lt;input {...register(\u0026#39;firstName\u0026#39;)} /\u0026gt; But for Controlled components, like material UI, it's recommended to use Controller. Its property render will pass a parameter field containing value to the Controlled Component.\n1\u0026lt;Controller 2 control={control} 3 name=\u0026#34;test\u0026#34; 4 render={({ 5 field: { onChange, onBlur, value, name, ref }, 6 fieldState: { invalid, isTouched, isDirty, error }, 7 formState, 8 }) =\u0026gt; ( 9 \u0026lt;Checkbox 10 onBlur={onBlur} // notify when input is touched 11 onChange={onChange} // send value to hook form 12 checked={value} 13 inputRef={ref} 14 /\u0026gt; 15 )} 16/\u0026gt; Typescript with Schema OK, before we go further, let's check one important of react-hook-form's features - schema validation. This is not a new thing, all the form libraries support schema validation and this is a kind of standard. But with help of typescript, react-hook-form provides a very powerful type-safe checking. I can explain this with example later. Let's simply check the setup. Here we will use Zod, which seems the best choice currently according to this article\n1const schema = z.object({ 2 name: z.string(), 3 age: z.number() 4}); 5 6type Schema = z.infer\u0026lt;typeof schema\u0026gt;; 7 8const App = () =\u0026gt; { 9 const { register, handleSubmit } = useForm\u0026lt;Schema\u0026gt;({ resolver: zodResolver(schema) }); 10 11 //... 12} Type checking React-hook-form provides very powerful type-checking, it also exports multiple types used with typescript generic type. This helps us a lot with good developer experience which is also one goal of this library's design and philosiphy.\nTo find out the power of type checking, let's compare a correct example to a tricky one.\nAccording to the official doc of setValue, it's possible to set value to an unregistered field. When we set value to an unregistered field, we will registered in this field as well.\n1// you can setValue to a unregistered input 2setValue(\u0026#39;notRegisteredInput\u0026#39;, \u0026#39;value\u0026#39;); // ✅ prefer to be registered Setup schema and initial value So go further, let's choose Material UI's component Select as an Controlled example. Before defining the component, setup the schema and initial value first.\n1// Select Option array 2const SelectValue = [ 3 { value: \u0026#34;10\u0026#34;, label: \u0026#34;The entire place\u0026#34; }, 4 { value: \u0026#34;20\u0026#34;, label: \u0026#34;A private room\u0026#34; }, 5 { value: \u0026#34;30\u0026#34;, label: \u0026#34;A shared room\u0026#34; }, 6] as const; 7 8// define the schema and type through Zod 9type Property = typeof SelectValue[number][\u0026#34;value\u0026#34;]; 10const VALUES: [Property, ...Property[]] = [ 11 SelectValue[0].value, 12 ...SelectValue.slice(1).map((p) =\u0026gt; p.value), 13]; 14 15const PropertySchema = z.enum(VALUES); 16 17// the Zod schema used for resolver in form 18const formSchema = z.object({ example: PropertySchema }); 19 20type Inputs = z.infer\u0026lt;typeof formSchema\u0026gt;; 21 22// default values provided to form 23const initValues: Inputs = { example: \u0026#34;10\u0026#34; }; Tricky Controlled Component Then we can create a simple tricky component with Mui Select, which will not register the field in the form in advance, just pass the react-hook-form's types values control, setValue as parameters to allow the component to obtain and update the value.\n1type Props\u0026lt;T extends FieldValues\u0026gt; = { 2 name: FieldPath\u0026lt;T\u0026gt;; 3 control: Control\u0026lt;T\u0026gt;; 4 setFormValue: UseFormSetValue\u0026lt;T\u0026gt;; 5 data: ReadonlyArray\u0026lt;{ 6 label: string; 7 value: FieldPathValue\u0026lt;T, FieldPath\u0026lt;T\u0026gt;\u0026gt;; 8 }\u0026gt;; 9}; 10 11const Input1 = \u0026lt;T extends FieldValues\u0026gt;({ 12 name, 13 control, 14 setFormValue, 15 data, 16}: Props\u0026lt;T\u0026gt;) =\u0026gt; { 17 const value = useWatch({ name, control }); 18 19 const handleChange = (event: SelectChangeEvent) =\u0026gt; setFormValue( 20 name, 21 (event.target.value + \u0026#34;11\u0026#34;) as FieldPathValue\u0026lt;T, FieldPath\u0026lt;T\u0026gt;\u0026gt; 22 ); 23 24 return ( 25 \u0026lt;FormControl fullWidth\u0026gt; 26 \u0026lt;InputLabel id=\u0026#34;demo-simple-select-label\u0026#34;\u0026gt;Age\u0026lt;/InputLabel\u0026gt; 27 \u0026lt;Select 28 labelId=\u0026#34;demo-simple-select-label\u0026#34; 29 id=\u0026#34;demo-simple-select\u0026#34; 30 value={value} 31 label=\u0026#34;Age\u0026#34; 32 onChange={handleChange} 33 \u0026gt; 34 {data.map((entry) =\u0026gt; { 35 return ( 36 \u0026lt;MenuItem key={entry.value} value={entry.value}\u0026gt; 37 {entry.label} 38 \u0026lt;/MenuItem\u0026gt; 39 ); 40 })} 41 \u0026lt;/Select\u0026gt; 42 \u0026lt;/FormControl\u0026gt; 43 ); 44}; For the input parameters, we use react-hook-form's types to let it check the types of name and values for us.\nname: FieldPath\u0026lt;T\u0026gt; control: Control\u0026lt;T\u0026gt; setFormValue: UseFormSetValue\u0026lt;T\u0026gt; value: FieldPathValue\u0026lt;T, FieldPath\u0026lt;T\u0026gt;\u0026gt; And when the value changes, we will use the input method setFormValue to set the field value directly. But here we do a tricky thing, instead of using the value from the option, we manipulate it by appending a string \u0026quot;11\u0026quot;.\n1const handleChange = (event: SelectChangeEvent) =\u0026gt; { 2 setFormValue( 3 name, 4 (event.target.value + \u0026#34;11\u0026#34;) as FieldPathValue\u0026lt;T, FieldPath\u0026lt;T\u0026gt;\u0026gt; 5 ) 6} Let's use this component in the form:\n1function App() { 2 const methods = useForm\u0026lt;Inputs\u0026gt;({ 3 defaultValues: initValues, 4 mode: \u0026#34;onChange\u0026#34;, 5 resolver: zodResolver(formSchema), 6 }); 7 8 const { 9 register, 10 control, 11 handleSubmit, 12 setValue, 13 formState: { errors }, 14 } = methods; 15 16 const onSubmit: SubmitHandler\u0026lt;Inputs\u0026gt; = (data) =\u0026gt; console.log(data, errors) 17 18 return ( 19 \u0026lt;div className=\u0026#34;App\u0026#34;\u0026gt; 20 \u0026lt;form onSubmit={handleSubmit(onSubmit)}\u0026gt; 21 \u0026lt;Input1 name=\u0026#34;example\u0026#34; setFormValue={setValue} control={control} data={SelectValue} /\u0026gt; 22 {errors.example \u0026amp;\u0026amp; errors.example.message} 23 \u0026lt;input type=\u0026#34;submit\u0026#34; /\u0026gt; 24 \u0026lt;/form\u0026gt; 25 \u0026lt;/div\u0026gt; 26 ); 27} We display the error if it exists. When we select the value in the Select, since the value has been manipulated, Select will be blank. But the error does not show either, only warning in the console. Definitely, this is not good, we do not have enough information about our error.\nCorrect Controlled Component Let's create a correct controlled component and pass it wrong data, see how it gives our error message.\n1const SelectValueWrong = [ 2 { value: \u0026#34;101\u0026#34;, label: \u0026#34;The entire place\u0026#34; }, // This value is different from the one in type and schema 3 { value: \u0026#34;20\u0026#34;, label: \u0026#34;A private room\u0026#34; }, 4 { value: \u0026#34;30\u0026#34;, label: \u0026#34;A shared room\u0026#34; }, 5] as const; 6 7type Props3\u0026lt;T extends FieldValues\u0026gt; = { 8 name: FieldPath\u0026lt;T\u0026gt;; 9 control: Control\u0026lt;T\u0026gt;; // And we do not need to pass the method setValue since react-hook-form will handle it for us 10 data: ReadonlyArray\u0026lt;{ 11 label: string; 12 value: FieldPathValue\u0026lt;T, FieldPath\u0026lt;T\u0026gt;\u0026gt;; 13 }\u0026gt;; 14}; 15 16const Input3 = \u0026lt;T extends FieldValues\u0026gt;({ name, control, data }: Props3\u0026lt;T\u0026gt;) =\u0026gt; ( 17 \u0026lt;Controller 18 control={control} 19 name={name} 20 render={({ field }) =\u0026gt; { 21 return ( 22 \u0026lt;FormControl fullWidth\u0026gt; 23 \u0026lt;InputLabel id=\u0026#34;demo-simple-select-label\u0026#34;\u0026gt;Age\u0026lt;/InputLabel\u0026gt; 24 \u0026lt;Select 25 {...field} 26 labelId=\u0026#34;demo-simple-select-label\u0026#34; 27 id=\u0026#34;demo-simple-select\u0026#34; 28 label=\u0026#34;Age\u0026#34; 29 \u0026gt; 30 {data.map((entry) =\u0026gt; { 31 return ( 32 \u0026lt;MenuItem key={entry.value} value={entry.value}\u0026gt; 33 {entry.label} 34 \u0026lt;/MenuItem\u0026gt; 35 ); 36 })} 37 \u0026lt;/Select\u0026gt; 38 \u0026lt;/FormControl\u0026gt; 39 ); 40 }} 41 /\u0026gt; 42); 43 44// use it in the form 45 \u0026lt;Input3 control={control} name=\u0026#34;example3\u0026#34; 46 data={SelectValueWrong} /\u0026gt; // pass the wrong select value 47 {errors.example3 \u0026amp;\u0026amp; errors.example3.message} 48//... When we select the wrong option, the value will still be displayed in the Select, but the schema validates the input value as well, set it as error and the error message is displayed.\nSource codes You can check all the codes here:\nFormProvider and useFormContext? Nja Another thought about React-hook-form is the FormProvider and useFormContext. When we pass the methods through them to the children components, we also lose the types of all the methods. Yes, of course, we can pass the type to useFormContext, but since we need to pass the form schema type twice, the type is still not 100% safe in theory. So if the form's elements are not deep, we would recommend to pass the control which would include the form's type to children components.\n","link":"https://xfsnowind.github.io/blogs/react-hook-form-notes/","section":"blogs","tags":["Typescript","Frontend","React","React hook form"],"title":"Powerful type-checking of React-hook-form and Learning Notes"},{"body":"","link":"https://xfsnowind.github.io/tags/react-hook-form/","section":"tags","tags":null,"title":"React hook form"},{"body":"Nowadays, I joined a frontend team in a new company in Singapore, the project is based on monorepo (you can find more about monorepo here) and the tech lead maintains the project very well, keeping updating the main libraries to the latest version and keeping an eye on the new technology to improve the solution and codes.\nWhen I invested the project, I found the project was not just a monorepo, but also a monolith frontend project which involves other project which is kidn of a historical problem. It works currently but have some issues for other team, let's call it Team D. Team D is working on one tab in the web page, it uses the same framework (React) and similar technologies, but it does not have any intersection with main project in business actually. It has its own development libraries and release plan. But since its codes are still in the same src folder with main project, which causes team D still stays inside of the main project's release lifecycles. Therefore, we need to separate it from Microfrontend technology.\nWhat is MicroFrontend Microfrontend is a popular architechtural solution that helps large, complex monolith applications to be built as a collection of independently-developed and deployed microservices. This can improve the scalability, maintainability and flexibility of the application, making it easier to collaborate with a team of developers.\nWhat is Module federation One way to implement microfrontend in the application is module federation, a plugin in the webpack 5. It connects different applications during build time and share modules with each other during runtime. This allows each module to define and manage its own components, while still being able to use common libraries by other modules.\nActually there are some other popular frameworks doing the microfrontend, like single-spa, bit, qiankun. The reason we choose module federation is:\nAll the other frameworks are doing two things\norganize the microfrontend services connect these services together through importing. Since we already have our own application well-organized in a monorepo way, each module is dynamically imported by react new feature React.lazy. So what we need here actually is just the way of importing modules dynamically.\nModule federation is just a plugin of webpack 5, we do not need to install another library to enable microfrontend. It also saves us time to maintain the extra library.\nMigration with Module federation with Nx In our project, we installed Nx to manage the monorepo, it's good to use module federation with Nx as well to include the new project in the management of Nx. You can learn more about monorepo and the comparasion with polyrepo Check here. Nx creates its own module federation module to simplify the procedure, if the whole project has not been created, it's good to use it.\n1const withModuleFederation = require(\u0026#39;@nrwl/react/module-federation\u0026#39;); 2const moduleFederationConfig = require(\u0026#39;./module-federation.config\u0026#39;); 3 4module.exports = withModuleFederation({ 5 ...moduleFederationConfig, 6}); Configure host with original configuration But normally when we want to apply the module federation to the project, it means the project's webpack has already been well configured, it comes some conflict if we use the methods from Nx. So instead of that, let's use the original module federation configuration.\n1const { ModuleFederationPlugin } = require(\u0026#39;webpack\u0026#39;).container 2const deps = require(\u0026#39;../../package.json\u0026#39;).dependencies 3 4... 5 6module.exports = { 7 entry: \u0026#39;./src/bootstrap.tsx\u0026#39;, // used to be entry: \u0026#39;./src/index.tsx\u0026#39;, 8 //... 9 plugins: [ 10 new ModuleFederationPlugin({ 11 name: \u0026#39;host\u0026#39;, 12 shared: { 13 react: { 14 singleton: true, 15 requiredVersion: deps[\u0026#39;react\u0026#39;], 16 }, 17 \u0026#39;react-dom\u0026#39;: { 18 singleton: true, 19 requiredVersion: deps[\u0026#39;react-dom\u0026#39;], 20 }, 21 }, 22 }), 23 ... 24 ]}; Here we only define the name in module federation plugin because we will use dynamic importing later. And we update the entry from ./src/index.tsx to './src/bootstrap.tsx'. It's because module federation needs an entrance to import the modules.\nThen let's create a new file bootstrap.tsx under folder src and fill the content with:\n1import(\u0026#39;./index\u0026#39;) Configure remote So the host part is finished, let's see how to create a remote project with Nx. In the root folder, run the following command. Here I named the project as delivery-test, feel free to change it if you want other name.\n1nx generate @nrwl/react:remote delivery-test It would create the remote project under the project with its own configuration. For the webpack, we would configure like below:\n1require(\u0026#39;dotenv\u0026#39;).config() 2const { join, resolve } = require(\u0026#39;path\u0026#39;) 3const webpack = require(\u0026#39;webpack\u0026#39;) 4const packageConfig = require(\u0026#39;../../package.json\u0026#39;) 5const { version } = packageConfig 6const isDev = process.env.NODE_ENV === \u0026#39;development\u0026#39; 7const isProductionBuild = process.env.NODE_ENV === \u0026#39;production\u0026#39; 8const isDevDockerEnv = isDev \u0026amp;\u0026amp; process.env.DEVELOPMENT_ENV === \u0026#39;docker\u0026#39; 9 10const { ModuleFederationPlugin } = require(\u0026#39;webpack\u0026#39;).container 11const deps = packageConfig.dependencies 12 13module.exports = { 14 mode: isDev ? \u0026#39;development\u0026#39; : \u0026#39;production\u0026#39;, 15 entry: \u0026#39;./src/main.ts\u0026#39;, 16 output: { 17 ...(isProductionBuild \u0026amp;\u0026amp; { 18 path: join(process.cwd(), \u0026#39;dist/apps/delivery-test\u0026#39;), 19 filename: \u0026#39;static/js/[name].[contenthash].js\u0026#39;, 20 chunkFilename: \u0026#39;static/js/[name].[contenthash].chunk.js\u0026#39;, 21 }), 22 publicPath: \u0026#39;auto\u0026#39;, 23 }, 24 context: __dirname, 25 devtool: isDev ? \u0026#39;eval-cheap-module-source-map\u0026#39; : \u0026#39;nosources-source-map\u0026#39;, 26 devServer: isDev 27 ? { 28 historyApiFallback: true, 29 host: \u0026#39;0.0.0.0\u0026#39;, 30 port: 9002, 31 hot: true, 32 liveReload: false, 33 static: __dirname, 34 devMiddleware: { 35 publicPath: \u0026#39;/\u0026#39;, 36 }, 37 client: { overlay: false }, 38 } 39 : undefined, 40 resolve: { 41 extensions: [\u0026#39;.js\u0026#39;, \u0026#39;.jsx\u0026#39;, \u0026#39;.ts\u0026#39;, \u0026#39;.tsx\u0026#39;], 42 }, 43 // ... 44 plugins: [ 45 new ModuleFederationPlugin({ 46 name: \u0026#39;delivery-test\u0026#39;, 47 filename: \u0026#39;remoteEntry.js\u0026#39;, 48 library: { type: \u0026#39;global\u0026#39;, name: \u0026#39;delivery_test\u0026#39; }, // NOTE: use underscore here, minus is not allowed 49 exposes: { 50 \u0026#39;./Module\u0026#39;: \u0026#39;./src/remote-entry.ts\u0026#39;, 51 }, 52 shared: { 53 react: { 54 singleton: true, 55 requiredVersion: deps[\u0026#39;react\u0026#39;], 56 }, 57 \u0026#39;react-dom\u0026#39;: { 58 singleton: true, 59 requiredVersion: deps[\u0026#39;react-dom\u0026#39;], 60 } 61 }, 62 }), 63 ], 64} In the module federation configuration, we define a global variable delivery_test to pass the parameters through dynamical importing. Be carefull, the variable's name does not accept - symbol.\nFor the Nx commands, we can also update the commands in project.json:\n1\u0026#34;build\u0026#34;: { 2 \u0026#34;executor\u0026#34;: \u0026#34;nx:run-commands\u0026#34;, 3 \u0026#34;options\u0026#34;: { 4 \u0026#34;command\u0026#34;: \u0026#34;pnpm cross-env NODE_OPTIONS=--max-old-space-size=6144 NODE_ENV=production STAGING=true webpack --config ./apps/delivery-test/webpack.config.js\u0026#34; 5 } 6}, 7\u0026#34;build-serve\u0026#34;: { 8 \u0026#34;executor\u0026#34;: \u0026#34;nx:run-commands\u0026#34;, 9 \u0026#34;options\u0026#34;: { 10 \u0026#34;command\u0026#34;: \u0026#34;pnpm cross-env NODE_OPTIONS=--max-old-space-size=6144 NODE_ENV=production STAGING=true webpack serve --config ./apps/delivery-test/webpack.config.js --port 9002\u0026#34; 11 } 12}, 13\u0026#34;serve\u0026#34;: { 14 \u0026#34;executor\u0026#34;: \u0026#34;nx:run-commands\u0026#34;, 15 \u0026#34;options\u0026#34;: { 16 \u0026#34;command\u0026#34;: \u0026#34;pnpm cross-env NODE_OPTIONS=--max-old-space-size=6144 NODE_ENV=development webpack serve --config ./apps/delivery-test/webpack.config.js\u0026#34;, 17 } 18}, Module federation dynamic library So the setup and configuration are completed. So how can we use the component from remote project in the host? In the module federation configuration of host, we do not have any text about the remote project delivery-test, it's because we gonna import the remote dynamically, which means the remote project can be imported during runtime without specifying at build time. For the principle, you can check this one and also 4 ways to use dynamic remotes.\n1function loadComponent(scope: string, module: string) { 2 return async () =\u0026gt; { 3 const libName = scope.replace(/\\//g, \u0026#39;_\u0026#39;).replace(/-/g, \u0026#39;_\u0026#39;) 4 // Initializes the share scope. This fills it with known provided modules from this build and all remotes 5 await __webpack_init_sharing__(\u0026#39;default\u0026#39;) 6 const container = window[libName] // or get the container somewhere else 7 // Initialize the container, it may provide shared modules 8 await container.init(__webpack_share_scopes__.default) 9 const factory = await window[libName].get(module) 10 const Module = factory() 11 return Module 12 } 13} 14 15const urlCache = new Set() 16const useDynamicScript = (url: string) =\u0026gt; { 17 const [ready, setReady] = React.useState(false) 18 const [errorLoading, setErrorLoading] = React.useState(false) 19 useEffect(() =\u0026gt; { 20 if (!url) return 21 if (urlCache.has(url)) { 22 setReady(true) 23 setErrorLoading(false) 24 return 25 } 26 setReady(false) 27 setErrorLoading(false) 28 const element = document.createElement(\u0026#39;script\u0026#39;) 29 element.src = url 30 element.type = \u0026#39;text/javascript\u0026#39; 31 element.async = true 32 element.onload = () =\u0026gt; { 33 urlCache.add(url) 34 setReady(true) 35 } 36 element.onerror = () =\u0026gt; { 37 setReady(false) 38 setErrorLoading(true) 39 } 40 document.head.appendChild(element) 41 return () =\u0026gt; { 42 urlCache.delete(url) 43 document.head.removeChild(element) 44 } 45 }, [url]) 46 return { 47 errorLoading, 48 ready, 49 } 50} 51 52const componentCache = new Map() 53const useFederatedComponent = (remoteUrl: string, scope: string, module: string) =\u0026gt; { 54 const key = `${remoteUrl}-${scope}-${module}` 55 const [Component, setComponent] = React.useState(null) 56 const { ready, errorLoading } = useDynamicScript(remoteUrl) 57 React.useEffect(() =\u0026gt; { 58 if (Component) setComponent(null) 59 // Only recalculate when key changes 60 }, [key]) 61 React.useEffect(() =\u0026gt; { 62 if (ready \u0026amp;\u0026amp; !Component) { 63 const Comp = React.lazy(loadComponent(scope, module)) 64 componentCache.set(key, Comp) 65 setComponent(Comp) 66 } 67 // key includes all dependencies (scope/module) 68 }, [Component, ready, key, module, scope]) 69 return { errorLoading, Component } 70} 71// NOTE: to make dynamica import work, we need to pass the container to a global variable which should be defined in the remote app\u0026#39;s webpack config 72// Find the file withModuleFederationPlugin.js in the remote app\u0026#39;s webpack config 73// 1. remove the code of setting \u0026#34;outputModule: true\u0026#34; 74// 2. update the library in modulefederation from value \u0026#39;module\u0026#39; to { 75// type: \u0026#39;global\u0026#39;, 76// name: options.name.replace(\u0026#39;-\u0026#39;, \u0026#39;_\u0026#39;), // the name does not accept dash and backslash 77// } 78const App = () =\u0026gt; { 79 const { Component: FederatedComponent, errorLoading } = useFederatedComponent( 80 \u0026#39;http://localhost:9002/remoteEntry.js\u0026#39;, 81 \u0026#39;delivery-test\u0026#39;, 82 \u0026#39;./Module\u0026#39;, 83 ) 84 return ( 85 \u0026lt;React.Suspense fallback=\u0026#34;Loading System\u0026#34;\u0026gt; 86 {errorLoading 87 ? `Error loading module \u0026#34;${module}\u0026#34;` 88 : FederatedComponent \u0026amp;\u0026amp; \u0026lt;FederatedComponent /\u0026gt;} 89 \u0026lt;/React.Suspense\u0026gt; 90 ) 91} Use the above codes in the host project, and call the App directly with \u0026lt;App /\u0026gt;.\n","link":"https://xfsnowind.github.io/blogs/micro-frontend-module-federation/","section":"blogs","tags":["Javascript","MicroFrontend","Module Federation"],"title":"How to convert an existing project to MicroFrontend with Module Federation"},{"body":"","link":"https://xfsnowind.github.io/tags/microfrontend/","section":"tags","tags":null,"title":"MicroFrontend"},{"body":"","link":"https://xfsnowind.github.io/tags/module-federation/","section":"tags","tags":null,"title":"Module Federation"},{"body":"Around 2018, one of my colleague was working on creating a list component which only renders a limited amount of items in the list instead of the whole one to improve the performance if the list is in large or huge scale. I was always interested at how he did that, but I did not do any investment, just an idea. Then once I was asked how to implement such thing during an interview, it remindered me. I wrote it to my learning plan blog. After I began to work in the new company, I found all the lists in the product already used this idea with the library react-virtualized and its optimized version react-window. Finaly, I decided to learn this thing -- virtualized, figure out how it is implemented.\nNowadays virtualized has become a kind of standard for all the grid/list library, it's used in most frameworks or libraries,like mui, react-table. It helps improve the performance and user experience of large, complex, and data-intensive applications built with React. It does this by rendering only the items that are currently visible on the screen, and virtualizing the rest of the items, which allows the application to handle large datasets without negatively impacting performance or the user experienceSo here I would share my research about how it is implemented. Since I am more familiar with React, so I will use React as the framework.\nGrid/List Normally, both List and Grid are virtualized. But since List is actually an one-dimension Grid, so let's take Grid as an example.\nWorkflow To implement this feature, we need to implement in two parts: javascript and html. With javascript, we need to calculate the start/end indexes of the visible elements. And for html, we need to paint them.\nJavascript - logic OK, let's clear the logic firstly. Let's imagine we have a 1000x1000 grid, only 20x20 are rendered in the table no matter how it scrolls. So to render only the visible items in the long list/grid during scrolling, it must be related to the scroll event. We need to\ncalculate the scroll offset of the whole component when scroll calculate the start and end index of vertical and horizontal elements based on offset generate the visible element based on the indexes Scroll offset Apparently, we need a callback event function to bind to the scroll event of the root element, calculating the offsets in vertical and horizontal directions. It can be obtained from node's property scrollLeft and scrollTop.\n1const [verticalScroll, setVerticalScroll] = React.useState(0); 2const [horizontalScroll, setHorizontalScroll] = React.useState(0); 3 4// set up scroll event to update the offset of top and left 5const onScroll = useCallback((event: UIEvent\u0026lt;HTMLDivElement\u0026gt;) =\u0026gt; { 6 const target = event.target as HTMLDivElement; 7 const leftOffset = Math.max(0, target.scrollLeft); 8 const topOffset = Math.max(0, target.scrollTop); 9 10 setVerticalScroll(topOffset); 11 setHorizontalScroll(leftOffset); 12}, []); Start/end index OK, the offsets are here now. Naturally, the start and end indexes are easy to calculate with the size of cell and the window from input.\n1const useIndexForDimensions = ({ 2 offset, 3 cellDimension, 4 windowDimension, 5}: DimensionsType) =\u0026gt; { 6 const startIndex = Math.floor(offset / cellDimension); 7 const endIndex = Math.ceil((offset + windowDimension) / cellDimension); 8 return [startIndex, endIndex]; 9}; 10 11... 12 13// calculate the start and end row and column based on the offset 14const [verticalStartIdx, verticalEndIdx] = useIndexForDimensions({ 15 offset: verticalScroll, 16 cellDimension: cellHeight, 17 windowDimension: inputWindowHeight, 18}); 19 20const [horizontalStartIdx, horizontalEndIdx] = useIndexForDimensions({ 21 offset: horizontalScroll, 22 cellDimension: cellWidth, 23 windowDimension: inputWindowWidth, 24}); Grid cell After getting the index, we can just render the element within the range. Just simply slice the data array and pass the width and height to the cell element.\n1const useScrollItem = ({ 2 verticalStartIdx, 3 verticalEndIdx, 4 horizontalStartIdx, 5 horizontalEndIdx, 6 cellWidth, 7 cellHeight, 8 data, 9}: ScrollItemType) =\u0026gt; 10 useMemo(() =\u0026gt; { 11 return data.slice(verticalStartIdx, verticalEndIdx).map((row, i) =\u0026gt; { 12 const rowChildren = row 13 .slice(horizontalStartIdx, horizontalEndIdx) 14 .map((_, j) =\u0026gt; { 15 const vIdx = i + verticalStartIdx; 16 const hIdx = j + horizontalStartIdx; 17 let background = (vIdx + hIdx) % 2 === 1 ? \u0026#34;grey\u0026#34; : \u0026#34;white\u0026#34;; 18 return ( 19 \u0026lt;div 20 key={\u0026#34;row-\u0026#34; + vIdx + \u0026#34;-column-\u0026#34; + hIdx} 21 style={{ 22 background, 23 color: \u0026#34;black\u0026#34;, 24 display: \u0026#34;flex\u0026#34;, 25 justifyContent: \u0026#34;center\u0026#34;, 26 alignItems: \u0026#34;center\u0026#34;, 27 width: cellWidth + \u0026#34;px\u0026#34;, 28 height: cellHeight + \u0026#34;px\u0026#34;, 29 }} 30 \u0026gt; 31 {vIdx}, {hIdx} 32 \u0026lt;/div\u0026gt; 33 ); 34 }); 35 36 return ( 37 \u0026lt;div key={\u0026#34;row-\u0026#34; + i} style={{ display: \u0026#34;flex\u0026#34; }} \u0026gt; 38 {rowChildren} 39 \u0026lt;/div\u0026gt; 40 ); 41 }); 42 }, [ 43 verticalStartIdx, 44 verticalEndIdx, 45 horizontalStartIdx, 46 horizontalEndIdx, 47 cellWidth, 48 cellHeight, 49 data, 50 ]); Html part So the logic part is finished. We also need to render it correctly in the html file. At first, to limit the component in the given size, we need a root element to set the width and height.\n1\u0026lt;div 2 onScroll={onScroll} 3 style={{ 4 width: `${inputWindowWidth}px`, 5 height: `${inputWindowHeight}px`, 6 overflow: \u0026#34;auto\u0026#34;, 7 position: \u0026#34;relative\u0026#34;, 8 }} 9\u0026gt; You can see we bind the onScroll callback function on this root element, and also set the overflow as auto to allow the children elements scrollable.\nSince we do not paint all the elements in the DOM, we must have something to meet two requirements at the same time.\nWe need a child element with big enough size to make the root element scrollable. And its size should allow the visible element display correctly. This child element has no text to display, only has size. 1\u0026lt;div style={{ 2 width: `${cellWidth * data[0].length}px`, 3 height: `${cellHeight * data.length}px`, 4 }} 5\u0026gt; So here the width would be cell width multiple the length of the row and height would be the same. When we scroll the page, actually we are scrolling this non-text element.\nFinally, we need to the parent node to display the visible elements. This is the core part, because when the previous invisible element scrolls, this child element would also have offset. To make sure it displays inside of the window, we need to do transform to it with the offset values calculated from the first step in javascript part.\n1\u0026lt;div 2 style={{ 3 position: \u0026#34;absolute\u0026#34;, 4 transform: `translate(${horizontalScroll}px, ${verticalScroll}px)`, 5 display: \u0026#34;flex\u0026#34;, 6 flexDirection: \u0026#34;column\u0026#34;, 7 }} 8\u0026gt; Deploy to Github pages You can check the source code xfsnowind/react-virtualized-experiment, I also have deployed it to my blog Here.\nActually, I have already deployed my own blog website by Hugo in Github Pages, then how could I deploy this app to a subpage of the website without effecting Hugo. Check here to deploy and here to add command to github actions.\n","link":"https://xfsnowind.github.io/blogs/react-virtualized/","section":"blogs","tags":["Javascript","React","virtualized","Frontend"],"title":"How to implement Virtualized Grid/List in React"},{"body":"","link":"https://xfsnowind.github.io/tags/virtualized/","section":"tags","tags":null,"title":"virtualized"},{"body":"","link":"https://xfsnowind.github.io/tags/git/","section":"tags","tags":null,"title":"Git"},{"body":"Git merge Normally, to get the latest update from main branch during development the feature or fix branch, I would checkout to the main branch and git pull the latest commits and then checkout back and run the merge command.\n1git checkout main 2git pull 3git checkout FEATURE-BUG-BRANCH 4git merge --no-ff development 5 6or 7 8git checkout main 9git pull 10git merge FEATURE-BUG-BRANCH main It works and will create a MERGE commit in the feature branch. It's OK because it's non-destructive operation. But it will always have an extraneous merge commit in the history, which may be fine to have it at the end of development, but not good during the development. So is there a possibility to merge the main branch into our feature branch without a merge commit?\nGit rebase The answer is git rebase. We can try the following:\n1git checkout FEATURE-BUG-BRANCH 2git rebase main This will move the whole feature branch to beginning of the main branch. And instead of creating a merge commit, it will re-write the whole history by making new commits, even there is some merge commits in the feature branch before.\nThe benefit of rebasing would be, first, there is no unrequired merge commits, second, the git history is quite linear, the main branch would be behind the feature branch. However, all of these should be done when there is only one developer, no collaborator. Because rebasing would re-write the commits, so if you collaborate with other developers, the commits from main branch would be different from the public main branch. That would be a hard situation.\nSo before using git rebase, ask yourself, is there another developer working together with you on this branch. If the answer is yes, then use merge instead.\nWhat happen when rebase mixed with merge Let's do some experiment, creating a main and feature branch.\n1\u0026gt; git checkout -b main 2Switched to a new branch \u0026#39;main\u0026#39; 3(main)\u0026gt; touch test.js 4(main)\u0026gt; git add test.js 5(main)\u0026gt; git commit -m \u0026#34;init\u0026#34; 6[main (root-commit) b7c27e8] init 7 1 file changed, 0 insertions(+), 0 deletions(-) 8 create mode 100644 test.js 9 10// feature branch 11(main)\u0026gt; git checkout -b feature 12Switched to a new branch \u0026#39;feature\u0026#39; 13(feature)\u0026gt; touch feature.js 14(feature)\u0026gt; git add feature.js 15(feature)\u0026gt; git commit -m \u0026#34;feature.js\u0026#34; 16[feature 4d60997] feature.js 17 1 file changed, 0 insertions(+), 0 deletions(-) 18 create mode 100644 feature.js So we have one commit in both feature and main branch. Let's create one more commit for each branch.\n1(feature)\u0026gt; git co main 2Switched to branch \u0026#39;main\u0026#39; 3\u0026gt; touch main.js 4(main)\u0026gt; git add main.js 5(main)\u0026gt; git commit -m \u0026#34;main.js\u0026#34; 6[main c593f25] main.js 7 1 file changed, 0 insertions(+), 0 deletions(-) 8 create mode 100644 main.js 9 10(main)\u0026gt; git co feature 11Switched to branch \u0026#39;feature\u0026#39; 12(feature)\u0026gt; touch feature2.js 13(feature)\u0026gt; git add feature2.js 14(feature)\u0026gt; git commit -m \u0026#34;feature2.js\u0026#34; 15[feature 193b518] feature2.js 16 1 file changed, 0 insertions(+), 0 deletions(-) 17 create mode 100644 feature2.js Now, let's merge the main to the feature and check how the history looks like\n1(feature)\u0026gt; git merge --no-ff main 2Merge made by the \u0026#39;ort\u0026#39; strategy. 3 main.js | 0 4 1 file changed, 0 insertions(+), 0 deletions(-) 5 create mode 100644 main.js 6 7(feature)\u0026gt; git log --oneline --graph 8* e99a53e (HEAD -\u0026gt; feature) Merge branch \u0026#39;main\u0026#39; into feature 9|\\ 10| * c593f25 (main) main.js 11* | 193b518 feature2.js 12* | 4d60997 feature.js 13|/ 14* b7c27e8 init Yes, a merge commit is created with merging. Let's check how it looks like with rebasing\n1(feature)\u0026gt; git co main 2Switched to branch \u0026#39;main\u0026#39; 3(main)\u0026gt; touch main2.js 4(main)\u0026gt; git add main2.js 5(main)\u0026gt; git commit -m \u0026#34;main2.js\u0026#34; 6[main 6c43d0f] main2.js 7 1 file changed, 0 insertions(+), 0 deletions(-) 8 create mode 100644 main2.js 9 10(main)\u0026gt; git co feature 11Switched to branch \u0026#39;feature\u0026#39; 12(feature)\u0026gt; touch feature3.js 13(feature)\u0026gt; git add feature3.js 14(feature)\u0026gt; git commit -m \u0026#34;feature3.js\u0026#34; 15[feature dc5fbcb] feature3.js 16 1 file changed, 0 insertions(+), 0 deletions(-) 17 create mode 100644 feature3.js 18 19 (feature)\u0026gt; git rebase main 20Successfully rebased and updated refs/heads/feature. 21(feature)\u0026gt; git log --oneline --graph 22* 3caa16c (HEAD -\u0026gt; feature) feature3.js 23* cd53eed feature2.js 24* 595209c feature.js 25* 6c43d0f (main) main2.js 26* c593f25 main.js 27* b7c27e8 init We can see the feature branch locates on the top of main branch and the history is linear, even we actually have created a merge commit before.\nAnd all the commits in the main branch are kept, while all the commits in feature are, as we said, re-write as new commits, we can see the commit ids/hashes are different.\nLet's do one more step, merge the main to feature again.\n1(feature)\u0026gt; git co main 2Switched to branch \u0026#39;main\u0026#39; 3(main)\u0026gt; touch main-after-rebase.js 4(main)\u0026gt; git add main-after-rebase.js 5(main)\u0026gt; git commit -m \u0026#34;main after rebase\u0026#34; 6[main 92bd62e] main after rebase 7 1 file changed, 0 insertions(+), 0 deletions(-) 8 create mode 100644 main-after-rebase.js 9 10 (main)\u0026gt; git co feature 11Switched to branch \u0026#39;feature\u0026#39; 12(feature)\u0026gt; touch feature-after-main-after-rebase.js 13(feature)\u0026gt; git add feature-after-main-after-rebase.js 14(feature)\u0026gt; git commit -m \u0026#34;feature after main after rebase\u0026#34; 15[feature 2556a80] feature after main after rebase 16 1 file changed, 0 insertions(+), 0 deletions(-) 17 create mode 100644 feature-after-main-after-rebase.js 18 19(feature)\u0026gt; git merge --no-ff main 20Merge made by the \u0026#39;ort\u0026#39; strategy. 21 main-after-rebase.js | 0 22 1 file changed, 0 insertions(+), 0 deletions(-) 23 create mode 100644 main-after-rebase.js 24(feature)\u0026gt; git log --oneline --graph 25* f162af2 (HEAD -\u0026gt; feature) Merge branch \u0026#39;main\u0026#39; into feature 26|\\ 27| * 92bd62e (main) main after rebase 28* | 2556a80 feature after main after rebase 29* | 3caa16c feature3.js 30* | cd53eed feature2.js 31* | 595209c feature.js 32|/ 33* 6c43d0f main2.js 34* c593f25 main.js 35* b7c27e8 init So the merge commit is created as expected, but it's based on the main2.js commit, not from the beginning.\n","link":"https://xfsnowind.github.io/blogs/git-rebase/","section":"blogs","tags":["Learning Notes","Git"],"title":"Learning Notes - Git rebase vs Git merge"},{"body":"","link":"https://xfsnowind.github.io/tags/folderflip/","section":"tags","tags":null,"title":"FolderFlip"},{"body":"Update 2022-11-15: add the images to explain the steps\nAs we presented in the previous article, we have showed how to implement the FolderFlip with limited number (like 3) items with the position: sticky and IntersectionObserver.\nThe Problem But it only allows limited number, if it comes more items or the screen is smaller, the items would not be able to scroll. So how would we display if the items are more and the titles take most of the screen.\nClear the logic first If you want the final answer, just jump to here. Otherwises, I would explain the solutions and the procedures below, also some problems I met.\nThe idea is we only display a certain number of items in the screen, when the items' number reaches the limit with scrolling down/up, the next/previous one would float out to leave the room for the new item, which can be implemented by changing postion to relative like what we have done in the previous blog. So it's like the state transition. I call the state sticky before some item reaches the threshold, when it reaches, the whole component would transit to a state named float. And in the float state, the first item (according to the scroll direction) would be moved out of screen.\nAs we see in the graph,\nwhen the content3 hasn't reach 100% in the screen, the state should be position: sticky; If we scroll down and the content3 reaches threshold 100%, it changes to the state position: relative; If we scroll up, then it will go back the state position: sticky again If we keep scrolling down until it reaches the threshold 0% of content4, the state would be update to position: sticky scroll up would go back the state position: relative And as we know, React is a declarative library, which means you just need to give the required state, React would render it for you anyway, you do not need to know how it's implemented. So it would be good to use state machine diagram to explain the different states and easy to convert the diagram to codes.\nState machine diagram Here are the diagram:\nState machine diagram Define variables and states We define some concepts first:\nWe define a window here, which means the items shown in the screen, and we set it as 3 here; WS or windowStart is the start value of window and its value is START. The original value is 0 and betwee 0 and LENGTH - windowSize; edge element is the upper element which would be checked if it reaches threshold 100% showup element is the lower element which would be checked if it reaches threshold 0 And we can see the variables as well:\nreach100 -\u0026gt; boolean, indicates if the current observed edge element reach threshold 100% reach0 -\u0026gt; boolean, indicates if the current observed showup element reaches threshold 0 edgeIndex -\u0026gt; indicates the observed edge element index in edge element array, the original value is windowStart + windowSize - 1 showupIndex -\u0026gt; indicates the observed showup element index in showup element array, the original value is windowStart + windowSize sectionState -\u0026gt; STICKY or FLOAT, indicates the current state of component windowStart -\u0026gt; window start value, initial value is 0 and range is \u0026gt;= 0 and \u0026lt;= LENGTH - window size According to the state machine diagram, there are three types of states:\nthe normal state, it's normally stable (yellow one) the state triggered by user scroll behavior (pink one) the state should be updated internally (blue one) We will handle each scenario which triggered and started by the scroll event which is solid line in the diagram. One entire process should be end to the normal state whose color is yellow. From the diagram, we can see one process should have three states, except two edge situations.\nThe process is triggered by scrolling down, starting from the original state and transiting to the normal state directly, without scroll state (pink) and internal state (blue); 2. The process is triggered by scrolling up from the final normal state and transites to the normal state directly as well. We need to handle these two situations separately.\nWith only two IntersectionObservers Although there are 6 (for example) items in the list, actually we only need two active observers. One is for the edge element, the other for showup element, although these two elements are not fixed. So why wouldn't we just create two observers and update the observer's observed element dynamically to get the correct state.\nAs you see, it does work if we scroll showly and carefully. But if we swipe the page fast, something begins going wrong. Why? Because when we swipe too fast, the observer could not change to the correct element before observing the changing.\nIntersectionObserver observes multiple elements??? OK, the solution with only two observers does not work. But actually one IntersectionObserver can observe multiple elements, like this:\n1// Create a new observer 2let observer = new IntersectionObserver(function (entries) { 3\tentries.forEach(function (entry) { 4\tconsole.log(entry.target); 5\tconsole.log(entry.isIntersecting); 6\t}); 7}); 8 9// The elements to observe 10let div1 = document.querySelector(\u0026#39;#div-1\u0026#39;); 11let div2 = document.querySelector(\u0026#39;#div-2\u0026#39;); 12 13// Attach them to the observer 14observer.observe(div1); 15observer.observe(div2); so would using one observer on multiple elements save some resources?\nThe answer is no. Not just because there is no big difference, but also it does not work as we expect. According to this blog, only elements that have changed show up in the entries array. So if the element's state not changed, the state would not be in the parameters of observer's callback function, which means we cannot get the correct state of desired element.\nSo actually when we change the state by scrolling behavior or internal updating, we need the state of the observed element which can be saved in an array. When we change the observed element, we just read the state from that array.\nObserver Array So we need to setup an array for every type elment (edge, showup) which saves the value of if the elements reaches the threshold, 0 or 100%. Therefore, we have to create observer for each element. Would it effect the performance? Luckily the answer is also no. According to previous mentioned blog, there is no difference of using many observers with one element each.\nA few years ago, there was a discussion about the performance implications of using this approach on the w3c GitHub repository for this specification. The general conclusion was that using many observers with one element each and one observer with many elements should be about equally performant...\n1const [edgeElementIndex, setEdgeElementIndex] = useState(windowSize - 1); 2const [showupElementIndex, setShowupElementIndex] = useState(windowSize); 3 4// save the edge and showup elements, it should be stable 5const edgeElements = useMemo( 6 () =\u0026gt; [].slice.call(contentElements, windowSize - 1, stepLength), 7 [contentElements, stepLength] 8); 9 10const showupElements = useMemo( 11 () =\u0026gt; [].slice.call(contentElements, windowSize - 1, stepLength), 12 [contentElements, stepLength] 13); 14 15// save all the states of edge and showup elements in the array and 16// get their states update whenever observers are triggered, init values are false 17const [edgeStates, setEdgeStates] = useState([]); 18const [showupStates, setShowupStates] = useState([]); 19 20// initial the content elements 21useEffect(() =\u0026gt; { 22 let tags = elementRef.current.getElementsByClassName(\u0026#34;FolderFlip-Tag\u0026#34;); 23 // get the height of the tag 24 setTagHeight(tags[0].getBoundingClientRect().height); 25 setContentElements( 26 elementRef.current.getElementsByClassName(\u0026#34;FolderFlip-Content\u0026#34;) 27 ); 28}, []); 29 30// the callback function to handle when the folder reaches edge with scrolling down 31// keep updating the state according to observers no matter if the element\u0026#39;s state is used 32const reachEdgeFunc = ([entry], index) =\u0026gt; { 33 setEdgeStates((v) =\u0026gt; { 34 let value = [...v]; 35 value[index] = entry.isIntersecting || entry.boundingClientRect.top \u0026lt; 0; 36 return value; 37 }); 38}; 39 40const folderShowUpFunc = ([entry], index) =\u0026gt; { 41 setShowupStates((v) =\u0026gt; { 42 let value = [...v]; 43 value[index] = entry.isIntersecting; 44 return value; 45 }); 46}; 47 48// set up the observer for edge element with threshold 100% 49useIntersection(edgeElements, reachEdgeFunc, { 50 threshold: 1.0 51}); 52 53// set up the observer for showup element with threshold 0% 54useIntersection(showupElements, folderShowUpFunc, { 55 threshold: 0 56}); We use useMemo to save the edgeElements and showupElements to avoid re-rendering. And create arrays edgeStates and showupStates to save the states of all the elements. To get the correct observed element's state, we also need edgeIndex and showupIndex. When certain element reaches the threshold and triggers the callback function, it passes entry and the index in state array.\nuseIntersection needs to update as well:\n1function useIntersection(nodeElements, callbackFunc, options) { 2 let observers = useMemo(() =\u0026gt; { 3 if (typeof IntersectionObserver === \u0026#34;undefined\u0026#34;) return; 4 5 return nodeElements.map( 6 (_, i) =\u0026gt; 7 new IntersectionObserver( 8 (entries) =\u0026gt; { 9 callbackFunc(entries, i); 10 }, 11 { 12 threshold: options.threshold 13 } 14 ) 15 ); 16 }, [nodeElements, callbackFunc, options.threshold]); 17 18 useEffect(() =\u0026gt; { 19 observers.forEach((observer, i) =\u0026gt; { 20 if (nodeElements[i]) { 21 if (observer) observer.observe(nodeElements[i]); 22 } 23 }); 24 25 return () =\u0026gt; { 26 observers.forEach((observer) =\u0026gt; { 27 if (observer) observer.disconnect(); 28 }); 29 }; 30 }, [nodeElements, observers]); 31} But here comes another problem, it seems too many useState, and each of them hangs out with others, to handle the logic, it's better to put them in one function. The state transition could be processed there. How to implement this?\nuseReducer makes my day The answer is useReducer in React.\nreducer and dispatcher are the concepts from Redux, even though we do not use it here, but useReducer was introduced to React as well.\n1const [state, dispatch] = useReducer(reducer, initialArg, init); So we can handle all the variables in the reducer and update the UI according to the returned state. Also use dispatch to send the state from observer's callback function.\n1// the callback function to handle when the folder reaches edge with scrolling down 2// keep updating the state according to observers no matter if the element\u0026#39;s state is used 3const reachEdgeFunc = useCallback( 4 ([entry], index) =\u0026gt; 5 dispatchFunc({ 6 type: REDUCER_TYPE.edge, 7 payload: { 8 index, 9 value: entry.isIntersecting || entry.boundingClientRect.top \u0026lt; 0 10 } 11 }), 12 [dispatchFunc] 13); 14 15const folderShowUpFunc = useCallback( 16 ([entry], index) =\u0026gt; 17 dispatchFunc({ 18 type: REDUCER_TYPE.showup, 19 payload: { index, value: entry.isIntersecting } 20 }), 21 [dispatchFunc] 22); Here we use useCallback to avoid re-rendering in hooks useIntersection. And the payload contains the element index and the state of element.\nThe reducer takes state and action as parameters and should be pure, which means with the same input, the output should also not change. Note: Within StrictMode of React, the reducer would be called twice with same value.\n1function FolderFlipReducer(state, action) { 2 if (!action) return state; 3 4 // set the value of edge state with given index 5 if (action.type === REDUCER_TYPE.edge) { 6 state.edgeStates[action.payload.index] = action.payload.value; 7 } else if (action.type === REDUCER_TYPE.showup) { 8 state.showupStates[action.payload.index] = action.payload.value; 9 } 10 11 let edgeIndex = state.edgeIndex, 12 showupIndex = state.showupIndex, 13 sectionState = state.sectionState, 14 windowStart = state.windowStart; 15 16 const reach0 = state.showupStates[state.showupIndex - windowSize + 1], 17 reach100 = state.edgeStates[state.edgeIndex - windowSize + 1]; 18 19 // if the prev state is initial stable state, just update the section state 20 if (!reach0 \u0026amp;\u0026amp; reach100 \u0026amp;\u0026amp; edgeIndex + 1 === showupIndex) { 21 sectionState = SECTION_STATE.float; 22 return { 23 ...state, 24 sectionState 25 }; 26 } 27 28 // if the prev state is final stable state 29 if (reach0 \u0026amp;\u0026amp; !reach100 \u0026amp;\u0026amp; edgeIndex === showupIndex) { 30 sectionState = SECTION_STATE.sticky; 31 return { 32 ...state, 33 sectionState 34 }; 35 } 36 37 // all the other four situations would need to be handled under state type scroll 38 // handle the pink ones in state machine diagram 39 40 // if edge and showup observed elements are the same, set the state as float 41 if (edgeIndex === showupIndex) sectionState = SECTION_STATE.float; 42 43 // otherwises, sticky 44 if (edgeIndex + 1 === showupIndex) sectionState = SECTION_STATE.sticky; 45 46 // need to update the edge and showup index in the internal state type 47 48 if (sectionState === SECTION_STATE.float) { 49 if (reach0 \u0026amp;\u0026amp; reach100) { 50 if (windowStart + windowSize \u0026lt; state.stepLength) 51 showupIndex = windowStart + windowSize; 52 } else if (!reach0 \u0026amp;\u0026amp; !reach100) { 53 windowStart = state.windowStart \u0026gt; 0 ? state.windowStart - 1 : 0; 54 edgeIndex = state.windowStart + windowSize - 2; 55 } 56 } 57 58 if (sectionState === SECTION_STATE.sticky) { 59 if (!reach0 \u0026amp;\u0026amp; !reach100) { 60 if (windowStart \u0026gt; 0) showupIndex = windowStart + windowSize - 1; 61 } else if (reach0 \u0026amp;\u0026amp; reach100) { 62 edgeIndex = windowStart + windowSize; 63 windowStart = 64 state.windowStart + windowSize \u0026lt; state.stepLength 65 ? state.windowStart + 1 66 : state.stepLength - windowSize; 67 } 68 } 69 70 return { 71 ...state, 72 windowStart, 73 edgeIndex, 74 showupIndex, 75 sectionState 76 }; 77} So til now, we have explained and presented the solution, the page works quite stable. Below is the full codes and welcome any comments.\n","link":"https://xfsnowind.github.io/blogs/folderflip-version2/","section":"blogs","tags":["Javascript","React","FolderFlip","Frontend"],"title":"How to implement a FolderFlip 2"},{"body":"Haven't updated the blogs for a long time. Just had been struggling on the house work during the whole summer time, painting external and internal wall, new bathroom and etc. But there is still the good news, implemented an interesting frontend component with React, which would inspired by lifeatspotify - borrow the name FolderFlip.\nThe original idea was come up with by the UX designer in our team, she would like to develop a fancy component which can be used to present the company culture. Here is how it looks like:\nAfter investing, I found it can be done with the css feature position: sticky and javascript's IntersectionObserver.\nTip: position: sticky This is not a new feature, but I rarely used it before because of not fully supported by all the browsers before. But now definitely it's supported by all the main stream browsers. Check CanIUse.\nLet's start with creating a list with three items which consists of a title and some simple texts as the content. And before the list, it also has some texts.\nWe can see when we scroll down and the list enters the screen, all the three titles would always be inside of screen with setting the value of top, bottom and margin-top. And display the titles in order according to the item's index in the list.\n1marginTop: `${tagHeight * idx}px`, 2top: `${idx * tagHeight}px`, 3bottom: `${(stepLength - idx - 1) * tagHeight}px` Here there is one thing I would like to mention. When we use position: sticky, the stickied item would be attached to its parent node, to make all the titles have the same parent node, we use React's fragment to compose each item.\n1\u0026lt;React.Fragment key={\u0026#34;FolderFlipStep\u0026#34; + Title.value + idx}\u0026gt; 2 \u0026lt;div id={id}\u0026gt;\u0026lt;/div\u0026gt; 3 \u0026lt;a 4 href={\u0026#34;#\u0026#34; + id} 5 className=\u0026#34;FolderFlip-Tag\u0026#34;\u0026gt; 6 \u0026lt;span className=\u0026#34;FolderFlip-Tag-Number\u0026#34; /\u0026gt; 7 \u0026lt;h2\u0026gt;{Title.value ?? \u0026#34;\u0026#34;}\u0026lt;/h2\u0026gt; 8 \u0026lt;/a\u0026gt; 9 \u0026lt;div className=\u0026#34;FolderFlip-Content\u0026#34;\u0026gt; 10 \u0026lt;span className=\u0026#34;FolderFlip-Content-Title\u0026#34;\u0026gt;{Title ?? \u0026#34;\u0026#34;}\u0026lt;/span\u0026gt; 11 \u0026lt;div className=\u0026#34;FolderFlip-Content-Container\u0026#34;\u0026gt; 12 \u0026lt;div\u0026gt;{Ingress}\u0026lt;/div\u0026gt; 13 \u0026lt;button\u0026gt;{Button}\u0026lt;/button\u0026gt; 14 \u0026lt;/div\u0026gt; 15 \u0026lt;/div\u0026gt; 16\u0026lt;/React.Fragment\u0026gt; OK, now it seems we have fixed the most important feature of the component. Nja, kind of. Actually, maybe you have found it when we keep scrolling down (there are some texts under the list as well) and beyond the list, the titles are still sticky and only contents move up. Definitely the title should move together with contents fluently. How do we solve this?\nFloating with IntersectionObserver It comes the js API IntersectionObserver, which observes how the node intersects with the specified master node (defaultly and normally it's the screen) in the non-main process. For detail and description, you can check Mozilla's doc.\n1let observer = new IntersectionObserver( 2 ([entry]) =\u0026gt; { 3 console.log(\u0026#34;reach 100%\u0026#34;); 4 }, 5 { 6 threshold: 1.0 7 } 8); 9 10observer.observe(element); In this example, when the node reaches 100% in the screen, it would print out the log.\nTherefore, the logic would be simple, when the content of the last item reaches the threshold 100% (taking the screen as master), we would change the items inside the screen from position: sticky to position: relative to allow the items float.\n1let observer = new IntersectionObserver( 2 ([entry]) =\u0026gt; { 3 setIntersection( 4 entry.isIntersecting || entry.boundingClientRect.top \u0026lt; 0 5 ); 6 }, 7 { 8 threshold: 1.0 9 } 10); 11 12useEffect(() =\u0026gt; { 13 observer.observe(textRef.current); 14 15 return () =\u0026gt; { 16 observer.disconnect(); 17 }; 18}, [observer]); In the code, the variable observer would be created every time when the page renders which would disconnect the observer and observe the same element again in useEffect. To avoid this, we can use useMemo to reserve the observer from rendering and we can pass a memorized callback function to deal with the entries. And we can create a new hooks to handle this:\n1function useIntersection (textRef, callbackFunc) { 2 let observer = useMemo(() =\u0026gt; { 3 return new IntersectionObserver(callbackFunc, 4 { 5 threshold: 1.0 6 } 7 ); 8 }, [callbackFunc]); 9 10 useEffect(() =\u0026gt; { 11 if (textRef?.current) observer.observe(textRef.current); 12 13 return () =\u0026gt; { 14 observer.disconnect(); 15 }; 16 }, [textRef, observer]); 17} And we can use this hooks to observe the last item of the list.\n1 const textRef = useRef(null); 2 3 const callbackFunc = useCallback( 4 ([entry]) =\u0026gt; 5 setIntersection(entry.isIntersecting || entry.boundingClientRect.top \u0026lt; 0), 6 [] 7 ); 8 9 useIntersection(textRef, intersectCallbackFunc); 10 11 ... 12 13 return (\u0026lt;React.Fragment\u0026gt; 14 \u0026lt;div 15 className=\u0026#34;FolderFlip-Content\u0026#34; 16 ref={stepLength - 1 == idx ? textRef : undefined} 17 \u0026gt;\u0026lt;/div\u0026gt; 18 \u0026lt;/React.Fragment\u0026gt;) Notice that the textRef is a React ref which would not trigger the execution of useEffect when it changes.\nNow we can see when we keep scrolling down, the whole items move out of the screen fluently.\nWhat if more items? Till now, we have implemented the component. And maybe someone has noticed that we have only three items in the example, what if there are more items, like 6 or more? And actually the title of items would take over the whole screen, the content of the item would only have a very small part of the screen or even cannot show, especially in mobile. How could we fix that?\nThe solution to this in simple would be that we set maximum value of displayed items in the screen, like 3, no matter how many items we have. And definitely it is more complicated and will be explained in the next article.\n","link":"https://xfsnowind.github.io/blogs/folderflip/","section":"blogs","tags":["Javascript","React","FolderFlip","Frontend"],"title":"How to implement a FolderFlip with React"},{"body":"","link":"https://xfsnowind.github.io/tags/azure/","section":"tags","tags":null,"title":"Azure"},{"body":"This blog is about the Azure developer challenge from Sparebanken Vest. I would like to write the learning notes here.\nExplore Azure App Service Target: Learn about the key components of Azure App Service and how App Service can help you create, maintain, and deploy web apps more efficiently.\nAzure App Service So what is Azure App Service? It's a Http-based service, which would server for web application, REST APIs and mobile backends. It can:\nauto scale support CI/CD support Deployment slots -- support different deployment environment, like stage, prod Linux support. But have some limitaions: Not support on Shared pricing tier; Cannot mix Windows and Linux in same App service plan; Cannot mix Windows and Linux apps in the same resource group after Jan 21, 2021; Azure Portal shows only working features Azure App Service plans An app runs in an App Service plan and each plan defines:\nRegion (West US, North Euro, etc) Number of VM instances Size of VM instances Pricing tier (Free, Shared, Basic, Premium and etc) And pricing tier decides what feature you can use:\nShared compute: Both Free and Shared share the resource pools and can't scale out. Dedicated compute: The Basic, Standard, Premium, PremiumV2, and PremiumV3 tiers run apps on dedicated Azure VMs. Isolated: This tier runs dedicated Azure VMs on dedicated Azure Virtual Networks and provides the maximum scale-out capabilities. Consumption: This tier is only available to function apps. It scales the functions dynamically depending on workload. In the Free and Shared tiers, app cannot scale out. And apps in the same App Service plan would share the same VM instances.\nWhen we add a new app, we need to understand the expected load for the new app. If it\nis resource intensive; needs resource in other geographical region; is scaled out independently from other apps; , we can isolate it into a new App Service plan. Deploy We can deploy App Service automatically from\nAzure DevOps Github Bitbucket Or manually through:\nGit CLI - az webapp up would create a new App Service web app and deploy it; Zip deploy - Use curl or similar Http utility to send a ZIP to App Service; FTP/S Deployment slots can be used when deploying a new production build.\nAuthentication and Authorization in App Service Built-in authentication can save time and effort with OpenID identity providers:\nMicrosoft Identity Platform Facebook Google Twitter Any OpenID connect provider The authentication and authorization will run in the same sandbox as application code and every incoming Http request would be handled with:\nauthenticating with the specified provider validating, storing and refreshing tokens managing the authenticated session injecting identity information to request headers Authentication flow:\nSign user in Post authentication Establish authenticated session Serve authenticated content In Azure portal, we can also configure App Service when the request is not authenticated:\nAllow unauthenticated requests Require authentication with Http 401/403 Networking features Sometimes we need to control the inbound and outbound network traffic. And features of inbound and outbound cannot be used to each other.\nInbound features Outbound features App-assigned address Hybrid Connections Access restrictions Gateway-required virtual network integration Service endpoints Virtual network integration Private endpoints But we can mix some features to solve the problems with a few exceptions.\nInbound use case Feature Support IP-based SSL needs for your app App-assigned address Support unshared dedicated inbound address for your app App-assigned address Restrict access to your app from a set of well-defined addresses Access restrictions Scale apps in Azure App Service Target Learn how autoscale operates in App Service and how to identify autoscale factors, enable autoscale, and how to create sound autoscale conditions.\nAutoscale factors Autoscaling can be triggered by defined rules and also deallocate resources when workload has diminished.\nAzure provides two options for autoscaling:\nScale based on a metric, like: CPU Percentage. Memory Percentage. Disk Queue Length. Http Queue Length. Data In. Data Out. Scale to a specific instance count according to a schedule. For example, you can arrange to scale out at a particular time of day, or on a specific date or day of the week. You also specify an end date, and the system will scale back in at this time. Azure App Service deployment slots Target In this module you will learn how slot swapping operates and how to perform a swap. You will also learn how to route traffic to different slots manually and automatically.\nExplore staging environments Deployment slot is supported in the Standard, Premium, or Isolated App Service plan tier.\nThe benefits to have the non-production deployment slot is\nvalidate the app changes in the staging environment Deploy an app and swap with production deployment can eliminate the downtime Easy to swap back to the last good site if the swapped one is not as we expected Develop for Azure Cache for Redis Target Learn how to configure Azure Cache for Redis, interact with the cache, and connect an application to Azure Cache for Redis by using .NET.\nScenarios Pattern Description Data cache Databases are often too large to load directly into a cache. It's common to use the cache-aside pattern to load data into the cache only as needed. When the system makes changes to the data, the system can also update the cache, which is then distributed to other clients. Content cache For static content for template. We can use in-memory cache to provide quick access Session store Commonly used in shopping carts or user history data that might associate with cookie. But the data is too large for cookie. We can use Cookie as a key to query the data in in-memory cache, to associate information with a user quickly. Job and message queuing Applications often add tasks to a queue when the operations associated with the request take time to execute. Longer running operations are queued to be processed in sequence, often by another server. This method of deferring work is called task queuing. Distributed transactions Azure Cache for Redis supports executing a batch of commands as a single transaction. Configuration Recommend always use Standard or Premium Tier for production system.\nWith Premium tier, you get supports:\nVirtual Network Clustering The access key is like the password to cache. There are a primary and a secondary key, we can use either, but we should update the key periodically.\nImplement Azure Key Vault Target Learn how Azure Key Vault can help you keep your apps more secure, and how to set and retrieve secrets by using the Azure CLI.\nExplore Azure Key Vault The Azure Key Vault service supports two types of containers: vaults and managed hardware security module(HSM) pools.\nAzure Key vault would manage:\nSecrets - tokens, passwords, certificates, API keys, and other secrets Key - encryption keys used to encrypt your data. Certificate - public and private Secure Sockets Layer/Transport Layer Security (SSL/TLS) certificates A Premium tier would include hardware security module(HSM)-protected keys.\nBenefites:\nCentralized application secrets Securely store secrets and keys Monitor access and use Simplified administration of application secrets Best Practices:\nUse separate key vaults: Recommended to use a vault per application per environment (Development, Pre-Production and Production).\nControl access to your vault: Key Vault data is sensitive and business critical, you need to secure access to your key vaults by allowing only authorized applications and users.\nBackup: Create regular back ups of your vault on update/delete/create of objects within a Vault.\nLogging: Be sure to turn on logging and alerts.\nRecovery options: Turn on soft-delete and purge protection if you want to guard against force deletion of the secret.\nAuthenticate to Azure Key Vault Authentication with Key Vault works in conjunction with Azure Active Directory, which is responsible for authenticating the identity of any given security principal.\nAccess tokens must be sent to the service using the HTTP Authorization header:\n1PUT /keys/MYKEY?api-version=\u0026lt;api_version\u0026gt; HTTP/1.1 2Authorization: Bearer \u0026lt;access_token\u0026gt; Explore Azure Cosmos DB Target Learn the core features and functionality of Azure Cosmos DB.\nBenefits Unlimited elastic write and read scalability. 99.999% read and write availability all around the world. Guaranteed reads and writes served in less than 10 milliseconds at the 99th percentile. Explore the resource hierarchy hierarchy of different entities in an Azure Cosmos DB account\nCosmos entities An Azure Cosmos database is mapped to various API-specific entities:\nAzure Cosmos entity SQL API Cassandra API Azure Cosmos DB API for MongoDB Gremlin API Table API Azure Cosmos database Database Keyspace Database Database N/A The mapping of API-specific entities to an Azure Cosmos item:\nCosmos entity SQL API Cassandra API Azure Cosmos DB API for MongoDB Gremlin API Table API Azure Cosmos item Item Row Document Node or edge Item Consistency With Azure Cosmos DB, developers can choose from five well-defined consistency models on the consistency spectrum. From strongest to more relaxed, the models include:\nstrong bounded staleness session consistent prefix eventual Five Consistency Levels TBC Explore the Microsoft identity platform Target Learn the core features and functionality of the Microsoft identity platform which includes authentication service, open-source libraries, and application management tools to enable and control access to resources.\nComponents Microsoft identity platform consist of several components:\nOAuth 2.0 and OpenID Connect standard-compliant authentication service enabling developers to authenticate several identity types, including:\nWork or school accounts, provisioned through Azure Active Directory Personal Microsoft account, like Skype, Xbox, and Outlook.com Social or local accounts, by using Azure Active Directory B2C Open-source libraries: Microsoft Authentication Libraries (MSAL) and support for other standards-compliant libraries\nApplication management portal\nApplication configuration API and PowerShell\nService principals An application must be registered with an Azure Active Directory tenant.\nCreate and deploy Azure Resource Manager templates Target Learn how Azure Resource Manager (ARM) can help streamline deployments, choose the correct deployment mode for your solution, and create and deploy an ARM template.\nAzure Resource Manager role Microsoft Graph Target Learn how Microsoft Graph facilitates the access and flow of data and how to form queries through REST and code\nMicrosoft Graph is the gateway to data and intelligence in Microsoft 365. It provides a unified programmability model that you can use to access the tremendous amount of data in Microsoft 365, Windows 10, and Enterprise Mobility + Security.\nThree main components to access and facilitate data:\nThe Microsoft Graph API offers a single endpoint, https://graph.microsoft.com Microsoft Graph connectors Microsoft Graph Data Connect Best practices Consent and authorization:\nUse least privilege Use the correct permission type based on scenarios. Consider the end user and admin experience. Consider multi-tenant applications. Handle responses effectively\nPagination Evolvable enumerations Provision virtual machines in Azure Target Learn the availability and sizing options of Azure Virtual Machines, and how to create a virtual machine by using the Azure CLI.\nExplore Azure virtual machines Design considerations for virtual machine creation:\nAvailability VM size VM limits - The current limit on a per subscription basis is 20 VMs per region VM image VM disks Standard disks - HDDs, deal for a cost effective dev and test workload Premium disks - SSD, Perfect for VMs running production workload. ","link":"https://xfsnowind.github.io/blogs/azure-challenge/","section":"blogs","tags":["Learning Notes","Azure"],"title":"Learning Notes - Azure Challenge"},{"body":"This article is a summary when I learned the React Hooks course in GeekTime. Even though we all use React Hooks in the frontend development, I cannot say I understand the internal core and logic of it. So this is a good time to re-learn it through this course. According to my experience, it's definitely better to write down the idea and thoughts down -- The palest ink is better than the best memory. Therefore have this article. And I would follow the course's original structure to organize the article.\nBasic chapter Reason to Hooks The nature of React is mapping the Model to View and the Model is the Component's props and state. So when Model's data change, React does not care how they change, it only focuses on the difference. And this is what we called declarative and this is implemented by React's diff function.\nSo UI presentation is more like execution of function. Model is parameter, View is function and the result would be the Dom's change. React just confirms to execute the process of changing in an optimized way.\nBefore we use class to create React Component, but actually it's not suit for React Component:\nWe rarely use inheritance in React Component; React is state driven and does not need generated instance's methods; But function also has its own limitation:\nFunction cannot provide internal state, it must be a pure function; Function cannot provide the entire lifecycle; The comes React Hooks.\nReact Hooks \u0026quot;binds\u0026quot; or \u0026quot;hooks\u0026quot; the target to some may changed data or event source. And when the hooked data or event change, the target would be executed again to generate the new result.\nThe hooked source can be not only data, also the result of another Hooks execution.\nHooks is created with the background of using High order Component, and it solves the problems of wrapper hell and code hard to understanding.\nHooks basic usage useState -- The principle of using useState is unnecessary to save the value which can be gotton from calculating. useEffect -- Should only be used to execute the code which would not effect the current result, not effect the rendered UI. And also be careful for the deps, it use reference to check if values have been changed, so take care of object and array. NB: useEffect is called after rendering useCallback -- The purpose is when need to pass function as parameter to UI, avoid triggering React render component. useMemo -- can be treated as combination of useEffect and useState. When deps change, execute useEffect to calculate the value and set the value through useState useRef Share data between multiple rendering Save the ref of a Dom node useContext -- define the global state useEffect can be equivalent to componentDidMount, componentDidUpdate and componentWillUnmount, but not exactly. The difference is\nuseEffect's callback functions are triggered only when deps change. While componentDidUpdate would be called every rendering useEffect's callback function return a function, which is used to clean, would be triggered before deps change or component unmount. If we need a constructor feature, we can use the code below:\n1function useSingleton(callback) { 2 // 用一个 called ref 标记 callback 是否执行过 3 const called = useRef(false); 4 // 如果已经执行过，则直接返回 5 if (called.current) return; 6 // 第一次调用时直接执行 7 callBack(); 8 // 设置标记为已执行过 9 called.current = true; 10} NB: Hooks can implement most functionalities of lifecycle, but not for getSnapshotBeforeUpdate, componentDidCatch, getDerivedStateFromError. These can only be implemented by class.\nPractice Data consistence The principle of using useState is keep state minimum.\nIf the data can be calculated or generated by the existing ones, then we should not store them in state.\nWhen we define the new state, ask yourself: is this state necessary? Can it be obtained by calculation? Is it just a middleware state?\nHandle rendering scenario Since Hooks cannot be handled in conditions and loops, we should move the condition into useEffect og create a wrapper for the component and return null in some conditions.\nAlthough we have Hooks now, it can only be used for logical reuse. If it comes to the UI behaviour, Hooks cannot play a role then. Therefore, we can use Render props mode.\nRender props Mode is just another presentation of High-ordering Component, which means Component takes functions as paramter or return functions. And then we can use the passed function to render, kind of like dependency injection. For example:\n1function CounterRenderProps({ children }) { 2 const [count, setCount] = useState(0); 3 const increment = useCallback(() =\u0026gt; { 4 setCount(count + 1); 5 }, [count]); 6 const decrement = useCallback(() =\u0026gt; { 7 setCount(count - 1); 8 }, [count]); 9 10 return children({ count, increment, decrement }); 11} 12 13function CounterRenderPropsExample() { 14 return ( 15 \u0026lt;CounterRenderProps\u0026gt; 16 {({ count, increment, decrement }) =\u0026gt; { 17 ... 18 }} 19 \u0026lt;/CounterRenderProps\u0026gt; 20 ); 21} So we leave children to render to make code reusable. Here, it does not have to be children, it can be any functions.\nSelf defined event When we bind an event to a node, because of Virtual Dom, React would bind the event to the app's root node. Before version 17, it's on document, after version 17, it's the react's root node. The reason to do this:\nWhen Virtual Dom renders, the node may have not been mounted to the page, so it cannot bind; It can block all the details from low level and avoid browser's compatible problem So React's event actually is the callback function.\nOrganize project structure via business To reduce the complexibility, we can organize the project based on service characteristic, so each feature can be independent and easy to manage and maintain.\nTo meet the requirement of low coupling, we can define some high level, abstract components to be reused among components.\nForm React is state driven, while Form is event driven。 The difference of React's onChange and html's onchange is onChange would be called whenever user inputs, while onchange is only triggered when the input loses focus.\nControlled vs uncontrolled For uncontrolled component, it would not pass the value to component, can only get the value actively, like useRef. The advantage is it would not toggle the rendering, although we cannot see the change of value as well.\nWhile for controlled component, it accepts value as props and add a callback function to update it.\nForm elements If we use Controlled component to build form, it would have three core parts:\nthe type of form element bind the value handle the onChange event So Hooks' contribution to form is, we can save the form's values to Hooks and provide the function to handle them through useState. For example:\n1import { useState, useCallback } from \u0026#34;react\u0026#34;; 2 3const useForm = (initialValues = {}) =\u0026gt; { 4 // define the state for the whole form：values 5 const [values, setValues] = useState(initialValues); 6 7 // provide a method to set the value of some field 8 const setFieldValue = useCallback((name, value) =\u0026gt; { 9 setValues((values) =\u0026gt; ({ 10 ...values, 11 [name]: value, 12 })); 13 }, []); 14 15 // return the values and the method 16 return { values, setFieldValue }; 17}; ","link":"https://xfsnowind.github.io/blogs/geektime/react-hooks/","section":"blogs","tags":["Javascript","React Hooks","Learning Notes"],"title":"Learning Notes - React Hooks"},{"body":"","link":"https://xfsnowind.github.io/tags/react-hooks/","section":"tags","tags":null,"title":"React Hooks"},{"body":"","link":"https://xfsnowind.github.io/tags/promise/","section":"tags","tags":null,"title":"Promise"},{"body":"Promise is a general concept to handle the asynchronize development in javascript. It's not hard to use, but when it comes with some other concepts, like react's hook, its internal chain etc. It always takes me some time to think through it. Especially when check the code of some open-source libraries, find the way they use Promise is quite fancy and also hard to understand, which reminders me that I am still stay on the level of using, far away from deep understanding.\nInspired by this blog, I think it's a good idea to write promise by myself. It's not only because it's not that hard and complex, it can also help me in the future work when I meet it again. Thesedays, function programing is quite popular in js development, but object-orient coding is still used in lots of scenarioes. So I would like to try to implement it with both function and class, even though javascript's prototype is almost equal to class concept, which was introduced in ES2015. It can also train these basic skills again. I would deploy them in my github and write blogs to record it.\nThanks to promise/A+, we get the requirement analysis, clear logic and library to test the solution.\nSteps According to the Promise/A+'s requirements, I think it would be four steps:\nBasic then function -- 1.1, 1.2 Fulfill Promise and then parameters -- from 2.1 to 2.2.5 Return a Promise in then -- 2.2.6, 2.2.7 resolve function -- 2.3 Basic thenable According to the Terminology, the first two are promise and thenable. The former should take a function (an executor) as parameter which would take two functions (resolve and reject) as parameters as well. Check Higher-order functions. These resolve and reject would be used in the executor and defined in the then's parameters. Let's simply implement this thenable first.\n1function Promise(executor) { 2 let self = this; 3 self.executor = executor; 4} 5 6Promise.prototype.then = function (onFulfilled, onRejected) { 7 let self = this; 8 self.executor(onFulfilled, onRejected); 9}; As we see, we just delay the execution of executor from Promise to then and the fulfill and reject functions are used in executor while defined or passed in then.\nWe can use below code to test it. NB: do not use arrow function in definition, because arrow function does not own this. If we use this inside of it, it would refer to the outer function. Check here.\n1const a = new Promise((resolve) =\u0026gt; setTimeout(() =\u0026gt; resolve(\u0026#34;result\u0026#34;), 100)); 2 3a.then((data) =\u0026gt; console.log(\u0026#34;Data\u0026#34;, data)); 4// console.log -\u0026gt; Data: result But obviously here, we only have one executor and the parameters are not validated. Besides executor runs in the then, not in the Promise. Currently, the code is simple, but it would cause problems. We will mention this below, let's go further.\nFulfill Promise and then parameters Validate then parameters 2.2.1 Both onFulfilled and onRejected are optional arguments:\n2.2.1.1 If onFulfilled is not a function, it must be ignored.\n2.2.1.2 If onRejected is not a function, it must be ignored.\nonFulfilled and onRejected should be validated:\n1let fulfillFunc = isFunction(onFulfilled) ? onFulfilled : (value) =\u0026gt; value; 2let rejectFunc = isFunction(onRejected) 3 ? onRejected 4 : (e) =\u0026gt; { 5 throw e; 6 }; Update state After validating the parameters, we can implement the point 2.2.2 and 2.2.3. Translate here:\nIf onFulfilled/onRejected is a function,\nit must be called after promise is fulfilled/rejected, with promise's value/reason as its first argument;\nit must not be called before promise is fulfilled/rejected;\nit must not be called more than once;\nSo we need to set the state and pass the value or reason to related functions. To do this, I wrap the validated functions and update internal states inside of them:\n1// 2.2.2.1 onFulfilled must be called after promise is fulfilled, with promise’s value as its first argument. 2function resolve(value) { 3 if (self.state === STATE.PENDING) { 4 // 2.2.2.2 it must not be called before promise is fulfilled. 5 self.state = STATE.FULFILLED; 6 self.value = value; 7 fulfillFunc(value); 8 } 9} 10 11// 2.2.3.1 onRejected must be called after promise is rejected, with promise’s reason as its first argument. 12function reject(err) { 13 if (self.state === STATE.PENDING) { 14 // 2.2.3.2 it must not be called before promise is rejected. 15 self.state = STATE.REJECTED; 16 self.value = err; 17 rejectFunc(err); 18 } 19} Asynchronized execution According to the first point 2.2.4 refering NOTE 3.1, we should execute the fulfill and reject functions asynchronously, which is the main reason for people using it. In javascript, we can utilize setTimeout.\n1setTimeout(() =\u0026gt; fulfillFunc(value), 0); Return Promise in then Before we continue implementing the rest requirement, we need to reorganize the codes first. We need to move the executor from then to the constructor of Promise.\nWhy? One main reason is we will execute the executor multiple times if it's in then, since one promise can have multiple thens. This is definitely unacceptable because we only need to execute executor once.\nSo til now, the Promise function looks like this:\n1function Promise(executor) { 2 let self = this; 3 4 // set the state as pending, 2.1.1 5 self.state = STATE.PENDING; 6 7 // 2.2.2.1 onFulfilled must be called after promise is fulfilled, with promise’s value as its first argument. 8 function resolve(value) { 9 if (self.state === STATE.PENDING) { 10 // 2.2.2.2 it must not be called before promise is fulfilled. 11 self.state = STATE.FULFILLED; 12 self.value = value; 13 setTimeout(() =\u0026gt; resolveFunc(value), 0); 14 } 15 } 16 17 // 2.2.3.1 onRejected must be called after promise is rejected, with promise’s reason as its first argument. 18 function reject(err) { 19 if (self.state === STATE.PENDING) { 20 // 2.2.3.2 it must not be called before promise is rejected. 21 self.state = STATE.REJECTED; 22 self.value = err; 23 setTimeout(() =\u0026gt; rejectFunc(err), 0); 24 } 25 } 26 27 try { 28 // executor is function whose parameters is resolve and reject functions, 29 // which would be called inside of executor. 30 if (isFunction(executor)) executor(resolve, reject); 31 } catch (err) { 32 reject(err); 33 } 34} And you may notice we use the function resolveFunc and rejectFunc, but we haven't define them. They would work together with the requirement of multiple calling of then.\nCall then mutiple times 2.2.6 2.2.6 then may be called multiple times on the same promise.\nSo all the respective fulfill/reject functions should be called in the order of original calls. Obviously, we can apply a queue here. Create a callback queue, add then's onFulfilled and onRejected parameters to it and handle it when fulfilled/rejected. And this is how we handle the above resolveFunc and rejectFunc.\n1function resolve(value) { 2 ... 3 // 2.2.6.1 4 setTimeout( 5 () =\u0026gt; self.callback.forEach(({ resolveFunc }) =\u0026gt; resolveFunc(value)), 6 0 7 ); 8} 9 10function reject(err) { 11 ... 12 // 2.2.6.2 13 setTimeout( 14 () =\u0026gt; self.callback.forEach(({ rejectFunc }) =\u0026gt; rejectFunc(err)), 15 0 16 ); 17} When Promise is fulfilled/rejected, we would execute all the related functions in the queue. And obviously, we have to push the callback functions to the queue in then when the state is still pending.\n1Promise.prototype.then = function (onFulfilled, onRejected) { 2 let self = this; 3 4 // 2.2.1 Both onFulfilled and onRejected are optional arguments, if any is not function, must ignore it 5 let fulfillFunc = isFunction(onFulfilled) ? onFulfilled : (value) =\u0026gt; value; 6 let rejectFunc = isFunction(onRejected) 7 ? onRejected 8 : (e) =\u0026gt; { 9 throw e; 10 }; 11 12 switch (self.state) { 13 // if the state is fulfilled or rejected, just execute the related function and pass the result to the resolvePromise 14 case STATE.FULFILLED: 15 case STATE.REJECTED: 16 return setTimeout(() =\u0026gt; { 17 try { 18 let func = self.state == STATE.FULFILLED ? fulfillFunc : rejectFunc; 19 func(self.value); 20 } catch (e) { 21 rejectFunc(e); 22 } 23 }, 0); 24 case STATE.PENDING: 25 // if it\u0026#39;s still pending, push the resolve/reject to callback queue. All the callback functions would be executed once state are changed 26 return self.callback.push({ 27 resolveFunc: () =\u0026gt; { 28 try { 29 fulfillFunc(self.value); 30 } catch (e) { 31 rejectFunc(e); 32 } 33 }, 34 rejectFunc: () =\u0026gt; { 35 try { 36 rejectFunc(self.value); 37 } catch (e) { 38 rejectFunc(e); 39 } 40 }, 41 }); 42 } 43}; Return Promise 2.2.7 Here comes the difficult part, then should return a Promise which would support the chaining feature.\nthen must return a promise [3.3].\npromise2 = promise1.then(onFulfilled, onRejected);\nAfter reading other implementations, here comes a question. Would this promise2 have its own executor? Yes or no would have different implementations.\nLet's first implement the simple one - Yes. It would have its own resolve/reject functions in executor. I would implement the optimized one -- No, with an empty promise, in another blog.\nAnother thing we need to think of is what if the value returned by promise2 is a promise. This is what the 2.3 Promise Resolution Procedure would do. Let's preserve this to later chapter and assume the value returned by promise2 is NOT another promise Then the logic of this promise2's executor should be:\nIf the state is fulfilled, the value returned by the onFulfilled function should be passed to resolve2 function in promise2's executor If the state is rejected, the value returned by the onRejected function should be passed to reject2 function in promise2's executor If the state is still pending, pass the resolveFunc and rejectFunc which would call resolve2 and reject2, to callback queue Any exception throwed by onFulfilled or onRejected should be handled by reject2 And we can extract the process of handling self.value as a function to reuse code.\n1function handleResult(resolve2, reject2) { 2 return () =\u0026gt; { 3 try { 4 // 2.2.7.1, 2.2.7.2 5 let func = self.state == STATE.FULFILLED ? fulfillFunc : rejectFunc; 6 let func2 = self.state == STATE.FULFILLED ? resolve2 : reject2; 7 func2(func(self.value)); 8 } catch (e) { 9 reject2(e); 10 } 11 }; 12} Til now, we have implement the features\nReturn Promise in then to support chaining Multiple then of one Promise The codes should be like this:\n1const STATE = { 2 PENDING: Symbol.for(\u0026#34;pending\u0026#34;), 3 FULFILLED: Symbol.for(\u0026#34;fulfilled\u0026#34;), 4 REJECTED: Symbol.for(\u0026#34;rejected\u0026#34;), 5}; 6 7const isFunction = (func) =\u0026gt; func \u0026amp;\u0026amp; typeof func === \u0026#34;function\u0026#34;; 8const isObject = (arg) =\u0026gt; arg \u0026amp;\u0026amp; typeof arg === \u0026#34;object\u0026#34;; 9 10function Promise(executor) { 11 let self = this; 12 13 // set the state as pending, 2.1.1 14 self.state = STATE.PENDING; 15 16 self.callback = []; 17 18 // 2.2.2.1 onFulfilled must be called after promise is fulfilled, with promise’s value as its first argument. 19 function resolve(value) { 20 if (self.state === STATE.PENDING) { 21 // 2.2.2.2 it must not be called before promise is fulfilled. 22 self.state = STATE.FULFILLED; 23 self.value = value; 24 // 2.2.6.1 25 setTimeout( 26 () =\u0026gt; self.callback.forEach(({ resolveFunc }) =\u0026gt; resolveFunc(value)), 27 0 28 ); 29 } 30 } 31 32 // 2.2.3.1 onRejected must be called after promise is rejected, with promise’s reason as its first argument. 33 function reject(err) { 34 if (self.state === STATE.PENDING) { 35 // 2.2.3.2 it must not be called before promise is rejected. 36 self.state = STATE.REJECTED; 37 self.value = err; 38 // 2.2.6.2 39 setTimeout( 40 () =\u0026gt; self.callback.forEach(({ rejectFunc }) =\u0026gt; rejectFunc(err)), 41 0 42 ); 43 } 44 } 45 46 try { 47 // executor is function whose parameters is resolve and reject functions, 48 // which would be called inside of executor. 49 if (isFunction(executor)) executor(resolve, reject); 50 } catch (err) { 51 reject(err); 52 } 53} 54 55Promise.prototype.then = function (onFulfilled, onRejected) { 56 let self = this; 57 58 // 2.2.1 Both onFulfilled and onRejected are optional arguments, if any is not function, must ignore it 59 let fulfillFunc = isFunction(onFulfilled) ? onFulfilled : (value) =\u0026gt; value; 60 let rejectFunc = isFunction(onRejected) 61 ? onRejected 62 : (e) =\u0026gt; { 63 throw e; 64 }; 65 66 function handleResult(resolve2, reject2) { 67 return () =\u0026gt; { 68 try { 69 // 2.2.7.1, 2.2.7.2 70 let func = self.state == STATE.FULFILLED ? fulfillFunc : rejectFunc; 71 let func2 = self.state == STATE.FULFILLED ? resolve2 : reject2; 72 func2(func(self.value)); 73 } catch (e) { 74 reject2(e); 75 } 76 }; 77 } 78 79 return new Promise((resolve2, reject2) =\u0026gt; { 80 switch (self.state) { 81 // if the state is fulfilled or rejected, just execute the related function and pass the result to the resolvePromise 82 case STATE.FULFILLED: 83 return setTimeout(handleResult(resolve2, reject2), 0); 84 case STATE.REJECTED: 85 return setTimeout(handleResult(resolve2, reject2), 0); 86 case STATE.PENDING: 87 // if it\u0026#39;s still pending, push the resolve/reject to callback queue. All the callback functions would be executed once state are changed 88 return self.callback.push({ 89 resolveFunc: handleResult(resolve2, reject2), 90 rejectFunc: handleResult(resolve2, reject2), 91 }); 92 } 93 }); 94}; Let's simply test it:\n1const p1 = new Promise((resolve, reject) =\u0026gt; { 2 setTimeout(() =\u0026gt; resolve(\u0026#34;resolved first one\u0026#34;), 3000); 3}); 4 5p1.then((res) =\u0026gt; { 6 console.log(\u0026#34;then1: \u0026#34;, res); 7 return res; 8}).then((res) =\u0026gt; { 9 setTimeout(() =\u0026gt; console.log(\u0026#34;then2: \u0026#34;, res), 1000); 10}); 11 12p1.then((res) =\u0026gt; { 13 console.log(\u0026#34;another then: \u0026#34;, res); 14}); 15 16// then1: resolved first one 17// another then: resolved first one 18// then2: resolved first one Promise Resolution Procedure 2.3 Here comes the last step, implement the Promise Resolution Procedure. According to the description of requirement:\nThis treatment of thenables allows promise implementations to interoperate, as long as they expose a Promises/A+-compliant then method. It also allows Promises/A+ implementations to “assimilate” nonconformant implementations with reasonable then methods.\nAnd before we begin to implement, let's think of why we have to have this resolvePromise, since it calls itself inside recursively. Comparing the text explanation, let me present one test case from Promise/A+. The case is generated by two loops, I just pick one here.\nAdapter In the test case, an adapter is utilized and explained in the Promise/A+ as well, check adapter;\n1Promise.defer = Promise.deferred = function () { 2 let dfd = {}; 3 dfd.promise = new Promise((resolve, reject) =\u0026gt; { 4 dfd.resolve = resolve; 5 dfd.reject = reject; 6 }); 7 return dfd; 8}; 9 10adapter.resolved = function (value) { 11 var d = adapter.deferred(); 12 d.resolve(value); 13 return d.promise; 14}; Definitely, we have seen this resolved many times, but what it does exactly? Through its code, we can understand it\nCreate a promise with a very simple executor which normally executes the logic of asynchronous codes Resolve the promise with the value immediately by updating state and saving the value before we have this resolve method Return this created promise So for the code resolved(value), actually it just preserves the value and waiting the resolve method from its then. When its then is called, the value would be passed to resolve method immediately.\nTest case The test case's description is\ny is an already-fulfilled promise for a synchronously-fulfilled custom thenable, then calls resolvePromise synchronously\nAnd I can simplify the test code, removing all the wrapped test functions:\n1const result = { result }; 2 3var promise = resolved({ dummy }).then(function onBasePromiseFulfilled() { 4 return { 5 then: function (resolvePromise) { 6 resolvePromise( 7 resolved({ 8 then: function (onFulfilled) { 9 onFulfilled(result); 10 }, 11 }) 12 ); 13 }, 14 }; 15}); 16 17promise.then(function onPromiseFulfilled(value) { 18 assert.strictEqual(value, result); 19 done(); 20}); Yes, HHHHHHHHeadache!!!!\nDefinitely there are a lot of promises wrapped like matryoshka doll, and so hard to dig into it. Yes, I know, but we can analysis the codes step by step, at leas we can simply count how many promises are here:\nresolved({ dummy }) uses resolved. As explained above, it returns a resolved promise and waits for the resolve method from its then. Let's call this promise as promise-TEMP; promise-TEMP called then which passes the function onBasePromiseFulfilled as resolve. AND it returns our first promise -- promise onBasePromiseFulfilled return a thenable object as value of promise. Let's call it x; x, which we can simply treat it as a Promise as well -- promise2, has the then function which would call its parameter resolvePromise further. The called value would be the value of promise2. Let's call it y; The value passed to resolvePromise is another resolved promise -- promise3, which is fulfilled and has no resolve method. But its value is another thenable object -- or promise4; Finally we reach the bottom level, the resolve method onFulfilled of promise4's then calls the result; So let's count how many promises and values we have here (ignore the promise-TEMP):\npromise -- the only one having name in our test codes its value x -\u0026gt; promise2 promise2 -- first thenable object its value y -\u0026gt; promise3 promise3 -- a resolved promise its value -\u0026gt; promise4 promise4 -- second thenable object its value -\u0026gt; result, an object So we can see the value of promise is a promise -- promise2 which wraps another two promises -- promise3 and promise4. And the assert sits inside of the resolve onPromiseFulfilled method of the first promise, it would expect the value returned by onPromiseFulfilled to be the same with result, which is the value of promise4.\nWe can conclude some points here:\nThe thenable object can be treated as a promise, which means they can be handled as the same codes. (This is not a principle, we can discuss this in another blog) If the value of a promise is a thenable object, the promise's resolve/reject methods would be passed to the value until the final value is not a promise and handled by the original resolve/reject methods. Implementation OK, it's enough to learn from the test case, even though it's what I learned after I passed all the test cases. Let's go back to the requirements and implement it.\nSince thenable object can be treated as promise, we would ignore the requirement of 2.3.2:\n2.3.2 If x is a promise, adopt its state [3.4]:\n2.3.2.1 If x is pending, promise must remain pending until x is fulfilled or rejected.\n2.3.2.2 If/when x is fulfilled, fulfill promise with the same value.\n2.3.2.3 If/when x is rejected, reject promise with the same reason.\nThis point can be merged with 2.3.3. Others would not be hard, just follow the steps:\n1function resolvePromise(promise, x, resolve2, reject2) { 2 if (promise == x) { 3 return reject2( 4 new TypeError(\u0026#34;Resolved result should not be the same promise!\u0026#34;) 5 ); 6 } else if (x \u0026amp;\u0026amp; (isFunction(x) || isObject(x))) { 7 let called = false; // 2.3.3.3.3 8 9 try { 10 let then = x.then; 11 12 if (isFunction(then)) { 13 then.call( 14 // 2.3.3.3 15 x, 16 function (y) { 17 if (called) return; // 2.3.3.3.3 18 called = true; 19 return resolvePromise(promise, y, resolve2, reject2); // 2.3.3.3.1 20 }, 21 function (r) { 22 if (called) return; 23 called = true; 24 return reject2(r); // 2.3.3.3.2 25 } 26 ); 27 } else { 28 resolve2(x); // 2.3.3.4 29 } 30 } catch (err) { 31 if (called) return; // 2.3.3.3.4.1 32 called = true; 33 reject2(err); // 2.3.3.3.4.2 34 } 35 } else { 36 resolve2(x); // 2.3.4 37 } 38} Test Now we have implemented all the mandatory codes, we can run the test the codes with npm lib promises-aplus-tests.\n1npm i -g promises-aplus-tests 2promises-aplus-tests promise1.js // promise1.js is the file name The full code can be checked here. There are different versions with different techniques, you can choose anyone.\nSummary This solution is not perfect and it just simply follows the rules of Promise/A+ without any better architecture and design. There are a lot of good solutions which restructures the codes with their own idea and logic. I would rewrite the promise with other techniques later.\nBesides, this version just completes the basic part. Promise also has resolve, catch, finally, etc. I will implement them as well and write another article about them.\nThanks to this article, which inspires me to make decision to implement the Promise and Zhi Sun's article, which reminders me of taking steps to implement the hard part.\n---------------------- UPDATE ----------------------\nInstead prototype, I have implemented the Promise with javascript class, which is not the feature of ES5, therefore, we need to compile it with babel and test with nodejs. And the code logic is almost the same with the version 1. Here is the code.\nThere are two things we need to take care when using class:\nWhen we pass the #internalResolve/#internalReject functions which are defined as class private methods, to executor, we need to use bind to bind the function with class's instance or this, since we use this inside of #internalResolve/#internalReject. Codes are: 1constructor(executor) { 2 try { 3 executor( 4 this.#internalResolve.bind(this), 5 this.#internalReject.bind(this) 6 ); 7 } catch (err) { 8 this.#internalReject(err); 9 } 10} 11 12#internalResolve(value) { 13 if (this.#state == STATE.PENDING) { 14 // ... 15 } 16} 17 18#internalReject(reason) { 19 if (this.#state == STATE.PENDING) { 20 //... 21 } 22} Be careful for this especially when we create functions inside of class methods. It's best to define a variable and assign this to it, like self. ","link":"https://xfsnowind.github.io/blogs/promise/","section":"blogs","tags":["Javascript","Promise"],"title":"Promise implementation"},{"body":"The techniques and some project I plan to learn or finish:\ngRPC vs REST -- get some knowledge of gRPC Esbuild, vite, svelte -- understand the difference of vite and esbuild, apply esbuild for develop and webpack for production webpack hotload ES6 ES7 -- get overview of ES6 and ES7 Command kitty -- get familiar with kitty Material UI -- get to know how to use material design Flutter vs React Native -- get some overview of mobile development React-hook-form website with react -- use react-hook-form to generate a full form again Hugo personal github page -- xfsnowind React long lists -- react-window, react-virtual-window Go through test framework of js, jest, react-testing-library -- review the test library of js Blog for learning geektime -- learning some topics throught geektime http headers -- go through the http headers to get an overview Regular express forward -- deep learn the regex forward again Terraform -- get knowledge of it Promise -- write promise self with different js tech until not forget it any more Kubernetes Folderflip and version 2 Google map knowledge Monorepo vs polyrepo Micro Frontend - module federation VIM Advanced GoLang Cloud Font vs SVG react list key with id Typescript ","link":"https://xfsnowind.github.io/blogs/learning-plan/","section":"blogs","tags":null,"title":"Learning Plan"},{"body":"I am a full stack developer currently living in Singapore and would like to record some technical ideas and articles here to help myself remember and summarize all the knowledge. If the blogs can help you, it would also be my please.\n","link":"https://xfsnowind.github.io/about/","section":"","tags":null,"title":"About"},{"body":"","link":"https://xfsnowind.github.io/categories/","section":"categories","tags":null,"title":"Categories"},{"body":"","link":"https://xfsnowind.github.io/series/","section":"series","tags":null,"title":"Series"}]